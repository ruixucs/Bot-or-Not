============================================================
RUN: max_v3_20260214_074700
LOG: C:\Users\XuRui\Downloads\Bot-or-Not-main\Bot-or-Not-main\runs\max_v3_20260214_074700\max_v3_20260214_074700.log
DIR: C:\Users\XuRui\Downloads\Bot-or-Not-main\Bot-or-Not-main\runs\max_v3_20260214_074700
============================================================

GPU available: True
GPU: NVIDIA GeForce RTX 3060 Laptop GPU
GPU Memory: 6.0 GB
Tree model device: XGBoost=cuda, CatBoost=GPU
[Local] DATA_DIR = C:\Users\XuRui\Downloads\Bot-or-Not-main\Bot-or-Not-main
Dataset 30 (en): 275 users, 7528 posts, 66 known bots
Dataset 31 (fr): 171 users, 4643 posts, 27 known bots
Dataset 32 (en): 271 users, 8237 posts, 63 known bots
Dataset 33 (fr): 172 users, 4361 posts, 28 known bots

Loaded 4 datasets: [30, 31, 32, 33]
English datasets: [30, 32]
French datasets: [31, 33]
Feature extraction functions defined.

Extracting basic features for dataset 30...
  Shape: (275, 62), Bots: 66, Humans: 209

Extracting basic features for dataset 31...
  Shape: (171, 62), Bots: 27, Humans: 144

Extracting basic features for dataset 32...
  Shape: (271, 62), Bots: 63, Humans: 208

Extracting basic features for dataset 33...
  Shape: (172, 62), Bots: 28, Humans: 144

Basic feature extraction complete!

Extracting advanced temporal features for dataset 30...
  Shape: (275, 22)

Extracting advanced temporal features for dataset 31...
  Shape: (171, 22)

Extracting advanced temporal features for dataset 32...
  Shape: (271, 22)

Extracting advanced temporal features for dataset 33...
  Shape: (172, 22)

Advanced temporal feature extraction complete!

Extracting stylometry features for dataset 30...
  Shape: (275, 16)

Extracting stylometry features for dataset 31...
  Shape: (171, 16)

Extracting stylometry features for dataset 32...
  Shape: (271, 16)

Extracting stylometry features for dataset 33...
  Shape: (172, 16)

Stylometry feature extraction complete!

Extracting mention network features for dataset 30...
  Shape: (275, 11)

Extracting mention network features for dataset 31...
  Shape: (171, 11)

Extracting mention network features for dataset 32...
  Shape: (271, 11)

Extracting mention network features for dataset 33...
  Shape: (172, 11)

Mention network feature extraction complete!
NLP feature functions defined.
Loading Sentence Transformer...
Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
Loading weights:   0%|                                                                         | 0/199 [00:00<?, ?it/s]Loading weights:   1%|▏                         | 1/199 [00:00<?, ?it/s, Materializing param=embeddings.LayerNorm.bias]Loading weights:   1%|▏                         | 1/199 [00:00<?, ?it/s, Materializing param=embeddings.LayerNorm.bias]Loading weights:   1%|▏                       | 2/199 [00:00<?, ?it/s, Materializing param=embeddings.LayerNorm.weight]Loading weights:   1%|▏                       | 2/199 [00:00<?, ?it/s, Materializing param=embeddings.LayerNorm.weight]Loading weights:   2%|     | 3/199 [00:00<00:00, 586.10it/s, Materializing param=embeddings.position_embeddings.weight]Loading weights:   2%|     | 3/199 [00:00<00:00, 586.10it/s, Materializing param=embeddings.position_embeddings.weight]Loading weights:   2%|   | 4/199 [00:00<00:00, 781.46it/s, Materializing param=embeddings.token_type_embeddings.weight]Loading weights:   2%|   | 4/199 [00:00<00:00, 781.46it/s, Materializing param=embeddings.token_type_embeddings.weight]Loading weights:   3%|▏        | 5/199 [00:00<00:00, 976.83it/s, Materializing param=embeddings.word_embeddings.weight]Loading weights:   3%|▏        | 5/199 [00:00<00:00, 976.83it/s, Materializing param=embeddings.word_embeddings.weight]Loading weights:   3%| | 6/199 [00:00<00:00, 1172.19it/s, Materializing param=encoder.layer.0.attention.output.LayerNorLoading weights:   3%| | 6/199 [00:00<00:00, 1172.19it/s, Materializing param=encoder.layer.0.attention.output.LayerNorLoading weights:   4%| | 7/199 [00:00<00:00, 691.38it/s, Materializing param=encoder.layer.0.attention.output.LayerNormLoading weights:   4%| | 7/199 [00:00<00:00, 691.38it/s, Materializing param=encoder.layer.0.attention.output.LayerNormLoading weights:   4%| | 8/199 [00:00<00:00, 790.15it/s, Materializing param=encoder.layer.0.attention.output.dense.biaLoading weights:   4%| | 8/199 [00:00<00:00, 790.15it/s, Materializing param=encoder.layer.0.attention.output.dense.biaLoading weights:   5%| | 9/199 [00:00<00:00, 888.92it/s, Materializing param=encoder.layer.0.attention.output.dense.weiLoading weights:   5%| | 9/199 [00:00<00:00, 888.92it/s, Materializing param=encoder.layer.0.attention.output.dense.weiLoading weights:   5%|  | 10/199 [00:00<00:00, 987.69it/s, Materializing param=encoder.layer.0.attention.self.key.bias]Loading weights:   5%|  | 10/199 [00:00<00:00, 658.63it/s, Materializing param=encoder.layer.0.attention.self.key.bias]Loading weights:   6%| | 11/199 [00:00<00:00, 724.50it/s, Materializing param=encoder.layer.0.attention.self.key.weightLoading weights:   6%| | 11/199 [00:00<00:00, 724.50it/s, Materializing param=encoder.layer.0.attention.self.key.weightLoading weights:   6%| | 12/199 [00:00<00:00, 790.36it/s, Materializing param=encoder.layer.0.attention.self.query.biasLoading weights:   6%| | 12/199 [00:00<00:00, 790.36it/s, Materializing param=encoder.layer.0.attention.self.query.biasLoading weights:   7%| | 13/199 [00:00<00:00, 856.22it/s, Materializing param=encoder.layer.0.attention.self.query.weigLoading weights:   7%| | 13/199 [00:00<00:00, 856.22it/s, Materializing param=encoder.layer.0.attention.self.query.weigLoading weights:   7%| | 14/199 [00:00<00:00, 922.09it/s, Materializing param=encoder.layer.0.attention.self.value.biasLoading weights:   7%| | 14/199 [00:00<00:00, 922.09it/s, Materializing param=encoder.layer.0.attention.self.value.biasLoading weights:   8%| | 15/199 [00:00<00:00, 739.69it/s, Materializing param=encoder.layer.0.attention.self.value.weigLoading weights:   8%| | 15/199 [00:00<00:00, 739.69it/s, Materializing param=encoder.layer.0.attention.self.value.weigLoading weights:   8%|▏ | 16/199 [00:00<00:00, 789.01it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]Loading weights:   8%|▏ | 16/199 [00:00<00:00, 789.01it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]Loading weights:   9%| | 17/199 [00:00<00:00, 838.32it/s, Materializing param=encoder.layer.0.intermediate.dense.weightLoading weights:   9%| | 17/199 [00:00<00:00, 838.32it/s, Materializing param=encoder.layer.0.intermediate.dense.weightLoading weights:   9%|▎   | 18/199 [00:00<00:00, 887.63it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]Loading weights:   9%|▎   | 18/199 [00:00<00:00, 887.63it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]Loading weights:  10%|▏ | 19/199 [00:00<00:00, 936.94it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]Loading weights:  10%|▏ | 19/199 [00:00<00:00, 936.94it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]Loading weights:  10%|▊       | 20/199 [00:00<00:00, 785.39it/s, Materializing param=encoder.layer.0.output.dense.bias]Loading weights:  10%|▊       | 20/199 [00:00<00:00, 785.39it/s, Materializing param=encoder.layer.0.output.dense.bias]Loading weights:  11%|▋     | 21/199 [00:00<00:00, 824.66it/s, Materializing param=encoder.layer.0.output.dense.weight]Loading weights:  11%|▋     | 21/199 [00:00<00:00, 824.66it/s, Materializing param=encoder.layer.0.output.dense.weight]Loading weights:  11%| | 22/199 [00:00<00:00, 863.93it/s, Materializing param=encoder.layer.1.attention.output.LayerNorLoading weights:  11%| | 22/199 [00:00<00:00, 863.93it/s, Materializing param=encoder.layer.1.attention.output.LayerNorLoading weights:  12%| | 23/199 [00:00<00:00, 903.20it/s, Materializing param=encoder.layer.1.attention.output.LayerNorLoading weights:  12%| | 23/199 [00:00<00:00, 903.20it/s, Materializing param=encoder.layer.1.attention.output.LayerNorLoading weights:  12%| | 24/199 [00:00<00:00, 942.47it/s, Materializing param=encoder.layer.1.attention.output.dense.biLoading weights:  12%| | 24/199 [00:00<00:00, 942.47it/s, Materializing param=encoder.layer.1.attention.output.dense.biLoading weights:  13%|▏| 25/199 [00:00<00:00, 981.74it/s, Materializing param=encoder.layer.1.attention.output.dense.weLoading weights:  13%|▏| 25/199 [00:00<00:00, 981.74it/s, Materializing param=encoder.layer.1.attention.output.dense.weLoading weights:  13%|▏| 26/199 [00:00<00:00, 1021.01it/s, Materializing param=encoder.layer.1.attention.self.key.bias]Loading weights:  13%|▏| 26/199 [00:00<00:00, 1021.01it/s, Materializing param=encoder.layer.1.attention.self.key.bias]Loading weights:  14%|▏| 27/199 [00:00<00:00, 1060.28it/s, Materializing param=encoder.layer.1.attention.self.key.weighLoading weights:  14%|▏| 27/199 [00:00<00:00, 1060.28it/s, Materializing param=encoder.layer.1.attention.self.key.weighLoading weights:  14%|▏| 28/199 [00:00<00:00, 1099.55it/s, Materializing param=encoder.layer.1.attention.self.query.biaLoading weights:  14%|▏| 28/199 [00:00<00:00, 1099.55it/s, Materializing param=encoder.layer.1.attention.self.query.biaLoading weights:  15%|▏| 29/199 [00:00<00:00, 1138.82it/s, Materializing param=encoder.layer.1.attention.self.query.weiLoading weights:  15%|▏| 29/199 [00:00<00:00, 1138.82it/s, Materializing param=encoder.layer.1.attention.self.query.weiLoading weights:  15%|▏| 30/199 [00:00<00:00, 1178.09it/s, Materializing param=encoder.layer.1.attention.self.value.biaLoading weights:  15%|▏| 30/199 [00:00<00:00, 979.27it/s, Materializing param=encoder.layer.1.attention.self.value.biasLoading weights:  16%|▏| 31/199 [00:00<00:00, 1011.91it/s, Materializing param=encoder.layer.1.attention.self.value.weiLoading weights:  16%|▏| 31/199 [00:00<00:00, 1011.91it/s, Materializing param=encoder.layer.1.attention.self.value.weiLoading weights:  16%|▏| 32/199 [00:00<00:00, 1019.30it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]Loading weights:  16%|▏| 32/199 [00:00<00:00, 1019.30it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]Loading weights:  17%|▏| 33/199 [00:00<00:00, 1051.15it/s, Materializing param=encoder.layer.1.intermediate.dense.weighLoading weights:  17%|▏| 33/199 [00:00<00:00, 1051.15it/s, Materializing param=encoder.layer.1.intermediate.dense.weighLoading weights:  17%|▌  | 34/199 [00:00<00:00, 1049.33it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]Loading weights:  17%|▌  | 34/199 [00:00<00:00, 1049.33it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]Loading weights:  18%|▏| 35/199 [00:00<00:00, 1080.19it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]Loading weights:  18%|▏| 35/199 [00:00<00:00, 1080.19it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]Loading weights:  18%|█▎     | 36/199 [00:00<00:00, 1079.51it/s, Materializing param=encoder.layer.1.output.dense.bias]Loading weights:  18%|█▎     | 36/199 [00:00<00:00, 1079.51it/s, Materializing param=encoder.layer.1.output.dense.bias]Loading weights:  19%|▉    | 37/199 [00:00<00:00, 1109.50it/s, Materializing param=encoder.layer.1.output.dense.weight]Loading weights:  19%|▉    | 37/199 [00:00<00:00, 1109.50it/s, Materializing param=encoder.layer.1.output.dense.weight]Loading weights:  19%|▏| 38/199 [00:00<00:00, 1139.49it/s, Materializing param=encoder.layer.2.attention.output.LayerNoLoading weights:  19%|▏| 38/199 [00:00<00:00, 1139.49it/s, Materializing param=encoder.layer.2.attention.output.LayerNoLoading weights:  20%|▏| 39/199 [00:00<00:00, 1169.47it/s, Materializing param=encoder.layer.2.attention.output.LayerNoLoading weights:  20%|▏| 39/199 [00:00<00:00, 1169.47it/s, Materializing param=encoder.layer.2.attention.output.LayerNoLoading weights:  20%|▏| 40/199 [00:00<00:00, 1199.46it/s, Materializing param=encoder.layer.2.attention.output.dense.bLoading weights:  20%|▏| 40/199 [00:00<00:00, 1199.46it/s, Materializing param=encoder.layer.2.attention.output.dense.bLoading weights:  21%|▏| 41/199 [00:00<00:00, 1229.45it/s, Materializing param=encoder.layer.2.attention.output.dense.wLoading weights:  21%|▏| 41/199 [00:00<00:00, 1229.45it/s, Materializing param=encoder.layer.2.attention.output.dense.wLoading weights:  21%|▏| 42/199 [00:00<00:00, 1259.43it/s, Materializing param=encoder.layer.2.attention.self.key.bias]Loading weights:  21%|▏| 42/199 [00:00<00:00, 1259.43it/s, Materializing param=encoder.layer.2.attention.self.key.bias]Loading weights:  22%|▏| 43/199 [00:00<00:00, 1289.42it/s, Materializing param=encoder.layer.2.attention.self.key.weighLoading weights:  22%|▏| 43/199 [00:00<00:00, 1289.42it/s, Materializing param=encoder.layer.2.attention.self.key.weighLoading weights:  22%|▏| 44/199 [00:00<00:00, 1319.41it/s, Materializing param=encoder.layer.2.attention.self.query.biaLoading weights:  22%|▏| 44/199 [00:00<00:00, 1176.44it/s, Materializing param=encoder.layer.2.attention.self.query.biaLoading weights:  23%|▏| 45/199 [00:00<00:00, 1203.18it/s, Materializing param=encoder.layer.2.attention.self.query.weiLoading weights:  23%|▏| 45/199 [00:00<00:00, 1203.18it/s, Materializing param=encoder.layer.2.attention.self.query.weiLoading weights:  23%|▏| 46/199 [00:00<00:00, 1205.55it/s, Materializing param=encoder.layer.2.attention.self.value.biaLoading weights:  23%|▏| 46/199 [00:00<00:00, 1205.55it/s, Materializing param=encoder.layer.2.attention.self.value.biaLoading weights:  24%|▏| 47/199 [00:00<00:00, 1231.76it/s, Materializing param=encoder.layer.2.attention.self.value.weiLoading weights:  24%|▏| 47/199 [00:00<00:00, 1231.76it/s, Materializing param=encoder.layer.2.attention.self.value.weiLoading weights:  24%|▏| 48/199 [00:00<00:00, 1257.97it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]Loading weights:  24%|▏| 48/199 [00:00<00:00, 1257.97it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]Loading weights:  25%|▏| 49/199 [00:00<00:00, 1284.18it/s, Materializing param=encoder.layer.2.intermediate.dense.weighLoading weights:  25%|▏| 49/199 [00:00<00:00, 1284.18it/s, Materializing param=encoder.layer.2.intermediate.dense.weighLoading weights:  25%|▊  | 50/199 [00:00<00:00, 1310.38it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]Loading weights:  25%|▊  | 50/199 [00:00<00:00, 1310.38it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]Loading weights:  26%|▎| 51/199 [00:00<00:00, 1336.59it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]Loading weights:  26%|▎| 51/199 [00:00<00:00, 1336.59it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]Loading weights:  26%|█▊     | 52/199 [00:00<00:00, 1362.80it/s, Materializing param=encoder.layer.2.output.dense.bias]Loading weights:  26%|█▊     | 52/199 [00:00<00:00, 1362.80it/s, Materializing param=encoder.layer.2.output.dense.bias]Loading weights:  27%|█▎   | 53/199 [00:00<00:00, 1389.01it/s, Materializing param=encoder.layer.2.output.dense.weight]Loading weights:  27%|█▎   | 53/199 [00:00<00:00, 1389.01it/s, Materializing param=encoder.layer.2.output.dense.weight]Loading weights:  27%|▎| 54/199 [00:00<00:00, 1415.21it/s, Materializing param=encoder.layer.3.attention.output.LayerNoLoading weights:  27%|▎| 54/199 [00:00<00:00, 1415.21it/s, Materializing param=encoder.layer.3.attention.output.LayerNoLoading weights:  28%|▎| 55/199 [00:00<00:00, 1441.42it/s, Materializing param=encoder.layer.3.attention.output.LayerNoLoading weights:  28%|▎| 55/199 [00:00<00:00, 1441.42it/s, Materializing param=encoder.layer.3.attention.output.LayerNoLoading weights:  28%|▎| 56/199 [00:00<00:00, 1467.63it/s, Materializing param=encoder.layer.3.attention.output.dense.bLoading weights:  28%|▎| 56/199 [00:00<00:00, 1467.63it/s, Materializing param=encoder.layer.3.attention.output.dense.bLoading weights:  29%|▎| 57/199 [00:00<00:00, 1493.84it/s, Materializing param=encoder.layer.3.attention.output.dense.wLoading weights:  29%|▎| 57/199 [00:00<00:00, 1493.84it/s, Materializing param=encoder.layer.3.attention.output.dense.wLoading weights:  29%|▎| 58/199 [00:00<00:00, 1339.14it/s, Materializing param=encoder.layer.3.attention.self.key.bias]Loading weights:  29%|▎| 58/199 [00:00<00:00, 1339.14it/s, Materializing param=encoder.layer.3.attention.self.key.bias]Loading weights:  30%|▎| 59/199 [00:00<00:00, 1362.23it/s, Materializing param=encoder.layer.3.attention.self.key.weighLoading weights:  30%|▎| 59/199 [00:00<00:00, 1338.94it/s, Materializing param=encoder.layer.3.attention.self.key.weighLoading weights:  30%|▎| 60/199 [00:00<00:00, 1361.63it/s, Materializing param=encoder.layer.3.attention.self.query.biaLoading weights:  30%|▎| 60/199 [00:00<00:00, 1361.63it/s, Materializing param=encoder.layer.3.attention.self.query.biaLoading weights:  31%|▎| 61/199 [00:00<00:00, 1384.33it/s, Materializing param=encoder.layer.3.attention.self.query.weiLoading weights:  31%|▎| 61/199 [00:00<00:00, 1384.33it/s, Materializing param=encoder.layer.3.attention.self.query.weiLoading weights:  31%|▎| 62/199 [00:00<00:00, 1407.02it/s, Materializing param=encoder.layer.3.attention.self.value.biaLoading weights:  31%|▎| 62/199 [00:00<00:00, 1407.02it/s, Materializing param=encoder.layer.3.attention.self.value.biaLoading weights:  32%|▎| 63/199 [00:00<00:00, 1429.71it/s, Materializing param=encoder.layer.3.attention.self.value.weiLoading weights:  32%|▎| 63/199 [00:00<00:00, 1429.71it/s, Materializing param=encoder.layer.3.attention.self.value.weiLoading weights:  32%|▎| 64/199 [00:00<00:00, 1452.41it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]Loading weights:  32%|▎| 64/199 [00:00<00:00, 1452.41it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]Loading weights:  33%|▎| 65/199 [00:00<00:00, 1475.10it/s, Materializing param=encoder.layer.3.intermediate.dense.weighLoading weights:  33%|▎| 65/199 [00:00<00:00, 1475.10it/s, Materializing param=encoder.layer.3.intermediate.dense.weighLoading weights:  33%|▉  | 66/199 [00:00<00:00, 1497.80it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]Loading weights:  33%|▉  | 66/199 [00:00<00:00, 1497.80it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]Loading weights:  34%|▎| 67/199 [00:00<00:00, 1520.49it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]Loading weights:  34%|▎| 67/199 [00:00<00:00, 1520.49it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]Loading weights:  34%|██▍    | 68/199 [00:00<00:00, 1543.18it/s, Materializing param=encoder.layer.3.output.dense.bias]Loading weights:  34%|██▍    | 68/199 [00:00<00:00, 1543.18it/s, Materializing param=encoder.layer.3.output.dense.bias]Loading weights:  35%|█▋   | 69/199 [00:00<00:00, 1565.88it/s, Materializing param=encoder.layer.3.output.dense.weight]Loading weights:  35%|█▋   | 69/199 [00:00<00:00, 1565.88it/s, Materializing param=encoder.layer.3.output.dense.weight]Loading weights:  35%|▎| 70/199 [00:00<00:00, 1588.57it/s, Materializing param=encoder.layer.4.attention.output.LayerNoLoading weights:  35%|▎| 70/199 [00:00<00:00, 1588.57it/s, Materializing param=encoder.layer.4.attention.output.LayerNoLoading weights:  36%|▎| 71/199 [00:00<00:00, 1611.26it/s, Materializing param=encoder.layer.4.attention.output.LayerNoLoading weights:  36%|▎| 71/199 [00:00<00:00, 1611.26it/s, Materializing param=encoder.layer.4.attention.output.LayerNoLoading weights:  36%|▎| 72/199 [00:00<00:00, 1633.96it/s, Materializing param=encoder.layer.4.attention.output.dense.bLoading weights:  36%|▎| 72/199 [00:00<00:00, 1461.16it/s, Materializing param=encoder.layer.4.attention.output.dense.bLoading weights:  37%|▎| 73/199 [00:00<00:00, 1481.46it/s, Materializing param=encoder.layer.4.attention.output.dense.wLoading weights:  37%|▎| 73/199 [00:00<00:00, 1481.46it/s, Materializing param=encoder.layer.4.attention.output.dense.wLoading weights:  37%|▎| 74/199 [00:00<00:00, 1477.80it/s, Materializing param=encoder.layer.4.attention.self.key.bias]Loading weights:  37%|▎| 74/199 [00:00<00:00, 1477.80it/s, Materializing param=encoder.layer.4.attention.self.key.bias]Loading weights:  38%|▍| 75/199 [00:00<00:00, 1497.77it/s, Materializing param=encoder.layer.4.attention.self.key.weighLoading weights:  38%|▍| 75/199 [00:00<00:00, 1497.77it/s, Materializing param=encoder.layer.4.attention.self.key.weighLoading weights:  38%|▍| 76/199 [00:00<00:00, 1517.74it/s, Materializing param=encoder.layer.4.attention.self.query.biaLoading weights:  38%|▍| 76/199 [00:00<00:00, 1517.74it/s, Materializing param=encoder.layer.4.attention.self.query.biaLoading weights:  39%|▍| 77/199 [00:00<00:00, 1537.71it/s, Materializing param=encoder.layer.4.attention.self.query.weiLoading weights:  39%|▍| 77/199 [00:00<00:00, 1537.71it/s, Materializing param=encoder.layer.4.attention.self.query.weiLoading weights:  39%|▍| 78/199 [00:00<00:00, 1557.68it/s, Materializing param=encoder.layer.4.attention.self.value.biaLoading weights:  39%|▍| 78/199 [00:00<00:00, 1557.68it/s, Materializing param=encoder.layer.4.attention.self.value.biaLoading weights:  40%|▍| 79/199 [00:00<00:00, 1577.65it/s, Materializing param=encoder.layer.4.attention.self.value.weiLoading weights:  40%|▍| 79/199 [00:00<00:00, 1577.65it/s, Materializing param=encoder.layer.4.attention.self.value.weiLoading weights:  40%|▍| 80/199 [00:00<00:00, 1597.62it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]Loading weights:  40%|▍| 80/199 [00:00<00:00, 1597.62it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]Loading weights:  41%|▍| 81/199 [00:00<00:00, 1617.59it/s, Materializing param=encoder.layer.4.intermediate.dense.weighLoading weights:  41%|▍| 81/199 [00:00<00:00, 1617.59it/s, Materializing param=encoder.layer.4.intermediate.dense.weighLoading weights:  41%|█▏ | 82/199 [00:00<00:00, 1637.56it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]Loading weights:  41%|█▏ | 82/199 [00:00<00:00, 1637.56it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]Loading weights:  42%|▍| 83/199 [00:00<00:00, 1657.53it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]Loading weights:  42%|▍| 83/199 [00:00<00:00, 1657.53it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]Loading weights:  42%|██▉    | 84/199 [00:00<00:00, 1677.50it/s, Materializing param=encoder.layer.4.output.dense.bias]Loading weights:  42%|██▉    | 84/199 [00:00<00:00, 1519.96it/s, Materializing param=encoder.layer.4.output.dense.bias]Loading weights:  43%|██▏  | 85/199 [00:00<00:00, 1526.80it/s, Materializing param=encoder.layer.4.output.dense.weight]Loading weights:  43%|██▏  | 85/199 [00:00<00:00, 1526.80it/s, Materializing param=encoder.layer.4.output.dense.weight]Loading weights:  43%|▍| 86/199 [00:00<00:00, 1544.76it/s, Materializing param=encoder.layer.5.attention.output.LayerNoLoading weights:  43%|▍| 86/199 [00:00<00:00, 1517.53it/s, Materializing param=encoder.layer.5.attention.output.LayerNoLoading weights:  44%|▍| 87/199 [00:00<00:00, 1535.17it/s, Materializing param=encoder.layer.5.attention.output.LayerNoLoading weights:  44%|▍| 87/199 [00:00<00:00, 1535.17it/s, Materializing param=encoder.layer.5.attention.output.LayerNoLoading weights:  44%|▍| 88/199 [00:00<00:00, 1552.82it/s, Materializing param=encoder.layer.5.attention.output.dense.bLoading weights:  44%|▍| 88/199 [00:00<00:00, 1552.82it/s, Materializing param=encoder.layer.5.attention.output.dense.bLoading weights:  45%|▍| 89/199 [00:00<00:00, 1570.46it/s, Materializing param=encoder.layer.5.attention.output.dense.wLoading weights:  45%|▍| 89/199 [00:00<00:00, 1570.46it/s, Materializing param=encoder.layer.5.attention.output.dense.wLoading weights:  45%|▍| 90/199 [00:00<00:00, 1588.11it/s, Materializing param=encoder.layer.5.attention.self.key.bias]Loading weights:  45%|▍| 90/199 [00:00<00:00, 1588.11it/s, Materializing param=encoder.layer.5.attention.self.key.bias]Loading weights:  46%|▍| 91/199 [00:00<00:00, 1605.76it/s, Materializing param=encoder.layer.5.attention.self.key.weighLoading weights:  46%|▍| 91/199 [00:00<00:00, 1605.76it/s, Materializing param=encoder.layer.5.attention.self.key.weighLoading weights:  46%|▍| 92/199 [00:00<00:00, 1623.40it/s, Materializing param=encoder.layer.5.attention.self.query.biaLoading weights:  46%|▍| 92/199 [00:00<00:00, 1623.40it/s, Materializing param=encoder.layer.5.attention.self.query.biaLoading weights:  47%|▍| 93/199 [00:00<00:00, 1641.05it/s, Materializing param=encoder.layer.5.attention.self.query.weiLoading weights:  47%|▍| 93/199 [00:00<00:00, 1641.05it/s, Materializing param=encoder.layer.5.attention.self.query.weiLoading weights:  47%|▍| 94/199 [00:00<00:00, 1658.69it/s, Materializing param=encoder.layer.5.attention.self.value.biaLoading weights:  47%|▍| 94/199 [00:00<00:00, 1658.69it/s, Materializing param=encoder.layer.5.attention.self.value.biaLoading weights:  48%|▍| 95/199 [00:00<00:00, 1676.34it/s, Materializing param=encoder.layer.5.attention.self.value.weiLoading weights:  48%|▍| 95/199 [00:00<00:00, 1569.43it/s, Materializing param=encoder.layer.5.attention.self.value.weiLoading weights:  48%|▍| 96/199 [00:00<00:00, 1585.95it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]Loading weights:  48%|▍| 96/199 [00:00<00:00, 1585.95it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]Loading weights:  49%|▍| 97/199 [00:00<00:00, 1602.47it/s, Materializing param=encoder.layer.5.intermediate.dense.weighLoading weights:  49%|▍| 97/199 [00:00<00:00, 1602.47it/s, Materializing param=encoder.layer.5.intermediate.dense.weighLoading weights:  49%|█▍ | 98/199 [00:00<00:00, 1618.99it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]Loading weights:  49%|█▍ | 98/199 [00:00<00:00, 1586.95it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]Loading weights:  50%|▍| 99/199 [00:00<00:00, 1603.15it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]Loading weights:  50%|▍| 99/199 [00:00<00:00, 1603.15it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]Loading weights:  50%|███   | 100/199 [00:00<00:00, 1619.34it/s, Materializing param=encoder.layer.5.output.dense.bias]Loading weights:  50%|███   | 100/199 [00:00<00:00, 1588.19it/s, Materializing param=encoder.layer.5.output.dense.bias]Loading weights:  51%|██  | 101/199 [00:00<00:00, 1596.13it/s, Materializing param=encoder.layer.5.output.dense.weight]Loading weights:  51%|██  | 101/199 [00:00<00:00, 1596.13it/s, Materializing param=encoder.layer.5.output.dense.weight]Loading weights:  51%|▌| 102/199 [00:00<00:00, 1611.94it/s, Materializing param=encoder.layer.6.attention.output.LayerNLoading weights:  51%|▌| 102/199 [00:00<00:00, 1611.94it/s, Materializing param=encoder.layer.6.attention.output.LayerNLoading weights:  52%|▌| 103/199 [00:00<00:00, 1627.74it/s, Materializing param=encoder.layer.6.attention.output.LayerNLoading weights:  52%|▌| 103/199 [00:00<00:00, 1627.74it/s, Materializing param=encoder.layer.6.attention.output.LayerNLoading weights:  52%|▌| 104/199 [00:00<00:00, 1643.54it/s, Materializing param=encoder.layer.6.attention.output.dense.Loading weights:  52%|▌| 104/199 [00:00<00:00, 1643.54it/s, Materializing param=encoder.layer.6.attention.output.dense.Loading weights:  53%|▌| 105/199 [00:00<00:00, 1659.35it/s, Materializing param=encoder.layer.6.attention.output.dense.Loading weights:  53%|▌| 105/199 [00:00<00:00, 1659.35it/s, Materializing param=encoder.layer.6.attention.output.dense.Loading weights:  53%|▌| 106/199 [00:00<00:00, 1675.15it/s, Materializing param=encoder.layer.6.attention.self.key.biasLoading weights:  53%|▌| 106/199 [00:00<00:00, 1675.15it/s, Materializing param=encoder.layer.6.attention.self.key.biasLoading weights:  54%|▌| 107/199 [00:00<00:00, 1690.95it/s, Materializing param=encoder.layer.6.attention.self.key.weigLoading weights:  54%|▌| 107/199 [00:00<00:00, 1690.95it/s, Materializing param=encoder.layer.6.attention.self.key.weigLoading weights:  54%|▌| 108/199 [00:00<00:00, 1706.76it/s, Materializing param=encoder.layer.6.attention.self.query.biLoading weights:  54%|▌| 108/199 [00:00<00:00, 1706.76it/s, Materializing param=encoder.layer.6.attention.self.query.biLoading weights:  55%|▌| 109/199 [00:00<00:00, 1722.56it/s, Materializing param=encoder.layer.6.attention.self.query.weLoading weights:  55%|▌| 109/199 [00:00<00:00, 1722.56it/s, Materializing param=encoder.layer.6.attention.self.query.weLoading weights:  55%|▌| 110/199 [00:00<00:00, 1738.36it/s, Materializing param=encoder.layer.6.attention.self.value.biLoading weights:  55%|▌| 110/199 [00:00<00:00, 1738.36it/s, Materializing param=encoder.layer.6.attention.self.value.biLoading weights:  56%|▌| 111/199 [00:00<00:00, 1754.17it/s, Materializing param=encoder.layer.6.attention.self.value.weLoading weights:  56%|▌| 111/199 [00:00<00:00, 1754.17it/s, Materializing param=encoder.layer.6.attention.self.value.weLoading weights:  56%|▌| 112/199 [00:00<00:00, 1769.97it/s, Materializing param=encoder.layer.6.intermediate.dense.biasLoading weights:  56%|▌| 112/199 [00:00<00:00, 1651.31it/s, Materializing param=encoder.layer.6.intermediate.dense.biasLoading weights:  57%|▌| 113/199 [00:00<00:00, 1666.06it/s, Materializing param=encoder.layer.6.intermediate.dense.weigLoading weights:  57%|▌| 113/199 [00:00<00:00, 1666.06it/s, Materializing param=encoder.layer.6.intermediate.dense.weigLoading weights:  57%|█▏| 114/199 [00:00<00:00, 1680.80it/s, Materializing param=encoder.layer.6.output.LayerNorm.bias]Loading weights:  57%|█▏| 114/199 [00:00<00:00, 1656.11it/s, Materializing param=encoder.layer.6.output.LayerNorm.bias]Loading weights:  58%|▌| 115/199 [00:00<00:00, 1670.64it/s, Materializing param=encoder.layer.6.output.LayerNorm.weightLoading weights:  58%|▌| 115/199 [00:00<00:00, 1657.49it/s, Materializing param=encoder.layer.6.output.LayerNorm.weightLoading weights:  58%|███▍  | 116/199 [00:00<00:00, 1671.90it/s, Materializing param=encoder.layer.6.output.dense.bias]Loading weights:  58%|███▍  | 116/199 [00:00<00:00, 1671.90it/s, Materializing param=encoder.layer.6.output.dense.bias]Loading weights:  59%|██▎ | 117/199 [00:00<00:00, 1686.31it/s, Materializing param=encoder.layer.6.output.dense.weight]Loading weights:  59%|██▎ | 117/199 [00:00<00:00, 1686.31it/s, Materializing param=encoder.layer.6.output.dense.weight]Loading weights:  59%|▌| 118/199 [00:00<00:00, 1700.72it/s, Materializing param=encoder.layer.7.attention.output.LayerNLoading weights:  59%|▌| 118/199 [00:00<00:00, 1700.72it/s, Materializing param=encoder.layer.7.attention.output.LayerNLoading weights:  60%|▌| 119/199 [00:00<00:00, 1715.14it/s, Materializing param=encoder.layer.7.attention.output.LayerNLoading weights:  60%|▌| 119/199 [00:00<00:00, 1715.14it/s, Materializing param=encoder.layer.7.attention.output.LayerNLoading weights:  60%|▌| 120/199 [00:00<00:00, 1729.55it/s, Materializing param=encoder.layer.7.attention.output.dense.Loading weights:  60%|▌| 120/199 [00:00<00:00, 1729.55it/s, Materializing param=encoder.layer.7.attention.output.dense.Loading weights:  61%|▌| 121/199 [00:00<00:00, 1743.96it/s, Materializing param=encoder.layer.7.attention.output.dense.Loading weights:  61%|▌| 121/199 [00:00<00:00, 1743.96it/s, Materializing param=encoder.layer.7.attention.output.dense.Loading weights:  61%|▌| 122/199 [00:00<00:00, 1758.38it/s, Materializing param=encoder.layer.7.attention.self.key.biasLoading weights:  61%|▌| 122/199 [00:00<00:00, 1758.38it/s, Materializing param=encoder.layer.7.attention.self.key.biasLoading weights:  62%|▌| 123/199 [00:00<00:00, 1772.79it/s, Materializing param=encoder.layer.7.attention.self.key.weigLoading weights:  62%|▌| 123/199 [00:00<00:00, 1772.79it/s, Materializing param=encoder.layer.7.attention.self.key.weigLoading weights:  62%|▌| 124/199 [00:00<00:00, 1787.20it/s, Materializing param=encoder.layer.7.attention.self.query.biLoading weights:  62%|▌| 124/199 [00:00<00:00, 1787.20it/s, Materializing param=encoder.layer.7.attention.self.query.biLoading weights:  63%|▋| 125/199 [00:00<00:00, 1801.62it/s, Materializing param=encoder.layer.7.attention.self.query.weLoading weights:  63%|▋| 125/199 [00:00<00:00, 1801.62it/s, Materializing param=encoder.layer.7.attention.self.query.weLoading weights:  63%|▋| 126/199 [00:00<00:00, 1816.03it/s, Materializing param=encoder.layer.7.attention.self.value.biLoading weights:  63%|▋| 126/199 [00:00<00:00, 1816.03it/s, Materializing param=encoder.layer.7.attention.self.value.biLoading weights:  64%|▋| 127/199 [00:00<00:00, 1715.00it/s, Materializing param=encoder.layer.7.attention.self.value.weLoading weights:  64%|▋| 127/199 [00:00<00:00, 1715.00it/s, Materializing param=encoder.layer.7.attention.self.value.weLoading weights:  64%|▋| 128/199 [00:00<00:00, 1728.50it/s, Materializing param=encoder.layer.7.intermediate.dense.biasLoading weights:  64%|▋| 128/199 [00:00<00:00, 1728.50it/s, Materializing param=encoder.layer.7.intermediate.dense.biasLoading weights:  65%|▋| 129/199 [00:00<00:00, 1742.01it/s, Materializing param=encoder.layer.7.intermediate.dense.weigLoading weights:  65%|▋| 129/199 [00:00<00:00, 1742.01it/s, Materializing param=encoder.layer.7.intermediate.dense.weigLoading weights:  65%|█▎| 130/199 [00:00<00:00, 1755.51it/s, Materializing param=encoder.layer.7.output.LayerNorm.bias]Loading weights:  65%|█▎| 130/199 [00:00<00:00, 1755.51it/s, Materializing param=encoder.layer.7.output.LayerNorm.bias]Loading weights:  66%|▋| 131/199 [00:00<00:00, 1769.01it/s, Materializing param=encoder.layer.7.output.LayerNorm.weightLoading weights:  66%|▋| 131/199 [00:00<00:00, 1769.01it/s, Materializing param=encoder.layer.7.output.LayerNorm.weightLoading weights:  66%|███▉  | 132/199 [00:00<00:00, 1782.52it/s, Materializing param=encoder.layer.7.output.dense.bias]Loading weights:  66%|███▉  | 132/199 [00:00<00:00, 1782.52it/s, Materializing param=encoder.layer.7.output.dense.bias]Loading weights:  67%|██▋ | 133/199 [00:00<00:00, 1796.02it/s, Materializing param=encoder.layer.7.output.dense.weight]Loading weights:  67%|██▋ | 133/199 [00:00<00:00, 1796.02it/s, Materializing param=encoder.layer.7.output.dense.weight]Loading weights:  67%|▋| 134/199 [00:00<00:00, 1809.53it/s, Materializing param=encoder.layer.8.attention.output.LayerNLoading weights:  67%|▋| 134/199 [00:00<00:00, 1809.53it/s, Materializing param=encoder.layer.8.attention.output.LayerNLoading weights:  68%|▋| 135/199 [00:00<00:00, 1823.03it/s, Materializing param=encoder.layer.8.attention.output.LayerNLoading weights:  68%|▋| 135/199 [00:00<00:00, 1823.03it/s, Materializing param=encoder.layer.8.attention.output.LayerNLoading weights:  68%|▋| 136/199 [00:00<00:00, 1836.53it/s, Materializing param=encoder.layer.8.attention.output.dense.Loading weights:  68%|▋| 136/199 [00:00<00:00, 1836.53it/s, Materializing param=encoder.layer.8.attention.output.dense.Loading weights:  69%|▋| 137/199 [00:00<00:00, 1850.04it/s, Materializing param=encoder.layer.8.attention.output.dense.Loading weights:  69%|▋| 137/199 [00:00<00:00, 1850.04it/s, Materializing param=encoder.layer.8.attention.output.dense.Loading weights:  69%|▋| 138/199 [00:00<00:00, 1863.54it/s, Materializing param=encoder.layer.8.attention.self.key.biasLoading weights:  69%|▋| 138/199 [00:00<00:00, 1863.54it/s, Materializing param=encoder.layer.8.attention.self.key.biasLoading weights:  70%|▋| 139/199 [00:00<00:00, 1877.04it/s, Materializing param=encoder.layer.8.attention.self.key.weigLoading weights:  70%|▋| 139/199 [00:00<00:00, 1877.04it/s, Materializing param=encoder.layer.8.attention.self.key.weigLoading weights:  70%|▋| 140/199 [00:00<00:00, 1766.31it/s, Materializing param=encoder.layer.8.attention.self.query.biLoading weights:  70%|▋| 140/199 [00:00<00:00, 1766.31it/s, Materializing param=encoder.layer.8.attention.self.query.biLoading weights:  71%|▋| 141/199 [00:00<00:00, 1778.93it/s, Materializing param=encoder.layer.8.attention.self.query.weLoading weights:  71%|▋| 141/199 [00:00<00:00, 1778.93it/s, Materializing param=encoder.layer.8.attention.self.query.weLoading weights:  71%|▋| 142/199 [00:00<00:00, 1791.54it/s, Materializing param=encoder.layer.8.attention.self.value.biLoading weights:  71%|▋| 142/199 [00:00<00:00, 1791.54it/s, Materializing param=encoder.layer.8.attention.self.value.biLoading weights:  72%|▋| 143/199 [00:00<00:00, 1804.16it/s, Materializing param=encoder.layer.8.attention.self.value.weLoading weights:  72%|▋| 143/199 [00:00<00:00, 1804.16it/s, Materializing param=encoder.layer.8.attention.self.value.weLoading weights:  72%|▋| 144/199 [00:00<00:00, 1816.78it/s, Materializing param=encoder.layer.8.intermediate.dense.biasLoading weights:  72%|▋| 144/199 [00:00<00:00, 1816.78it/s, Materializing param=encoder.layer.8.intermediate.dense.biasLoading weights:  73%|▋| 145/199 [00:00<00:00, 1829.39it/s, Materializing param=encoder.layer.8.intermediate.dense.weigLoading weights:  73%|▋| 145/199 [00:00<00:00, 1829.39it/s, Materializing param=encoder.layer.8.intermediate.dense.weigLoading weights:  73%|█▍| 146/199 [00:00<00:00, 1842.01it/s, Materializing param=encoder.layer.8.output.LayerNorm.bias]Loading weights:  73%|█▍| 146/199 [00:00<00:00, 1842.01it/s, Materializing param=encoder.layer.8.output.LayerNorm.bias]Loading weights:  74%|▋| 147/199 [00:00<00:00, 1854.63it/s, Materializing param=encoder.layer.8.output.LayerNorm.weightLoading weights:  74%|▋| 147/199 [00:00<00:00, 1854.63it/s, Materializing param=encoder.layer.8.output.LayerNorm.weightLoading weights:  74%|████▍ | 148/199 [00:00<00:00, 1867.24it/s, Materializing param=encoder.layer.8.output.dense.bias]Loading weights:  74%|████▍ | 148/199 [00:00<00:00, 1867.24it/s, Materializing param=encoder.layer.8.output.dense.bias]Loading weights:  75%|██▉ | 149/199 [00:00<00:00, 1879.86it/s, Materializing param=encoder.layer.8.output.dense.weight]Loading weights:  75%|██▉ | 149/199 [00:00<00:00, 1879.86it/s, Materializing param=encoder.layer.8.output.dense.weight]Loading weights:  75%|▊| 150/199 [00:00<00:00, 1892.47it/s, Materializing param=encoder.layer.9.attention.output.LayerNLoading weights:  75%|▊| 150/199 [00:00<00:00, 1892.47it/s, Materializing param=encoder.layer.9.attention.output.LayerNLoading weights:  76%|▊| 151/199 [00:00<00:00, 1905.09it/s, Materializing param=encoder.layer.9.attention.output.LayerNLoading weights:  76%|▊| 151/199 [00:00<00:00, 1905.09it/s, Materializing param=encoder.layer.9.attention.output.LayerNLoading weights:  76%|▊| 152/199 [00:00<00:00, 1917.71it/s, Materializing param=encoder.layer.9.attention.output.dense.Loading weights:  76%|▊| 152/199 [00:00<00:00, 1801.36it/s, Materializing param=encoder.layer.9.attention.output.dense.Loading weights:  77%|▊| 153/199 [00:00<00:00, 1813.21it/s, Materializing param=encoder.layer.9.attention.output.dense.Loading weights:  77%|▊| 153/199 [00:00<00:00, 1813.21it/s, Materializing param=encoder.layer.9.attention.output.dense.Loading weights:  77%|▊| 154/199 [00:00<00:00, 1825.06it/s, Materializing param=encoder.layer.9.attention.self.key.biasLoading weights:  77%|▊| 154/199 [00:00<00:00, 1825.06it/s, Materializing param=encoder.layer.9.attention.self.key.biasLoading weights:  78%|▊| 155/199 [00:00<00:00, 1836.91it/s, Materializing param=encoder.layer.9.attention.self.key.weigLoading weights:  78%|▊| 155/199 [00:00<00:00, 1836.91it/s, Materializing param=encoder.layer.9.attention.self.key.weigLoading weights:  78%|▊| 156/199 [00:00<00:00, 1848.76it/s, Materializing param=encoder.layer.9.attention.self.query.biLoading weights:  78%|▊| 156/199 [00:00<00:00, 1848.76it/s, Materializing param=encoder.layer.9.attention.self.query.biLoading weights:  79%|▊| 157/199 [00:00<00:00, 1860.61it/s, Materializing param=encoder.layer.9.attention.self.query.weLoading weights:  79%|▊| 157/199 [00:00<00:00, 1860.61it/s, Materializing param=encoder.layer.9.attention.self.query.weLoading weights:  79%|▊| 158/199 [00:00<00:00, 1872.46it/s, Materializing param=encoder.layer.9.attention.self.value.biLoading weights:  79%|▊| 158/199 [00:00<00:00, 1872.46it/s, Materializing param=encoder.layer.9.attention.self.value.biLoading weights:  80%|▊| 159/199 [00:00<00:00, 1884.31it/s, Materializing param=encoder.layer.9.attention.self.value.weLoading weights:  80%|▊| 159/199 [00:00<00:00, 1884.31it/s, Materializing param=encoder.layer.9.attention.self.value.weLoading weights:  80%|▊| 160/199 [00:00<00:00, 1896.16it/s, Materializing param=encoder.layer.9.intermediate.dense.biasLoading weights:  80%|▊| 160/199 [00:00<00:00, 1896.16it/s, Materializing param=encoder.layer.9.intermediate.dense.biasLoading weights:  81%|▊| 161/199 [00:00<00:00, 1908.02it/s, Materializing param=encoder.layer.9.intermediate.dense.weigLoading weights:  81%|▊| 161/199 [00:00<00:00, 1908.02it/s, Materializing param=encoder.layer.9.intermediate.dense.weigLoading weights:  81%|█▋| 162/199 [00:00<00:00, 1919.87it/s, Materializing param=encoder.layer.9.output.LayerNorm.bias]Loading weights:  81%|█▋| 162/199 [00:00<00:00, 1919.87it/s, Materializing param=encoder.layer.9.output.LayerNorm.bias]Loading weights:  82%|▊| 163/199 [00:00<00:00, 1931.72it/s, Materializing param=encoder.layer.9.output.LayerNorm.weightLoading weights:  82%|▊| 163/199 [00:00<00:00, 1931.72it/s, Materializing param=encoder.layer.9.output.LayerNorm.weightLoading weights:  82%|████▉ | 164/199 [00:00<00:00, 1943.57it/s, Materializing param=encoder.layer.9.output.dense.bias]Loading weights:  82%|████▉ | 164/199 [00:00<00:00, 1943.57it/s, Materializing param=encoder.layer.9.output.dense.bias]Loading weights:  83%|███▎| 165/199 [00:00<00:00, 1955.42it/s, Materializing param=encoder.layer.9.output.dense.weight]Loading weights:  83%|███▎| 165/199 [00:00<00:00, 1844.37it/s, Materializing param=encoder.layer.9.output.dense.weight]Loading weights:  83%|▊| 166/199 [00:00<00:00, 1855.55it/s, Materializing param=encoder.layer.10.attention.output.LayerLoading weights:  83%|▊| 166/199 [00:00<00:00, 1855.55it/s, Materializing param=encoder.layer.10.attention.output.LayerLoading weights:  84%|▊| 167/199 [00:00<00:00, 1866.72it/s, Materializing param=encoder.layer.10.attention.output.LayerLoading weights:  84%|▊| 167/199 [00:00<00:00, 1866.72it/s, Materializing param=encoder.layer.10.attention.output.LayerLoading weights:  84%|▊| 168/199 [00:00<00:00, 1877.90it/s, Materializing param=encoder.layer.10.attention.output.denseLoading weights:  84%|▊| 168/199 [00:00<00:00, 1877.90it/s, Materializing param=encoder.layer.10.attention.output.denseLoading weights:  85%|▊| 169/199 [00:00<00:00, 1889.08it/s, Materializing param=encoder.layer.10.attention.output.denseLoading weights:  85%|▊| 169/199 [00:00<00:00, 1889.08it/s, Materializing param=encoder.layer.10.attention.output.denseLoading weights:  85%|▊| 170/199 [00:00<00:00, 1900.26it/s, Materializing param=encoder.layer.10.attention.self.key.biaLoading weights:  85%|▊| 170/199 [00:00<00:00, 1900.26it/s, Materializing param=encoder.layer.10.attention.self.key.biaLoading weights:  86%|▊| 171/199 [00:00<00:00, 1911.44it/s, Materializing param=encoder.layer.10.attention.self.key.weiLoading weights:  86%|▊| 171/199 [00:00<00:00, 1911.44it/s, Materializing param=encoder.layer.10.attention.self.key.weiLoading weights:  86%|▊| 172/199 [00:00<00:00, 1922.61it/s, Materializing param=encoder.layer.10.attention.self.query.bLoading weights:  86%|▊| 172/199 [00:00<00:00, 1922.61it/s, Materializing param=encoder.layer.10.attention.self.query.bLoading weights:  87%|▊| 173/199 [00:00<00:00, 1933.79it/s, Materializing param=encoder.layer.10.attention.self.query.wLoading weights:  87%|▊| 173/199 [00:00<00:00, 1933.79it/s, Materializing param=encoder.layer.10.attention.self.query.wLoading weights:  87%|▊| 174/199 [00:00<00:00, 1944.97it/s, Materializing param=encoder.layer.10.attention.self.value.bLoading weights:  87%|▊| 174/199 [00:00<00:00, 1944.97it/s, Materializing param=encoder.layer.10.attention.self.value.bLoading weights:  88%|▉| 175/199 [00:00<00:00, 1956.15it/s, Materializing param=encoder.layer.10.attention.self.value.wLoading weights:  88%|▉| 175/199 [00:00<00:00, 1956.15it/s, Materializing param=encoder.layer.10.attention.self.value.wLoading weights:  88%|▉| 176/199 [00:00<00:00, 1967.33it/s, Materializing param=encoder.layer.10.intermediate.dense.biaLoading weights:  88%|▉| 176/199 [00:00<00:00, 1967.33it/s, Materializing param=encoder.layer.10.intermediate.dense.biaLoading weights:  89%|▉| 177/199 [00:00<00:00, 1978.50it/s, Materializing param=encoder.layer.10.intermediate.dense.weiLoading weights:  89%|▉| 177/199 [00:00<00:00, 1978.50it/s, Materializing param=encoder.layer.10.intermediate.dense.weiLoading weights:  89%|▉| 178/199 [00:00<00:00, 1989.68it/s, Materializing param=encoder.layer.10.output.LayerNorm.bias]Loading weights:  89%|▉| 178/199 [00:00<00:00, 1989.68it/s, Materializing param=encoder.layer.10.output.LayerNorm.bias]Loading weights:  90%|▉| 179/199 [00:00<00:00, 1892.86it/s, Materializing param=encoder.layer.10.output.LayerNorm.weighLoading weights:  90%|▉| 179/199 [00:00<00:00, 1892.86it/s, Materializing param=encoder.layer.10.output.LayerNorm.weighLoading weights:  90%|████▌| 180/199 [00:00<00:00, 1903.44it/s, Materializing param=encoder.layer.10.output.dense.bias]Loading weights:  90%|████▌| 180/199 [00:00<00:00, 1903.44it/s, Materializing param=encoder.layer.10.output.dense.bias]Loading weights:  91%|██▋| 181/199 [00:00<00:00, 1914.01it/s, Materializing param=encoder.layer.10.output.dense.weight]Loading weights:  91%|██▋| 181/199 [00:00<00:00, 1914.01it/s, Materializing param=encoder.layer.10.output.dense.weight]Loading weights:  91%|▉| 182/199 [00:00<00:00, 1924.58it/s, Materializing param=encoder.layer.11.attention.output.LayerLoading weights:  91%|▉| 182/199 [00:00<00:00, 1924.58it/s, Materializing param=encoder.layer.11.attention.output.LayerLoading weights:  92%|▉| 183/199 [00:00<00:00, 1935.16it/s, Materializing param=encoder.layer.11.attention.output.LayerLoading weights:  92%|▉| 183/199 [00:00<00:00, 1935.16it/s, Materializing param=encoder.layer.11.attention.output.LayerLoading weights:  92%|▉| 184/199 [00:00<00:00, 1945.73it/s, Materializing param=encoder.layer.11.attention.output.denseLoading weights:  92%|▉| 184/199 [00:00<00:00, 1945.73it/s, Materializing param=encoder.layer.11.attention.output.denseLoading weights:  93%|▉| 185/199 [00:00<00:00, 1956.31it/s, Materializing param=encoder.layer.11.attention.output.denseLoading weights:  93%|▉| 185/199 [00:00<00:00, 1956.31it/s, Materializing param=encoder.layer.11.attention.output.denseLoading weights:  93%|▉| 186/199 [00:00<00:00, 1966.88it/s, Materializing param=encoder.layer.11.attention.self.key.biaLoading weights:  93%|▉| 186/199 [00:00<00:00, 1966.88it/s, Materializing param=encoder.layer.11.attention.self.key.biaLoading weights:  94%|▉| 187/199 [00:00<00:00, 1977.46it/s, Materializing param=encoder.layer.11.attention.self.key.weiLoading weights:  94%|▉| 187/199 [00:00<00:00, 1977.46it/s, Materializing param=encoder.layer.11.attention.self.key.weiLoading weights:  94%|▉| 188/199 [00:00<00:00, 1988.03it/s, Materializing param=encoder.layer.11.attention.self.query.bLoading weights:  94%|▉| 188/199 [00:00<00:00, 1988.03it/s, Materializing param=encoder.layer.11.attention.self.query.bLoading weights:  95%|▉| 189/199 [00:00<00:00, 1998.61it/s, Materializing param=encoder.layer.11.attention.self.query.wLoading weights:  95%|▉| 189/199 [00:00<00:00, 1998.61it/s, Materializing param=encoder.layer.11.attention.self.query.wLoading weights:  95%|▉| 190/199 [00:00<00:00, 2009.18it/s, Materializing param=encoder.layer.11.attention.self.value.bLoading weights:  95%|▉| 190/199 [00:00<00:00, 2009.18it/s, Materializing param=encoder.layer.11.attention.self.value.bLoading weights:  96%|▉| 191/199 [00:00<00:00, 2019.76it/s, Materializing param=encoder.layer.11.attention.self.value.wLoading weights:  96%|▉| 191/199 [00:00<00:00, 2019.76it/s, Materializing param=encoder.layer.11.attention.self.value.wLoading weights:  96%|▉| 192/199 [00:00<00:00, 2030.33it/s, Materializing param=encoder.layer.11.intermediate.dense.biaLoading weights:  96%|▉| 192/199 [00:00<00:00, 1927.81it/s, Materializing param=encoder.layer.11.intermediate.dense.biaLoading weights:  97%|▉| 193/199 [00:00<00:00, 1937.85it/s, Materializing param=encoder.layer.11.intermediate.dense.weiLoading weights:  97%|▉| 193/199 [00:00<00:00, 1937.85it/s, Materializing param=encoder.layer.11.intermediate.dense.weiLoading weights:  97%|▉| 194/199 [00:00<00:00, 1947.89it/s, Materializing param=encoder.layer.11.output.LayerNorm.bias]Loading weights:  97%|▉| 194/199 [00:00<00:00, 1947.89it/s, Materializing param=encoder.layer.11.output.LayerNorm.bias]Loading weights:  98%|▉| 195/199 [00:00<00:00, 1957.93it/s, Materializing param=encoder.layer.11.output.LayerNorm.weighLoading weights:  98%|▉| 195/199 [00:00<00:00, 1957.93it/s, Materializing param=encoder.layer.11.output.LayerNorm.weighLoading weights:  98%|████▉| 196/199 [00:00<00:00, 1967.97it/s, Materializing param=encoder.layer.11.output.dense.bias]Loading weights:  98%|████▉| 196/199 [00:00<00:00, 1967.97it/s, Materializing param=encoder.layer.11.output.dense.bias]Loading weights:  99%|██▉| 197/199 [00:00<00:00, 1978.01it/s, Materializing param=encoder.layer.11.output.dense.weight]Loading weights:  99%|██▉| 197/199 [00:00<00:00, 1978.01it/s, Materializing param=encoder.layer.11.output.dense.weight]Loading weights:  99%|█████████████████████▉| 198/199 [00:00<00:00, 1988.05it/s, Materializing param=pooler.dense.bias]Loading weights:  99%|█████████████████████▉| 198/199 [00:00<00:00, 1988.05it/s, Materializing param=pooler.dense.bias]Loading weights: 100%|████████████████████| 199/199 [00:00<00:00, 1998.10it/s, Materializing param=pooler.dense.weight]Loading weights: 100%|████████████████████| 199/199 [00:00<00:00, 1998.10it/s, Materializing param=pooler.dense.weight]Loading weights: 100%|████████████████████| 199/199 [00:00<00:00, 1998.10it/s, Materializing param=pooler.dense.weight]
[1mBertModel LOAD REPORT[0m from: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
Key                     | Status     |  | 
------------------------+------------+--+-
embeddings.position_ids | [38;5;208mUNEXPECTED[0m |  | 

[3mNotes:
- [38;5;208mUNEXPECTED[0m[3m	:can be ignored when loading from different task/architecture; not ok if you expect identical arch.[0m

Loading perplexity model for 'en'...
  Loading perplexity model for 'en': gpt2 (device=cuda)
`torch_dtype` is deprecated! Use `dtype` instead!
Loading weights:   0%|                                                                         | 0/148 [00:00<?, ?it/s]Loading weights:   1%|▏                  | 1/148 [00:00<?, ?it/s, Materializing param=transformer.h.0.attn.c_attn.bias]Loading weights:   1%|▏                  | 1/148 [00:00<?, ?it/s, Materializing param=transformer.h.0.attn.c_attn.bias]Loading weights:   1%|        | 2/148 [00:00<00:00, 716.00it/s, Materializing param=transformer.h.0.attn.c_attn.weight]Loading weights:   1%|        | 2/148 [00:00<00:00, 716.00it/s, Materializing param=transformer.h.0.attn.c_attn.weight]Loading weights:   2%|▏        | 3/148 [00:00<00:00, 1073.99it/s, Materializing param=transformer.h.0.attn.c_proj.bias]Loading weights:   2%|▏        | 3/148 [00:00<00:00, 1073.99it/s, Materializing param=transformer.h.0.attn.c_proj.bias]Loading weights:   3%|▏       | 4/148 [00:00<00:00, 794.71it/s, Materializing param=transformer.h.0.attn.c_proj.weight]Loading weights:   3%|▏       | 4/148 [00:00<00:00, 794.71it/s, Materializing param=transformer.h.0.attn.c_proj.weight]Loading weights:   3%|▌                | 5/148 [00:00<00:00, 993.39it/s, Materializing param=transformer.h.0.ln_1.bias]Loading weights:   3%|▌                | 5/148 [00:00<00:00, 993.39it/s, Materializing param=transformer.h.0.ln_1.bias]Loading weights:   4%|▌             | 6/148 [00:00<00:00, 1192.07it/s, Materializing param=transformer.h.0.ln_1.weight]Loading weights:   4%|▌              | 6/148 [00:00<00:00, 852.15it/s, Materializing param=transformer.h.0.ln_1.weight]Loading weights:   5%|▊                | 7/148 [00:00<00:00, 994.18it/s, Materializing param=transformer.h.0.ln_2.bias]Loading weights:   5%|▊                | 7/148 [00:00<00:00, 994.18it/s, Materializing param=transformer.h.0.ln_2.bias]Loading weights:   5%|▊              | 8/148 [00:00<00:00, 884.13it/s, Materializing param=transformer.h.0.ln_2.weight]Loading weights:   5%|▊              | 8/148 [00:00<00:00, 795.77it/s, Materializing param=transformer.h.0.ln_2.weight]Loading weights:   6%|▊            | 9/148 [00:00<00:00, 895.24it/s, Materializing param=transformer.h.0.mlp.c_fc.bias]Loading weights:   6%|▊            | 9/148 [00:00<00:00, 895.24it/s, Materializing param=transformer.h.0.mlp.c_fc.bias]Loading weights:   7%|▋         | 10/148 [00:00<00:00, 829.42it/s, Materializing param=transformer.h.0.mlp.c_fc.weight]Loading weights:   7%|▋         | 10/148 [00:00<00:00, 829.42it/s, Materializing param=transformer.h.0.mlp.c_fc.weight]Loading weights:   7%|▋         | 11/148 [00:00<00:00, 912.36it/s, Materializing param=transformer.h.0.mlp.c_proj.bias]Loading weights:   7%|▋         | 11/148 [00:00<00:00, 912.36it/s, Materializing param=transformer.h.0.mlp.c_proj.bias]Loading weights:   8%|▋       | 12/148 [00:00<00:00, 796.27it/s, Materializing param=transformer.h.0.mlp.c_proj.weight]Loading weights:   8%|▋       | 12/148 [00:00<00:00, 796.27it/s, Materializing param=transformer.h.0.mlp.c_proj.weight]Loading weights:   9%|▊        | 13/148 [00:00<00:00, 761.30it/s, Materializing param=transformer.h.1.attn.c_attn.bias]Loading weights:   9%|▊        | 13/148 [00:00<00:00, 761.30it/s, Materializing param=transformer.h.1.attn.c_attn.bias]Loading weights:   9%|▋      | 14/148 [00:00<00:00, 819.86it/s, Materializing param=transformer.h.1.attn.c_attn.weight]Loading weights:   9%|▋      | 14/148 [00:00<00:00, 633.69it/s, Materializing param=transformer.h.1.attn.c_attn.weight]Loading weights:  10%|▉        | 15/148 [00:00<00:00, 678.95it/s, Materializing param=transformer.h.1.attn.c_proj.bias]Loading weights:  10%|▉        | 15/148 [00:00<00:00, 678.95it/s, Materializing param=transformer.h.1.attn.c_proj.bias]Loading weights:  11%|▊      | 16/148 [00:00<00:00, 663.98it/s, Materializing param=transformer.h.1.attn.c_proj.weight]Loading weights:  11%|▊      | 16/148 [00:00<00:00, 663.98it/s, Materializing param=transformer.h.1.attn.c_proj.weight]Loading weights:  11%|█▊              | 17/148 [00:00<00:00, 705.48it/s, Materializing param=transformer.h.1.ln_1.bias]Loading weights:  11%|█▊              | 17/148 [00:00<00:00, 677.24it/s, Materializing param=transformer.h.1.ln_1.bias]Loading weights:  12%|█▋            | 18/148 [00:00<00:00, 717.08it/s, Materializing param=transformer.h.1.ln_1.weight]Loading weights:  12%|█▋            | 18/148 [00:00<00:00, 664.04it/s, Materializing param=transformer.h.1.ln_1.weight]Loading weights:  13%|██              | 19/148 [00:00<00:00, 700.93it/s, Materializing param=transformer.h.1.ln_2.bias]Loading weights:  13%|██              | 19/148 [00:00<00:00, 700.93it/s, Materializing param=transformer.h.1.ln_2.bias]Loading weights:  14%|█▉            | 20/148 [00:00<00:00, 737.82it/s, Materializing param=transformer.h.1.ln_2.weight]Loading weights:  14%|█▉            | 20/148 [00:00<00:00, 737.82it/s, Materializing param=transformer.h.1.ln_2.weight]Loading weights:  14%|█▋          | 21/148 [00:00<00:00, 774.71it/s, Materializing param=transformer.h.1.mlp.c_fc.bias]Loading weights:  14%|█▋          | 21/148 [00:00<00:00, 774.71it/s, Materializing param=transformer.h.1.mlp.c_fc.bias]Loading weights:  15%|█▍        | 22/148 [00:00<00:00, 811.61it/s, Materializing param=transformer.h.1.mlp.c_fc.weight]Loading weights:  15%|█▍        | 22/148 [00:00<00:00, 811.61it/s, Materializing param=transformer.h.1.mlp.c_fc.weight]Loading weights:  16%|█▌        | 23/148 [00:00<00:00, 848.50it/s, Materializing param=transformer.h.1.mlp.c_proj.bias]Loading weights:  16%|█▌        | 23/148 [00:00<00:00, 848.50it/s, Materializing param=transformer.h.1.mlp.c_proj.bias]Loading weights:  16%|█▎      | 24/148 [00:00<00:00, 791.40it/s, Materializing param=transformer.h.1.mlp.c_proj.weight]Loading weights:  16%|█▎      | 24/148 [00:00<00:00, 791.40it/s, Materializing param=transformer.h.1.mlp.c_proj.weight]Loading weights:  17%|█▌       | 25/148 [00:00<00:00, 824.38it/s, Materializing param=transformer.h.2.attn.c_attn.bias]Loading weights:  17%|█▌       | 25/148 [00:00<00:00, 824.38it/s, Materializing param=transformer.h.2.attn.c_attn.bias]Loading weights:  18%|█▏     | 26/148 [00:00<00:00, 857.35it/s, Materializing param=transformer.h.2.attn.c_attn.weight]Loading weights:  18%|█▏     | 26/148 [00:00<00:00, 857.35it/s, Materializing param=transformer.h.2.attn.c_attn.weight]Loading weights:  18%|█▋       | 27/148 [00:00<00:00, 890.33it/s, Materializing param=transformer.h.2.attn.c_proj.bias]Loading weights:  18%|█▋       | 27/148 [00:00<00:00, 890.33it/s, Materializing param=transformer.h.2.attn.c_proj.bias]Loading weights:  19%|█▎     | 28/148 [00:00<00:00, 860.75it/s, Materializing param=transformer.h.2.attn.c_proj.weight]Loading weights:  19%|█▎     | 28/148 [00:00<00:00, 860.75it/s, Materializing param=transformer.h.2.attn.c_proj.weight]Loading weights:  20%|███▏            | 29/148 [00:00<00:00, 891.49it/s, Materializing param=transformer.h.2.ln_1.bias]Loading weights:  20%|███▏            | 29/148 [00:00<00:00, 891.49it/s, Materializing param=transformer.h.2.ln_1.bias]Loading weights:  20%|██▊           | 30/148 [00:00<00:00, 922.23it/s, Materializing param=transformer.h.2.ln_1.weight]Loading weights:  20%|██▊           | 30/148 [00:00<00:00, 922.23it/s, Materializing param=transformer.h.2.ln_1.weight]Loading weights:  21%|███▎            | 31/148 [00:00<00:00, 897.57it/s, Materializing param=transformer.h.2.ln_2.bias]Loading weights:  21%|███▎            | 31/148 [00:00<00:00, 872.11it/s, Materializing param=transformer.h.2.ln_2.bias]Loading weights:  22%|███           | 32/148 [00:00<00:00, 900.24it/s, Materializing param=transformer.h.2.ln_2.weight]Loading weights:  22%|███           | 32/148 [00:00<00:00, 900.24it/s, Materializing param=transformer.h.2.ln_2.weight]Loading weights:  22%|██▋         | 33/148 [00:00<00:00, 928.37it/s, Materializing param=transformer.h.2.mlp.c_fc.bias]Loading weights:  22%|██▋         | 33/148 [00:00<00:00, 878.77it/s, Materializing param=transformer.h.2.mlp.c_fc.bias]Loading weights:  23%|██▎       | 34/148 [00:00<00:00, 905.40it/s, Materializing param=transformer.h.2.mlp.c_fc.weight]Loading weights:  23%|██▎       | 34/148 [00:00<00:00, 905.40it/s, Materializing param=transformer.h.2.mlp.c_fc.weight]Loading weights:  24%|██▎       | 35/148 [00:00<00:00, 932.03it/s, Materializing param=transformer.h.2.mlp.c_proj.bias]Loading weights:  24%|██▎       | 35/148 [00:00<00:00, 932.03it/s, Materializing param=transformer.h.2.mlp.c_proj.bias]Loading weights:  24%|█▉      | 36/148 [00:00<00:00, 887.31it/s, Materializing param=transformer.h.2.mlp.c_proj.weight]Loading weights:  24%|█▉      | 36/148 [00:00<00:00, 887.31it/s, Materializing param=transformer.h.2.mlp.c_proj.weight]Loading weights:  25%|██▎      | 37/148 [00:00<00:00, 911.96it/s, Materializing param=transformer.h.3.attn.c_attn.bias]Loading weights:  25%|██▎      | 37/148 [00:00<00:00, 911.96it/s, Materializing param=transformer.h.3.attn.c_attn.bias]Loading weights:  26%|█▊     | 38/148 [00:00<00:00, 936.61it/s, Materializing param=transformer.h.3.attn.c_attn.weight]Loading weights:  26%|█▊     | 38/148 [00:00<00:00, 936.61it/s, Materializing param=transformer.h.3.attn.c_attn.weight]Loading weights:  26%|██▎      | 39/148 [00:00<00:00, 961.26it/s, Materializing param=transformer.h.3.attn.c_proj.bias]Loading weights:  26%|██▎      | 39/148 [00:00<00:00, 915.95it/s, Materializing param=transformer.h.3.attn.c_proj.bias]Loading weights:  27%|█▉     | 40/148 [00:00<00:00, 939.44it/s, Materializing param=transformer.h.3.attn.c_proj.weight]Loading weights:  27%|█▉     | 40/148 [00:00<00:00, 897.20it/s, Materializing param=transformer.h.3.attn.c_proj.weight]Loading weights:  28%|████▍           | 41/148 [00:00<00:00, 919.63it/s, Materializing param=transformer.h.3.ln_1.bias]Loading weights:  28%|████▍           | 41/148 [00:00<00:00, 899.37it/s, Materializing param=transformer.h.3.ln_1.bias]Loading weights:  28%|███▉          | 42/148 [00:00<00:00, 921.31it/s, Materializing param=transformer.h.3.ln_1.weight]Loading weights:  28%|███▉          | 42/148 [00:00<00:00, 921.31it/s, Materializing param=transformer.h.3.ln_1.weight]Loading weights:  29%|████▋           | 43/148 [00:00<00:00, 943.25it/s, Materializing param=transformer.h.3.ln_2.bias]Loading weights:  29%|████▋           | 43/148 [00:00<00:00, 943.25it/s, Materializing param=transformer.h.3.ln_2.bias]Loading weights:  30%|████▏         | 44/148 [00:00<00:00, 965.18it/s, Materializing param=transformer.h.3.ln_2.weight]Loading weights:  30%|████▏         | 44/148 [00:00<00:00, 965.18it/s, Materializing param=transformer.h.3.ln_2.weight]Loading weights:  30%|███▋        | 45/148 [00:00<00:00, 987.12it/s, Materializing param=transformer.h.3.mlp.c_fc.bias]Loading weights:  30%|███▋        | 45/148 [00:00<00:00, 987.12it/s, Materializing param=transformer.h.3.mlp.c_fc.bias]Loading weights:  31%|██▊      | 46/148 [00:00<00:00, 1009.05it/s, Materializing param=transformer.h.3.mlp.c_fc.weight]Loading weights:  31%|███       | 46/148 [00:00<00:00, 916.56it/s, Materializing param=transformer.h.3.mlp.c_fc.weight]Loading weights:  32%|███▏      | 47/148 [00:00<00:00, 936.48it/s, Materializing param=transformer.h.3.mlp.c_proj.bias]Loading weights:  32%|███▏      | 47/148 [00:00<00:00, 936.48it/s, Materializing param=transformer.h.3.mlp.c_proj.bias]Loading weights:  32%|██▌     | 48/148 [00:00<00:00, 956.41it/s, Materializing param=transformer.h.3.mlp.c_proj.weight]Loading weights:  32%|██▌     | 48/148 [00:00<00:00, 956.41it/s, Materializing param=transformer.h.3.mlp.c_proj.weight]Loading weights:  33%|██▉      | 49/148 [00:00<00:00, 976.33it/s, Materializing param=transformer.h.4.attn.c_attn.bias]Loading weights:  33%|██▉      | 49/148 [00:00<00:00, 976.33it/s, Materializing param=transformer.h.4.attn.c_attn.bias]Loading weights:  34%|██▎    | 50/148 [00:00<00:00, 996.26it/s, Materializing param=transformer.h.4.attn.c_attn.weight]Loading weights:  34%|██▎    | 50/148 [00:00<00:00, 996.26it/s, Materializing param=transformer.h.4.attn.c_attn.weight]Loading weights:  34%|██▊     | 51/148 [00:00<00:00, 1016.18it/s, Materializing param=transformer.h.4.attn.c_proj.bias]Loading weights:  34%|██▊     | 51/148 [00:00<00:00, 1016.18it/s, Materializing param=transformer.h.4.attn.c_proj.bias]Loading weights:  35%|██    | 52/148 [00:00<00:00, 1036.11it/s, Materializing param=transformer.h.4.attn.c_proj.weight]Loading weights:  35%|██    | 52/148 [00:00<00:00, 1036.11it/s, Materializing param=transformer.h.4.attn.c_proj.weight]Loading weights:  36%|█████▎         | 53/148 [00:00<00:00, 1056.03it/s, Materializing param=transformer.h.4.ln_1.bias]Loading weights:  36%|█████▎         | 53/148 [00:00<00:00, 1056.03it/s, Materializing param=transformer.h.4.ln_1.bias]Loading weights:  36%|████▋        | 54/148 [00:00<00:00, 1075.96it/s, Materializing param=transformer.h.4.ln_1.weight]Loading weights:  36%|████▋        | 54/148 [00:00<00:00, 1075.96it/s, Materializing param=transformer.h.4.ln_1.weight]Loading weights:  37%|█████▉          | 55/148 [00:00<00:00, 996.04it/s, Materializing param=transformer.h.4.ln_2.bias]Loading weights:  37%|█████▉          | 55/148 [00:00<00:00, 996.04it/s, Materializing param=transformer.h.4.ln_2.bias]Loading weights:  38%|████▉        | 56/148 [00:00<00:00, 1014.15it/s, Materializing param=transformer.h.4.ln_2.weight]Loading weights:  38%|████▉        | 56/148 [00:00<00:00, 1014.15it/s, Materializing param=transformer.h.4.ln_2.weight]Loading weights:  39%|████▏      | 57/148 [00:00<00:00, 1032.26it/s, Materializing param=transformer.h.4.mlp.c_fc.bias]Loading weights:  39%|████▏      | 57/148 [00:00<00:00, 1032.26it/s, Materializing param=transformer.h.4.mlp.c_fc.bias]Loading weights:  39%|███▌     | 58/148 [00:00<00:00, 1050.37it/s, Materializing param=transformer.h.4.mlp.c_fc.weight]Loading weights:  39%|███▌     | 58/148 [00:00<00:00, 1050.37it/s, Materializing param=transformer.h.4.mlp.c_fc.weight]Loading weights:  40%|███▌     | 59/148 [00:00<00:00, 1068.48it/s, Materializing param=transformer.h.4.mlp.c_proj.bias]Loading weights:  40%|███▌     | 59/148 [00:00<00:00, 1068.48it/s, Materializing param=transformer.h.4.mlp.c_proj.bias]Loading weights:  41%|██▊    | 60/148 [00:00<00:00, 1086.59it/s, Materializing param=transformer.h.4.mlp.c_proj.weight]Loading weights:  41%|██▊    | 60/148 [00:00<00:00, 1086.59it/s, Materializing param=transformer.h.4.mlp.c_proj.weight]Loading weights:  41%|███▎    | 61/148 [00:00<00:00, 1039.78it/s, Materializing param=transformer.h.5.attn.c_attn.bias]Loading weights:  41%|███▎    | 61/148 [00:00<00:00, 1039.78it/s, Materializing param=transformer.h.5.attn.c_attn.bias]Loading weights:  42%|██▌   | 62/148 [00:00<00:00, 1026.39it/s, Materializing param=transformer.h.5.attn.c_attn.weight]Loading weights:  42%|██▌   | 62/148 [00:00<00:00, 1026.39it/s, Materializing param=transformer.h.5.attn.c_attn.weight]Loading weights:  43%|███▍    | 63/148 [00:00<00:00, 1042.95it/s, Materializing param=transformer.h.5.attn.c_proj.bias]Loading weights:  43%|███▍    | 63/148 [00:00<00:00, 1042.95it/s, Materializing param=transformer.h.5.attn.c_proj.bias]Loading weights:  43%|██▌   | 64/148 [00:00<00:00, 1059.50it/s, Materializing param=transformer.h.5.attn.c_proj.weight]Loading weights:  43%|██▌   | 64/148 [00:00<00:00, 1059.50it/s, Materializing param=transformer.h.5.attn.c_proj.weight]Loading weights:  44%|██████▌        | 65/148 [00:00<00:00, 1076.06it/s, Materializing param=transformer.h.5.ln_1.bias]Loading weights:  44%|██████▌        | 65/148 [00:00<00:00, 1032.65it/s, Materializing param=transformer.h.5.ln_1.bias]Loading weights:  45%|█████▊       | 66/148 [00:00<00:00, 1048.54it/s, Materializing param=transformer.h.5.ln_1.weight]Loading weights:  45%|█████▊       | 66/148 [00:00<00:00, 1048.54it/s, Materializing param=transformer.h.5.ln_1.weight]Loading weights:  45%|██████▊        | 67/148 [00:00<00:00, 1064.43it/s, Materializing param=transformer.h.5.ln_2.bias]Loading weights:  45%|██████▊        | 67/148 [00:00<00:00, 1031.56it/s, Materializing param=transformer.h.5.ln_2.bias]Loading weights:  46%|█████▉       | 68/148 [00:00<00:00, 1046.96it/s, Materializing param=transformer.h.5.ln_2.weight]Loading weights:  46%|█████▉       | 68/148 [00:00<00:00, 1015.58it/s, Materializing param=transformer.h.5.ln_2.weight]Loading weights:  47%|█████▏     | 69/148 [00:00<00:00, 1030.52it/s, Materializing param=transformer.h.5.mlp.c_fc.bias]Loading weights:  47%|█████▏     | 69/148 [00:00<00:00, 1030.52it/s, Materializing param=transformer.h.5.mlp.c_fc.bias]Loading weights:  47%|████▎    | 70/148 [00:00<00:00, 1029.74it/s, Materializing param=transformer.h.5.mlp.c_fc.weight]Loading weights:  47%|████▎    | 70/148 [00:00<00:00, 1014.71it/s, Materializing param=transformer.h.5.mlp.c_fc.weight]Loading weights:  48%|████▎    | 71/148 [00:00<00:00, 1029.20it/s, Materializing param=transformer.h.5.mlp.c_proj.bias]Loading weights:  48%|████▎    | 71/148 [00:00<00:00, 1016.37it/s, Materializing param=transformer.h.5.mlp.c_proj.bias]Loading weights:  49%|███▍   | 72/148 [00:00<00:00, 1030.69it/s, Materializing param=transformer.h.5.mlp.c_proj.weight]Loading weights:  49%|███▍   | 72/148 [00:00<00:00, 1017.49it/s, Materializing param=transformer.h.5.mlp.c_proj.weight]Loading weights:  49%|███▉    | 73/148 [00:00<00:00, 1031.62it/s, Materializing param=transformer.h.6.attn.c_attn.bias]Loading weights:  49%|███▉    | 73/148 [00:00<00:00, 1031.62it/s, Materializing param=transformer.h.6.attn.c_attn.bias]Loading weights:  50%|███   | 74/148 [00:00<00:00, 1045.75it/s, Materializing param=transformer.h.6.attn.c_attn.weight]Loading weights:  50%|███   | 74/148 [00:00<00:00, 1045.75it/s, Materializing param=transformer.h.6.attn.c_attn.weight]Loading weights:  51%|████    | 75/148 [00:00<00:00, 1059.88it/s, Materializing param=transformer.h.6.attn.c_proj.bias]Loading weights:  51%|████    | 75/148 [00:00<00:00, 1059.88it/s, Materializing param=transformer.h.6.attn.c_proj.bias]Loading weights:  51%|███   | 76/148 [00:00<00:00, 1074.02it/s, Materializing param=transformer.h.6.attn.c_proj.weight]Loading weights:  51%|███   | 76/148 [00:00<00:00, 1026.75it/s, Materializing param=transformer.h.6.attn.c_proj.weight]Loading weights:  52%|███████▊       | 77/148 [00:00<00:00, 1040.26it/s, Materializing param=transformer.h.6.ln_1.bias]Loading weights:  52%|███████▊       | 77/148 [00:00<00:00, 1040.26it/s, Materializing param=transformer.h.6.ln_1.bias]Loading weights:  53%|██████▊      | 78/148 [00:00<00:00, 1039.62it/s, Materializing param=transformer.h.6.ln_1.weight]Loading weights:  53%|██████▊      | 78/148 [00:00<00:00, 1039.62it/s, Materializing param=transformer.h.6.ln_1.weight]Loading weights:  53%|████████       | 79/148 [00:00<00:00, 1052.95it/s, Materializing param=transformer.h.6.ln_2.bias]Loading weights:  53%|████████       | 79/148 [00:00<00:00, 1052.95it/s, Materializing param=transformer.h.6.ln_2.bias]Loading weights:  54%|███████      | 80/148 [00:00<00:00, 1066.28it/s, Materializing param=transformer.h.6.ln_2.weight]Loading weights:  54%|███████      | 80/148 [00:00<00:00, 1066.28it/s, Materializing param=transformer.h.6.ln_2.weight]Loading weights:  55%|██████     | 81/148 [00:00<00:00, 1079.61it/s, Materializing param=transformer.h.6.mlp.c_fc.bias]Loading weights:  55%|██████     | 81/148 [00:00<00:00, 1079.61it/s, Materializing param=transformer.h.6.mlp.c_fc.bias]Loading weights:  55%|████▉    | 82/148 [00:00<00:00, 1092.94it/s, Materializing param=transformer.h.6.mlp.c_fc.weight]Loading weights:  55%|████▉    | 82/148 [00:00<00:00, 1054.11it/s, Materializing param=transformer.h.6.mlp.c_fc.weight]Loading weights:  56%|█████    | 83/148 [00:00<00:00, 1066.97it/s, Materializing param=transformer.h.6.mlp.c_proj.bias]Loading weights:  56%|█████    | 83/148 [00:00<00:00, 1066.97it/s, Materializing param=transformer.h.6.mlp.c_proj.bias]Loading weights:  57%|███▉   | 84/148 [00:00<00:00, 1079.82it/s, Materializing param=transformer.h.6.mlp.c_proj.weight]Loading weights:  57%|███▉   | 84/148 [00:00<00:00, 1079.82it/s, Materializing param=transformer.h.6.mlp.c_proj.weight]Loading weights:  57%|████▌   | 85/148 [00:00<00:00, 1065.22it/s, Materializing param=transformer.h.7.attn.c_attn.bias]Loading weights:  57%|████▌   | 85/148 [00:00<00:00, 1060.88it/s, Materializing param=transformer.h.7.attn.c_attn.bias]Loading weights:  58%|███▍  | 86/148 [00:00<00:00, 1073.36it/s, Materializing param=transformer.h.7.attn.c_attn.weight]Loading weights:  58%|███▍  | 86/148 [00:00<00:00, 1060.06it/s, Materializing param=transformer.h.7.attn.c_attn.weight]Loading weights:  59%|████▋   | 87/148 [00:00<00:00, 1072.38it/s, Materializing param=transformer.h.7.attn.c_proj.bias]Loading weights:  59%|████▋   | 87/148 [00:00<00:00, 1072.38it/s, Materializing param=transformer.h.7.attn.c_proj.bias]Loading weights:  59%|███▌  | 88/148 [00:00<00:00, 1084.71it/s, Materializing param=transformer.h.7.attn.c_proj.weight]Loading weights:  59%|███▌  | 88/148 [00:00<00:00, 1051.81it/s, Materializing param=transformer.h.7.attn.c_proj.weight]Loading weights:  60%|█████████      | 89/148 [00:00<00:00, 1063.76it/s, Materializing param=transformer.h.7.ln_1.bias]Loading weights:  60%|█████████      | 89/148 [00:00<00:00, 1063.76it/s, Materializing param=transformer.h.7.ln_1.bias]Loading weights:  61%|███████▉     | 90/148 [00:00<00:00, 1075.71it/s, Materializing param=transformer.h.7.ln_1.weight]Loading weights:  61%|███████▉     | 90/148 [00:00<00:00, 1075.71it/s, Materializing param=transformer.h.7.ln_1.weight]Loading weights:  61%|█████████▏     | 91/148 [00:00<00:00, 1062.22it/s, Materializing param=transformer.h.7.ln_2.bias]Loading weights:  61%|█████████▏     | 91/148 [00:00<00:00, 1056.90it/s, Materializing param=transformer.h.7.ln_2.bias]Loading weights:  62%|████████     | 92/148 [00:00<00:00, 1057.55it/s, Materializing param=transformer.h.7.ln_2.weight]Loading weights:  62%|████████     | 92/148 [00:00<00:00, 1057.55it/s, Materializing param=transformer.h.7.ln_2.weight]Loading weights:  63%|██████▉    | 93/148 [00:00<00:00, 1069.04it/s, Materializing param=transformer.h.7.mlp.c_fc.bias]Loading weights:  63%|██████▉    | 93/148 [00:00<00:00, 1069.04it/s, Materializing param=transformer.h.7.mlp.c_fc.bias]Loading weights:  64%|█████▋   | 94/148 [00:00<00:00, 1080.54it/s, Materializing param=transformer.h.7.mlp.c_fc.weight]Loading weights:  64%|█████▋   | 94/148 [00:00<00:00, 1080.54it/s, Materializing param=transformer.h.7.mlp.c_fc.weight]Loading weights:  64%|█████▊   | 95/148 [00:00<00:00, 1092.03it/s, Materializing param=transformer.h.7.mlp.c_proj.bias]Loading weights:  64%|█████▊   | 95/148 [00:00<00:00, 1092.03it/s, Materializing param=transformer.h.7.mlp.c_proj.bias]Loading weights:  65%|████▌  | 96/148 [00:00<00:00, 1103.53it/s, Materializing param=transformer.h.7.mlp.c_proj.weight]Loading weights:  65%|████▌  | 96/148 [00:00<00:00, 1103.53it/s, Materializing param=transformer.h.7.mlp.c_proj.weight]Loading weights:  66%|█████▏  | 97/148 [00:00<00:00, 1115.02it/s, Materializing param=transformer.h.8.attn.c_attn.bias]Loading weights:  66%|█████▏  | 97/148 [00:00<00:00, 1115.02it/s, Materializing param=transformer.h.8.attn.c_attn.bias]Loading weights:  66%|███▉  | 98/148 [00:00<00:00, 1126.52it/s, Materializing param=transformer.h.8.attn.c_attn.weight]Loading weights:  66%|███▉  | 98/148 [00:00<00:00, 1126.52it/s, Materializing param=transformer.h.8.attn.c_attn.weight]Loading weights:  67%|█████▎  | 99/148 [00:00<00:00, 1138.01it/s, Materializing param=transformer.h.8.attn.c_proj.bias]Loading weights:  67%|█████▎  | 99/148 [00:00<00:00, 1138.01it/s, Materializing param=transformer.h.8.attn.c_proj.bias]Loading weights:  68%|███▍ | 100/148 [00:00<00:00, 1084.85it/s, Materializing param=transformer.h.8.attn.c_proj.weight]Loading weights:  68%|███▍ | 100/148 [00:00<00:00, 1073.12it/s, Materializing param=transformer.h.8.attn.c_proj.weight]Loading weights:  68%|█████████▌    | 101/148 [00:00<00:00, 1083.85it/s, Materializing param=transformer.h.8.ln_1.bias]Loading weights:  68%|█████████▌    | 101/148 [00:00<00:00, 1083.85it/s, Materializing param=transformer.h.8.ln_1.bias]Loading weights:  69%|████████▎   | 102/148 [00:00<00:00, 1070.83it/s, Materializing param=transformer.h.8.ln_1.weight]Loading weights:  69%|████████▎   | 102/148 [00:00<00:00, 1070.83it/s, Materializing param=transformer.h.8.ln_1.weight]Loading weights:  70%|█████████▋    | 103/148 [00:00<00:00, 1059.04it/s, Materializing param=transformer.h.8.ln_2.bias]Loading weights:  70%|█████████▋    | 103/148 [00:00<00:00, 1059.04it/s, Materializing param=transformer.h.8.ln_2.bias]Loading weights:  70%|████████▍   | 104/148 [00:00<00:00, 1058.66it/s, Materializing param=transformer.h.8.ln_2.weight]Loading weights:  70%|████████▍   | 104/148 [00:00<00:00, 1058.66it/s, Materializing param=transformer.h.8.ln_2.weight]Loading weights:  71%|███████   | 105/148 [00:00<00:00, 1058.49it/s, Materializing param=transformer.h.8.mlp.c_fc.bias]Loading weights:  71%|███████   | 105/148 [00:00<00:00, 1058.49it/s, Materializing param=transformer.h.8.mlp.c_fc.bias]Loading weights:  72%|█████▋  | 106/148 [00:00<00:00, 1068.57it/s, Materializing param=transformer.h.8.mlp.c_fc.weight]Loading weights:  72%|█████▋  | 106/148 [00:00<00:00, 1068.57it/s, Materializing param=transformer.h.8.mlp.c_fc.weight]Loading weights:  72%|█████▊  | 107/148 [00:00<00:00, 1078.65it/s, Materializing param=transformer.h.8.mlp.c_proj.bias]Loading weights:  72%|█████▊  | 107/148 [00:00<00:00, 1078.65it/s, Materializing param=transformer.h.8.mlp.c_proj.bias]Loading weights:  73%|████▍ | 108/148 [00:00<00:00, 1088.74it/s, Materializing param=transformer.h.8.mlp.c_proj.weight]Loading weights:  73%|████▍ | 108/148 [00:00<00:00, 1088.74it/s, Materializing param=transformer.h.8.mlp.c_proj.weight]Loading weights:  74%|█████▏ | 109/148 [00:00<00:00, 1098.82it/s, Materializing param=transformer.h.9.attn.c_attn.bias]Loading weights:  74%|█████▏ | 109/148 [00:00<00:00, 1098.82it/s, Materializing param=transformer.h.9.attn.c_attn.bias]Loading weights:  74%|███▋ | 110/148 [00:00<00:00, 1108.90it/s, Materializing param=transformer.h.9.attn.c_attn.weight]Loading weights:  74%|███▋ | 110/148 [00:00<00:00, 1108.90it/s, Materializing param=transformer.h.9.attn.c_attn.weight]Loading weights:  75%|█████▎ | 111/148 [00:00<00:00, 1118.98it/s, Materializing param=transformer.h.9.attn.c_proj.bias]Loading weights:  75%|█████▎ | 111/148 [00:00<00:00, 1118.98it/s, Materializing param=transformer.h.9.attn.c_proj.bias]Loading weights:  76%|███▊ | 112/148 [00:00<00:00, 1129.06it/s, Materializing param=transformer.h.9.attn.c_proj.weight]Loading weights:  76%|███▊ | 112/148 [00:00<00:00, 1129.06it/s, Materializing param=transformer.h.9.attn.c_proj.weight]Loading weights:  76%|██████████▋   | 113/148 [00:00<00:00, 1139.14it/s, Materializing param=transformer.h.9.ln_1.bias]Loading weights:  76%|██████████▋   | 113/148 [00:00<00:00, 1083.59it/s, Materializing param=transformer.h.9.ln_1.bias]Loading weights:  77%|██████████▊   | 114/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.9.ln_1.bias]Loading weights:  77%|█████████▏  | 114/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.9.ln_1.weight]Loading weights:  77%|█████████▏  | 114/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.9.ln_1.weight]Loading weights:  78%|██████████▉   | 115/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.9.ln_2.bias]Loading weights:  78%|██████████▉   | 115/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.9.ln_2.bias]Loading weights:  78%|█████████▍  | 116/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.9.ln_2.weight]Loading weights:  78%|█████████▍  | 116/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.9.ln_2.weight]Loading weights:  79%|███████▉  | 117/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.9.mlp.c_fc.bias]Loading weights:  79%|███████▉  | 117/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.9.mlp.c_fc.bias]Loading weights:  80%|██████▍ | 118/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.9.mlp.c_fc.weight]Loading weights:  80%|██████▍ | 118/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.9.mlp.c_fc.weight]Loading weights:  80%|██████▍ | 119/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.9.mlp.c_proj.bias]Loading weights:  80%|██████▍ | 119/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.9.mlp.c_proj.bias]Loading weights:  81%|████▊ | 120/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.9.mlp.c_proj.weight]Loading weights:  81%|████▊ | 120/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.9.mlp.c_proj.weight]Loading weights:  82%|████▉ | 121/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.10.attn.c_attn.bias]Loading weights:  82%|████▉ | 121/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.10.attn.c_attn.bias]Loading weights:  82%|███▎| 122/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.10.attn.c_attn.weight]Loading weights:  82%|███▎| 122/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.10.attn.c_attn.weight]Loading weights:  83%|████▉ | 123/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.10.attn.c_proj.bias]Loading weights:  83%|████▉ | 123/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.10.attn.c_proj.bias]Loading weights:  84%|███▎| 124/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.10.attn.c_proj.weight]Loading weights:  84%|███▎| 124/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.10.attn.c_proj.weight]Loading weights:  84%|██████████▉  | 125/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.10.ln_1.bias]Loading weights:  84%|██████████▉  | 125/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.10.ln_1.bias]Loading weights:  85%|█████████▎ | 126/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.10.ln_1.weight]Loading weights:  85%|█████████▎ | 126/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.10.ln_1.weight]Loading weights:  86%|███████████▏ | 127/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.10.ln_2.bias]Loading weights:  86%|███████████▏ | 127/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.10.ln_2.bias]Loading weights:  86%|█████████▌ | 128/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.10.ln_2.weight]Loading weights:  86%|█████████▌ | 128/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.10.ln_2.weight]Loading weights:  87%|███████▊ | 129/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.10.mlp.c_fc.bias]Loading weights:  87%|███████▊ | 129/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.10.mlp.c_fc.bias]Loading weights:  88%|██████▏| 130/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.10.mlp.c_fc.weight]Loading weights:  88%|██████▏| 130/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.10.mlp.c_fc.weight]Loading weights:  89%|██████▏| 131/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.10.mlp.c_proj.bias]Loading weights:  89%|██████▏| 131/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.10.mlp.c_proj.bias]Loading weights:  89%|████▍| 132/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.10.mlp.c_proj.weight]Loading weights:  89%|████▍| 132/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.10.mlp.c_proj.weight]Loading weights:  90%|█████▍| 133/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.11.attn.c_attn.bias]Loading weights:  90%|█████▍| 133/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.11.attn.c_attn.bias]Loading weights:  91%|███▌| 134/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.11.attn.c_attn.weight]Loading weights:  91%|███▌| 134/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.11.attn.c_attn.weight]Loading weights:  91%|█████▍| 135/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.11.attn.c_proj.bias]Loading weights:  91%|█████▍| 135/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.11.attn.c_proj.bias]Loading weights:  92%|███▋| 136/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.11.attn.c_proj.weight]Loading weights:  92%|███▋| 136/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.11.attn.c_proj.weight]Loading weights:  93%|████████████ | 137/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.11.ln_1.bias]Loading weights:  93%|████████████ | 137/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.11.ln_1.bias]Loading weights:  93%|██████████▎| 138/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.11.ln_1.weight]Loading weights:  93%|██████████▎| 138/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.11.ln_1.weight]Loading weights:  94%|████████████▏| 139/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.11.ln_2.bias]Loading weights:  94%|████████████▏| 139/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.11.ln_2.bias]Loading weights:  95%|██████████▍| 140/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.11.ln_2.weight]Loading weights:  95%|██████████▍| 140/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.11.ln_2.weight]Loading weights:  95%|████████▌| 141/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.11.mlp.c_fc.bias]Loading weights:  95%|████████▌| 141/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.11.mlp.c_fc.bias]Loading weights:  96%|██████▋| 142/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.11.mlp.c_fc.weight]Loading weights:  96%|██████▋| 142/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.11.mlp.c_fc.weight]Loading weights:  97%|██████▊| 143/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.11.mlp.c_proj.bias]Loading weights:  97%|██████▊| 143/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.11.mlp.c_proj.bias]Loading weights:  97%|████▊| 144/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.11.mlp.c_proj.weight]Loading weights:  97%|████▊| 144/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.h.11.mlp.c_proj.weight]Loading weights:  98%|█████████████████▋| 145/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.ln_f.bias]Loading weights:  98%|█████████████████▋| 145/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.ln_f.bias]Loading weights:  99%|███████████████▊| 146/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.ln_f.weight]Loading weights:  99%|███████████████▊| 146/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.ln_f.weight]Loading weights:  99%|████████████████▉| 147/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.wpe.weight]Loading weights:  99%|████████████████▉| 147/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.wpe.weight]Loading weights: 100%|█████████████████| 148/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.wte.weight]Loading weights: 100%|█████████████████| 148/148 [00:00<00:00, 1093.18it/s, Materializing param=transformer.wte.weight]Loading weights: 100%|██████████████████| 148/148 [00:00<00:00, 702.36it/s, Materializing param=transformer.wte.weight]
[1mGPT2LMHeadModel LOAD REPORT[0m from: gpt2
Key                  | Status     |  | 
---------------------+------------+--+-
h.{0...11}.attn.bias | [38;5;208mUNEXPECTED[0m |  | 

[3mNotes:
- [38;5;208mUNEXPECTED[0m[3m	:can be ignored when loading from different task/architecture; not ok if you expect identical arch.[0m

Loading perplexity model for 'fr'...
  Loading perplexity model for 'fr': bigscience/bloom-560m (device=cuda)
Loading weights:   0%|                                                                         | 0/293 [00:00<?, ?it/s]Loading weights:   0%|      | 1/293 [00:00<00:00, 498.61it/s, Materializing param=transformer.h.0.input_layernorm.bias]Loading weights:   0%|      | 1/293 [00:00<00:01, 249.35it/s, Materializing param=transformer.h.0.input_layernorm.bias]Loading weights:   1%|    | 2/293 [00:00<00:00, 398.75it/s, Materializing param=transformer.h.0.input_layernorm.weight]Loading weights:   1%|    | 2/293 [00:00<00:00, 398.75it/s, Materializing param=transformer.h.0.input_layernorm.weight]Loading weights:   1%|    | 3/293 [00:00<00:00, 332.37it/s, Materializing param=transformer.h.0.mlp.dense_4h_to_h.bias]Loading weights:   1%|    | 3/293 [00:00<00:00, 299.02it/s, Materializing param=transformer.h.0.mlp.dense_4h_to_h.bias]Loading weights:   1%|  | 4/293 [00:00<00:00, 398.70it/s, Materializing param=transformer.h.0.mlp.dense_4h_to_h.weight]Loading weights:   1%|  | 4/293 [00:00<00:00, 332.31it/s, Materializing param=transformer.h.0.mlp.dense_4h_to_h.weight]Loading weights:   2%|    | 5/293 [00:00<00:00, 332.32it/s, Materializing param=transformer.h.0.mlp.dense_h_to_4h.bias]Loading weights:   2%|    | 5/293 [00:00<00:00, 293.25it/s, Materializing param=transformer.h.0.mlp.dense_h_to_4h.bias]Loading weights:   2%|  | 6/293 [00:00<00:00, 314.88it/s, Materializing param=transformer.h.0.mlp.dense_h_to_4h.weight]Loading weights:   2%|  | 6/293 [00:00<00:00, 314.88it/s, Materializing param=transformer.h.0.mlp.dense_h_to_4h.weight]Loading weights:   2%| | 7/293 [00:00<00:00, 348.97it/s, Materializing param=transformer.h.0.post_attention_layernorm.bLoading weights:   2%| | 7/293 [00:00<00:00, 317.27it/s, Materializing param=transformer.h.0.post_attention_layernorm.bLoading weights:   3%| | 8/293 [00:00<00:00, 362.59it/s, Materializing param=transformer.h.0.post_attention_layernorm.wLoading weights:   3%| | 8/293 [00:00<00:00, 332.39it/s, Materializing param=transformer.h.0.post_attention_layernorm.wLoading weights:   3%| | 9/293 [00:00<00:00, 358.94it/s, Materializing param=transformer.h.0.self_attention.dense.bias]Loading weights:   3%| | 9/293 [00:00<00:00, 358.94it/s, Materializing param=transformer.h.0.self_attention.dense.bias]Loading weights:   3%| | 10/293 [00:00<00:00, 343.86it/s, Materializing param=transformer.h.0.self_attention.dense.weigLoading weights:   3%| | 10/293 [00:00<00:00, 332.38it/s, Materializing param=transformer.h.0.self_attention.dense.weigLoading weights:   4%| | 11/293 [00:00<00:00, 342.78it/s, Materializing param=transformer.h.0.self_attention.query_key_Loading weights:   4%| | 11/293 [00:00<00:00, 313.41it/s, Materializing param=transformer.h.0.self_attention.query_key_Loading weights:   4%| | 12/293 [00:00<00:00, 341.90it/s, Materializing param=transformer.h.0.self_attention.query_key_Loading weights:   4%| | 12/293 [00:00<00:00, 341.90it/s, Materializing param=transformer.h.0.self_attention.query_key_Loading weights:   4%|▏    | 13/293 [00:00<00:00, 350.38it/s, Materializing param=transformer.h.1.input_layernorm.bias]Loading weights:   4%|▏    | 13/293 [00:00<00:00, 332.42it/s, Materializing param=transformer.h.1.input_layernorm.bias]Loading weights:   5%|▏  | 14/293 [00:00<00:00, 357.99it/s, Materializing param=transformer.h.1.input_layernorm.weight]Loading weights:   5%|▏  | 14/293 [00:00<00:00, 349.02it/s, Materializing param=transformer.h.1.input_layernorm.weight]Loading weights:   5%|▏  | 15/293 [00:00<00:00, 356.16it/s, Materializing param=transformer.h.1.mlp.dense_4h_to_h.bias]Loading weights:   5%|▏  | 15/293 [00:00<00:00, 356.16it/s, Materializing param=transformer.h.1.mlp.dense_4h_to_h.bias]Loading weights:   5%| | 16/293 [00:00<00:00, 362.64it/s, Materializing param=transformer.h.1.mlp.dense_4h_to_h.weight]Loading weights:   5%| | 16/293 [00:00<00:00, 354.56it/s, Materializing param=transformer.h.1.mlp.dense_4h_to_h.weight]Loading weights:   6%|▏  | 17/293 [00:00<00:00, 376.72it/s, Materializing param=transformer.h.1.mlp.dense_h_to_4h.bias]Loading weights:   6%|▏  | 17/293 [00:00<00:00, 360.69it/s, Materializing param=transformer.h.1.mlp.dense_h_to_4h.bias]Loading weights:   6%| | 18/293 [00:00<00:00, 366.33it/s, Materializing param=transformer.h.1.mlp.dense_h_to_4h.weight]Loading weights:   6%| | 18/293 [00:00<00:00, 358.99it/s, Materializing param=transformer.h.1.mlp.dense_h_to_4h.weight]Loading weights:   6%| | 19/293 [00:00<00:00, 378.93it/s, Materializing param=transformer.h.1.post_attention_layernorm.Loading weights:   6%| | 19/293 [00:00<00:00, 364.36it/s, Materializing param=transformer.h.1.post_attention_layernorm.Loading weights:   7%| | 20/293 [00:00<00:00, 383.54it/s, Materializing param=transformer.h.1.post_attention_layernorm.Loading weights:   7%| | 20/293 [00:00<00:00, 383.54it/s, Materializing param=transformer.h.1.post_attention_layernorm.Loading weights:   7%| | 21/293 [00:00<00:00, 378.29it/s, Materializing param=transformer.h.1.self_attention.dense.biasLoading weights:   7%| | 21/293 [00:00<00:00, 378.29it/s, Materializing param=transformer.h.1.self_attention.dense.biasLoading weights:   8%| | 22/293 [00:00<00:00, 382.49it/s, Materializing param=transformer.h.1.self_attention.dense.weigLoading weights:   8%| | 22/293 [00:00<00:00, 382.49it/s, Materializing param=transformer.h.1.self_attention.dense.weigLoading weights:   8%| | 23/293 [00:00<00:00, 399.87it/s, Materializing param=transformer.h.1.self_attention.query_key_Loading weights:   8%| | 23/293 [00:00<00:00, 380.00it/s, Materializing param=transformer.h.1.self_attention.query_key_Loading weights:   8%| | 24/293 [00:00<00:00, 396.52it/s, Materializing param=transformer.h.1.self_attention.query_key_Loading weights:   8%| | 24/293 [00:00<00:00, 383.81it/s, Materializing param=transformer.h.1.self_attention.query_key_Loading weights:   9%|▍    | 25/293 [00:00<00:00, 399.80it/s, Materializing param=transformer.h.2.input_layernorm.bias]Loading weights:   9%|▍    | 25/293 [00:00<00:00, 399.80it/s, Materializing param=transformer.h.2.input_layernorm.bias]Loading weights:   9%|▎  | 26/293 [00:00<00:00, 415.79it/s, Materializing param=transformer.h.2.input_layernorm.weight]Loading weights:   9%|▎  | 26/293 [00:00<00:00, 402.87it/s, Materializing param=transformer.h.2.input_layernorm.weight]Loading weights:   9%|▎  | 27/293 [00:00<00:00, 418.37it/s, Materializing param=transformer.h.2.mlp.dense_4h_to_h.bias]Loading weights:   9%|▎  | 27/293 [00:00<00:00, 418.37it/s, Materializing param=transformer.h.2.mlp.dense_4h_to_h.bias]Loading weights:  10%| | 28/293 [00:00<00:00, 433.86it/s, Materializing param=transformer.h.2.mlp.dense_4h_to_h.weight]Loading weights:  10%| | 28/293 [00:00<00:00, 433.86it/s, Materializing param=transformer.h.2.mlp.dense_4h_to_h.weight]Loading weights:  10%|▎  | 29/293 [00:00<00:00, 442.47it/s, Materializing param=transformer.h.2.mlp.dense_h_to_4h.bias]Loading weights:  10%|▎  | 29/293 [00:00<00:00, 442.47it/s, Materializing param=transformer.h.2.mlp.dense_h_to_4h.bias]Loading weights:  10%| | 30/293 [00:00<00:00, 457.73it/s, Materializing param=transformer.h.2.mlp.dense_h_to_4h.weight]Loading weights:  10%| | 30/293 [00:00<00:00, 457.73it/s, Materializing param=transformer.h.2.mlp.dense_h_to_4h.weight]Loading weights:  11%| | 31/293 [00:00<00:00, 472.99it/s, Materializing param=transformer.h.2.post_attention_layernorm.Loading weights:  11%| | 31/293 [00:00<00:00, 472.99it/s, Materializing param=transformer.h.2.post_attention_layernorm.Loading weights:  11%| | 32/293 [00:00<00:00, 488.25it/s, Materializing param=transformer.h.2.post_attention_layernorm.Loading weights:  11%| | 32/293 [00:00<00:00, 488.25it/s, Materializing param=transformer.h.2.post_attention_layernorm.Loading weights:  11%| | 33/293 [00:00<00:00, 503.50it/s, Materializing param=transformer.h.2.self_attention.dense.biasLoading weights:  11%| | 33/293 [00:00<00:00, 503.50it/s, Materializing param=transformer.h.2.self_attention.dense.biasLoading weights:  12%| | 34/293 [00:00<00:00, 503.37it/s, Materializing param=transformer.h.2.self_attention.dense.weigLoading weights:  12%| | 34/293 [00:00<00:00, 503.37it/s, Materializing param=transformer.h.2.self_attention.dense.weigLoading weights:  12%| | 35/293 [00:00<00:00, 518.17it/s, Materializing param=transformer.h.2.self_attention.query_key_Loading weights:  12%| | 35/293 [00:00<00:00, 518.17it/s, Materializing param=transformer.h.2.self_attention.query_key_Loading weights:  12%| | 36/293 [00:00<00:00, 532.97it/s, Materializing param=transformer.h.2.self_attention.query_key_Loading weights:  12%| | 36/293 [00:00<00:00, 532.97it/s, Materializing param=transformer.h.2.self_attention.query_key_Loading weights:  13%|▋    | 37/293 [00:00<00:00, 547.78it/s, Materializing param=transformer.h.3.input_layernorm.bias]Loading weights:  13%|▋    | 37/293 [00:00<00:00, 547.78it/s, Materializing param=transformer.h.3.input_layernorm.bias]Loading weights:  13%|▍  | 38/293 [00:00<00:00, 562.58it/s, Materializing param=transformer.h.3.input_layernorm.weight]Loading weights:  13%|▍  | 38/293 [00:00<00:00, 562.58it/s, Materializing param=transformer.h.3.input_layernorm.weight]Loading weights:  13%|▍  | 39/293 [00:00<00:00, 560.74it/s, Materializing param=transformer.h.3.mlp.dense_4h_to_h.bias]Loading weights:  13%|▍  | 39/293 [00:00<00:00, 560.74it/s, Materializing param=transformer.h.3.mlp.dense_4h_to_h.bias]Loading weights:  14%|▏| 40/293 [00:00<00:00, 575.12it/s, Materializing param=transformer.h.3.mlp.dense_4h_to_h.weight]Loading weights:  14%|▏| 40/293 [00:00<00:00, 575.12it/s, Materializing param=transformer.h.3.mlp.dense_4h_to_h.weight]Loading weights:  14%|▍  | 41/293 [00:00<00:00, 589.50it/s, Materializing param=transformer.h.3.mlp.dense_h_to_4h.bias]Loading weights:  14%|▍  | 41/293 [00:00<00:00, 581.10it/s, Materializing param=transformer.h.3.mlp.dense_h_to_4h.bias]Loading weights:  14%|▏| 42/293 [00:00<00:00, 595.27it/s, Materializing param=transformer.h.3.mlp.dense_h_to_4h.weight]Loading weights:  14%|▏| 42/293 [00:00<00:00, 595.27it/s, Materializing param=transformer.h.3.mlp.dense_h_to_4h.weight]Loading weights:  15%|▏| 43/293 [00:00<00:00, 609.45it/s, Materializing param=transformer.h.3.post_attention_layernorm.Loading weights:  15%|▏| 43/293 [00:00<00:00, 609.45it/s, Materializing param=transformer.h.3.post_attention_layernorm.Loading weights:  15%|▏| 44/293 [00:00<00:00, 623.62it/s, Materializing param=transformer.h.3.post_attention_layernorm.Loading weights:  15%|▏| 44/293 [00:00<00:00, 623.62it/s, Materializing param=transformer.h.3.post_attention_layernorm.Loading weights:  15%|▏| 45/293 [00:00<00:00, 637.79it/s, Materializing param=transformer.h.3.self_attention.dense.biasLoading weights:  15%|▏| 45/293 [00:00<00:00, 637.79it/s, Materializing param=transformer.h.3.self_attention.dense.biasLoading weights:  16%|▏| 46/293 [00:00<00:00, 651.97it/s, Materializing param=transformer.h.3.self_attention.dense.weigLoading weights:  16%|▏| 46/293 [00:00<00:00, 651.97it/s, Materializing param=transformer.h.3.self_attention.dense.weigLoading weights:  16%|▏| 47/293 [00:00<00:00, 647.74it/s, Materializing param=transformer.h.3.self_attention.query_key_Loading weights:  16%|▏| 47/293 [00:00<00:00, 647.74it/s, Materializing param=transformer.h.3.self_attention.query_key_Loading weights:  16%|▏| 48/293 [00:00<00:00, 661.52it/s, Materializing param=transformer.h.3.self_attention.query_key_Loading weights:  16%|▏| 48/293 [00:00<00:00, 661.52it/s, Materializing param=transformer.h.3.self_attention.query_key_Loading weights:  17%|▊    | 49/293 [00:00<00:00, 675.30it/s, Materializing param=transformer.h.4.input_layernorm.bias]Loading weights:  17%|▊    | 49/293 [00:00<00:00, 675.30it/s, Materializing param=transformer.h.4.input_layernorm.bias]Loading weights:  17%|▌  | 50/293 [00:00<00:00, 689.08it/s, Materializing param=transformer.h.4.input_layernorm.weight]Loading weights:  17%|▌  | 50/293 [00:00<00:00, 689.08it/s, Materializing param=transformer.h.4.input_layernorm.weight]Loading weights:  17%|▌  | 51/293 [00:00<00:00, 702.86it/s, Materializing param=transformer.h.4.mlp.dense_4h_to_h.bias]Loading weights:  17%|▌  | 51/293 [00:00<00:00, 702.86it/s, Materializing param=transformer.h.4.mlp.dense_4h_to_h.bias]Loading weights:  18%|▏| 52/293 [00:00<00:00, 697.37it/s, Materializing param=transformer.h.4.mlp.dense_4h_to_h.weight]Loading weights:  18%|▏| 52/293 [00:00<00:00, 697.37it/s, Materializing param=transformer.h.4.mlp.dense_4h_to_h.weight]Loading weights:  18%|▌  | 53/293 [00:00<00:00, 710.78it/s, Materializing param=transformer.h.4.mlp.dense_h_to_4h.bias]Loading weights:  18%|▌  | 53/293 [00:00<00:00, 710.78it/s, Materializing param=transformer.h.4.mlp.dense_h_to_4h.bias]Loading weights:  18%|▏| 54/293 [00:00<00:00, 724.19it/s, Materializing param=transformer.h.4.mlp.dense_h_to_4h.weight]Loading weights:  18%|▏| 54/293 [00:00<00:00, 714.57it/s, Materializing param=transformer.h.4.mlp.dense_h_to_4h.weight]Loading weights:  19%|▏| 55/293 [00:00<00:00, 727.80it/s, Materializing param=transformer.h.4.post_attention_layernorm.Loading weights:  19%|▏| 55/293 [00:00<00:00, 727.80it/s, Materializing param=transformer.h.4.post_attention_layernorm.Loading weights:  19%|▏| 56/293 [00:00<00:00, 741.03it/s, Materializing param=transformer.h.4.post_attention_layernorm.Loading weights:  19%|▏| 56/293 [00:00<00:00, 741.03it/s, Materializing param=transformer.h.4.post_attention_layernorm.Loading weights:  19%|▏| 57/293 [00:00<00:00, 754.26it/s, Materializing param=transformer.h.4.self_attention.dense.biasLoading weights:  19%|▏| 57/293 [00:00<00:00, 754.26it/s, Materializing param=transformer.h.4.self_attention.dense.biasLoading weights:  20%|▏| 58/293 [00:00<00:00, 767.50it/s, Materializing param=transformer.h.4.self_attention.dense.weigLoading weights:  20%|▏| 58/293 [00:00<00:00, 767.50it/s, Materializing param=transformer.h.4.self_attention.dense.weigLoading weights:  20%|▏| 59/293 [00:00<00:00, 780.73it/s, Materializing param=transformer.h.4.self_attention.query_key_Loading weights:  20%|▏| 59/293 [00:00<00:00, 760.55it/s, Materializing param=transformer.h.4.self_attention.query_key_Loading weights:  20%|▏| 60/293 [00:00<00:00, 773.44it/s, Materializing param=transformer.h.4.self_attention.query_key_Loading weights:  20%|▏| 60/293 [00:00<00:00, 773.44it/s, Materializing param=transformer.h.4.self_attention.query_key_Loading weights:  21%|█    | 61/293 [00:00<00:00, 786.33it/s, Materializing param=transformer.h.5.input_layernorm.bias]Loading weights:  21%|█    | 61/293 [00:00<00:00, 786.33it/s, Materializing param=transformer.h.5.input_layernorm.bias]Loading weights:  21%|▋  | 62/293 [00:00<00:00, 799.22it/s, Materializing param=transformer.h.5.input_layernorm.weight]Loading weights:  21%|▋  | 62/293 [00:00<00:00, 799.22it/s, Materializing param=transformer.h.5.input_layernorm.weight]Loading weights:  22%|▋  | 63/293 [00:00<00:00, 812.11it/s, Materializing param=transformer.h.5.mlp.dense_4h_to_h.bias]Loading weights:  22%|▋  | 63/293 [00:00<00:00, 812.11it/s, Materializing param=transformer.h.5.mlp.dense_4h_to_h.bias]Loading weights:  22%|▏| 64/293 [00:00<00:00, 825.00it/s, Materializing param=transformer.h.5.mlp.dense_4h_to_h.weight]Loading weights:  22%|▏| 64/293 [00:00<00:00, 825.00it/s, Materializing param=transformer.h.5.mlp.dense_4h_to_h.weight]Loading weights:  22%|▋  | 65/293 [00:00<00:00, 837.89it/s, Materializing param=transformer.h.5.mlp.dense_h_to_4h.bias]Loading weights:  22%|▋  | 65/293 [00:00<00:00, 837.89it/s, Materializing param=transformer.h.5.mlp.dense_h_to_4h.bias]Loading weights:  23%|▏| 66/293 [00:00<00:00, 850.78it/s, Materializing param=transformer.h.5.mlp.dense_h_to_4h.weight]Loading weights:  23%|▏| 66/293 [00:00<00:00, 850.78it/s, Materializing param=transformer.h.5.mlp.dense_h_to_4h.weight]Loading weights:  23%|▏| 67/293 [00:00<00:00, 863.68it/s, Materializing param=transformer.h.5.post_attention_layernorm.Loading weights:  23%|▏| 67/293 [00:00<00:00, 829.38it/s, Materializing param=transformer.h.5.post_attention_layernorm.Loading weights:  23%|▏| 68/293 [00:00<00:00, 841.76it/s, Materializing param=transformer.h.5.post_attention_layernorm.Loading weights:  23%|▏| 68/293 [00:00<00:00, 841.76it/s, Materializing param=transformer.h.5.post_attention_layernorm.Loading weights:  24%|▏| 69/293 [00:00<00:00, 854.14it/s, Materializing param=transformer.h.5.self_attention.dense.biasLoading weights:  24%|▏| 69/293 [00:00<00:00, 854.14it/s, Materializing param=transformer.h.5.self_attention.dense.biasLoading weights:  24%|▏| 70/293 [00:00<00:00, 866.52it/s, Materializing param=transformer.h.5.self_attention.dense.weigLoading weights:  24%|▏| 70/293 [00:00<00:00, 866.52it/s, Materializing param=transformer.h.5.self_attention.dense.weigLoading weights:  24%|▏| 71/293 [00:00<00:00, 878.90it/s, Materializing param=transformer.h.5.self_attention.query_key_Loading weights:  24%|▏| 71/293 [00:00<00:00, 878.90it/s, Materializing param=transformer.h.5.self_attention.query_key_Loading weights:  25%|▏| 72/293 [00:00<00:00, 891.28it/s, Materializing param=transformer.h.5.self_attention.query_key_Loading weights:  25%|▏| 72/293 [00:00<00:00, 891.28it/s, Materializing param=transformer.h.5.self_attention.query_key_Loading weights:  25%|█▏   | 73/293 [00:00<00:00, 903.66it/s, Materializing param=transformer.h.6.input_layernorm.bias]Loading weights:  25%|█▏   | 73/293 [00:00<00:00, 903.66it/s, Materializing param=transformer.h.6.input_layernorm.bias]Loading weights:  25%|▊  | 74/293 [00:00<00:00, 916.04it/s, Materializing param=transformer.h.6.input_layernorm.weight]Loading weights:  25%|▊  | 74/293 [00:00<00:00, 916.04it/s, Materializing param=transformer.h.6.input_layernorm.weight]Loading weights:  26%|▊  | 75/293 [00:00<00:00, 928.41it/s, Materializing param=transformer.h.6.mlp.dense_4h_to_h.bias]Loading weights:  26%|▊  | 75/293 [00:00<00:00, 928.41it/s, Materializing param=transformer.h.6.mlp.dense_4h_to_h.bias]Loading weights:  26%|▎| 76/293 [00:00<00:00, 940.79it/s, Materializing param=transformer.h.6.mlp.dense_4h_to_h.weight]Loading weights:  26%|▎| 76/293 [00:00<00:00, 940.79it/s, Materializing param=transformer.h.6.mlp.dense_4h_to_h.weight]Loading weights:  26%|▊  | 77/293 [00:00<00:00, 953.17it/s, Materializing param=transformer.h.6.mlp.dense_h_to_4h.bias]Loading weights:  26%|▊  | 77/293 [00:00<00:00, 953.17it/s, Materializing param=transformer.h.6.mlp.dense_h_to_4h.bias]Loading weights:  27%|▎| 78/293 [00:00<00:00, 965.55it/s, Materializing param=transformer.h.6.mlp.dense_h_to_4h.weight]Loading weights:  27%|▎| 78/293 [00:00<00:00, 965.55it/s, Materializing param=transformer.h.6.mlp.dense_h_to_4h.weight]Loading weights:  27%|▎| 79/293 [00:00<00:00, 977.93it/s, Materializing param=transformer.h.6.post_attention_layernorm.Loading weights:  27%|▎| 79/293 [00:00<00:00, 977.93it/s, Materializing param=transformer.h.6.post_attention_layernorm.Loading weights:  27%|▎| 80/293 [00:00<00:00, 931.93it/s, Materializing param=transformer.h.6.post_attention_layernorm.Loading weights:  27%|▎| 80/293 [00:00<00:00, 931.93it/s, Materializing param=transformer.h.6.post_attention_layernorm.Loading weights:  28%|▎| 81/293 [00:00<00:00, 943.58it/s, Materializing param=transformer.h.6.self_attention.dense.biasLoading weights:  28%|▎| 81/293 [00:00<00:00, 943.58it/s, Materializing param=transformer.h.6.self_attention.dense.biasLoading weights:  28%|▎| 82/293 [00:00<00:00, 955.23it/s, Materializing param=transformer.h.6.self_attention.dense.weigLoading weights:  28%|▎| 82/293 [00:00<00:00, 955.23it/s, Materializing param=transformer.h.6.self_attention.dense.weigLoading weights:  28%|▎| 83/293 [00:00<00:00, 966.88it/s, Materializing param=transformer.h.6.self_attention.query_key_Loading weights:  28%|▎| 83/293 [00:00<00:00, 966.88it/s, Materializing param=transformer.h.6.self_attention.query_key_Loading weights:  29%|▎| 84/293 [00:00<00:00, 978.53it/s, Materializing param=transformer.h.6.self_attention.query_key_Loading weights:  29%|▎| 84/293 [00:00<00:00, 978.53it/s, Materializing param=transformer.h.6.self_attention.query_key_Loading weights:  29%|█▍   | 85/293 [00:00<00:00, 990.18it/s, Materializing param=transformer.h.7.input_layernorm.bias]Loading weights:  29%|█▍   | 85/293 [00:00<00:00, 990.18it/s, Materializing param=transformer.h.7.input_layernorm.bias]Loading weights:  29%|▌ | 86/293 [00:00<00:00, 1001.83it/s, Materializing param=transformer.h.7.input_layernorm.weight]Loading weights:  29%|▌ | 86/293 [00:00<00:00, 1001.83it/s, Materializing param=transformer.h.7.input_layernorm.weight]Loading weights:  30%|▌ | 87/293 [00:00<00:00, 1013.48it/s, Materializing param=transformer.h.7.mlp.dense_4h_to_h.bias]Loading weights:  30%|▌ | 87/293 [00:00<00:00, 1013.48it/s, Materializing param=transformer.h.7.mlp.dense_4h_to_h.bias]Loading weights:  30%|▎| 88/293 [00:00<00:00, 1025.13it/s, Materializing param=transformer.h.7.mlp.dense_4h_to_h.weightLoading weights:  30%|▎| 88/293 [00:00<00:00, 1025.13it/s, Materializing param=transformer.h.7.mlp.dense_4h_to_h.weightLoading weights:  30%|▌ | 89/293 [00:00<00:00, 1036.78it/s, Materializing param=transformer.h.7.mlp.dense_h_to_4h.bias]Loading weights:  30%|▌ | 89/293 [00:00<00:00, 1036.78it/s, Materializing param=transformer.h.7.mlp.dense_h_to_4h.bias]Loading weights:  31%|▎| 90/293 [00:00<00:00, 1048.42it/s, Materializing param=transformer.h.7.mlp.dense_h_to_4h.weightLoading weights:  31%|▎| 90/293 [00:00<00:00, 1048.42it/s, Materializing param=transformer.h.7.mlp.dense_h_to_4h.weightLoading weights:  31%|▎| 91/293 [00:00<00:00, 1060.07it/s, Materializing param=transformer.h.7.post_attention_layernormLoading weights:  31%|▎| 91/293 [00:00<00:00, 1060.07it/s, Materializing param=transformer.h.7.post_attention_layernormLoading weights:  31%|▎| 92/293 [00:00<00:00, 1071.72it/s, Materializing param=transformer.h.7.post_attention_layernormLoading weights:  31%|▎| 92/293 [00:00<00:00, 1071.72it/s, Materializing param=transformer.h.7.post_attention_layernormLoading weights:  32%|▎| 93/293 [00:00<00:00, 1023.32it/s, Materializing param=transformer.h.7.self_attention.dense.biaLoading weights:  32%|▎| 93/293 [00:00<00:00, 1023.32it/s, Materializing param=transformer.h.7.self_attention.dense.biaLoading weights:  32%|▎| 94/293 [00:00<00:00, 1034.32it/s, Materializing param=transformer.h.7.self_attention.dense.weiLoading weights:  32%|▎| 94/293 [00:00<00:00, 1034.32it/s, Materializing param=transformer.h.7.self_attention.dense.weiLoading weights:  32%|▎| 95/293 [00:00<00:00, 1045.33it/s, Materializing param=transformer.h.7.self_attention.query_keyLoading weights:  32%|▎| 95/293 [00:00<00:00, 1045.33it/s, Materializing param=transformer.h.7.self_attention.query_keyLoading weights:  33%|▎| 96/293 [00:00<00:00, 1056.33it/s, Materializing param=transformer.h.7.self_attention.query_keyLoading weights:  33%|▎| 96/293 [00:00<00:00, 1056.33it/s, Materializing param=transformer.h.7.self_attention.query_keyLoading weights:  33%|█▎  | 97/293 [00:00<00:00, 1067.33it/s, Materializing param=transformer.h.8.input_layernorm.bias]Loading weights:  33%|█▎  | 97/293 [00:00<00:00, 1067.33it/s, Materializing param=transformer.h.8.input_layernorm.bias]Loading weights:  33%|▋ | 98/293 [00:00<00:00, 1078.34it/s, Materializing param=transformer.h.8.input_layernorm.weight]Loading weights:  33%|▋ | 98/293 [00:00<00:00, 1078.34it/s, Materializing param=transformer.h.8.input_layernorm.weight]Loading weights:  34%|▋ | 99/293 [00:00<00:00, 1089.34it/s, Materializing param=transformer.h.8.mlp.dense_4h_to_h.bias]Loading weights:  34%|▋ | 99/293 [00:00<00:00, 1089.34it/s, Materializing param=transformer.h.8.mlp.dense_4h_to_h.bias]Loading weights:  34%|▎| 100/293 [00:00<00:00, 1100.34it/s, Materializing param=transformer.h.8.mlp.dense_4h_to_h.weighLoading weights:  34%|▎| 100/293 [00:00<00:00, 1100.34it/s, Materializing param=transformer.h.8.mlp.dense_4h_to_h.weighLoading weights:  34%|▎| 101/293 [00:00<00:00, 1111.35it/s, Materializing param=transformer.h.8.mlp.dense_h_to_4h.bias]Loading weights:  34%|▎| 101/293 [00:00<00:00, 1111.35it/s, Materializing param=transformer.h.8.mlp.dense_h_to_4h.bias]Loading weights:  35%|▎| 102/293 [00:00<00:00, 1122.35it/s, Materializing param=transformer.h.8.mlp.dense_h_to_4h.weighLoading weights:  35%|▎| 102/293 [00:00<00:00, 1122.35it/s, Materializing param=transformer.h.8.mlp.dense_h_to_4h.weighLoading weights:  35%|▎| 103/293 [00:00<00:00, 1133.35it/s, Materializing param=transformer.h.8.post_attention_layernorLoading weights:  35%|▎| 103/293 [00:00<00:00, 1133.35it/s, Materializing param=transformer.h.8.post_attention_layernorLoading weights:  35%|▎| 104/293 [00:00<00:00, 1144.36it/s, Materializing param=transformer.h.8.post_attention_layernorLoading weights:  35%|▎| 104/293 [00:00<00:00, 1144.36it/s, Materializing param=transformer.h.8.post_attention_layernorLoading weights:  36%|▎| 105/293 [00:00<00:00, 1093.82it/s, Materializing param=transformer.h.8.self_attention.dense.biLoading weights:  36%|▎| 105/293 [00:00<00:00, 1093.82it/s, Materializing param=transformer.h.8.self_attention.dense.biLoading weights:  36%|▎| 106/293 [00:00<00:00, 1104.23it/s, Materializing param=transformer.h.8.self_attention.dense.weLoading weights:  36%|▎| 106/293 [00:00<00:00, 1104.23it/s, Materializing param=transformer.h.8.self_attention.dense.weLoading weights:  37%|▎| 107/293 [00:00<00:00, 1114.65it/s, Materializing param=transformer.h.8.self_attention.query_keLoading weights:  37%|▎| 107/293 [00:00<00:00, 1114.65it/s, Materializing param=transformer.h.8.self_attention.query_keLoading weights:  37%|▎| 108/293 [00:00<00:00, 1125.07it/s, Materializing param=transformer.h.8.self_attention.query_keLoading weights:  37%|▎| 108/293 [00:00<00:00, 1125.07it/s, Materializing param=transformer.h.8.self_attention.query_keLoading weights:  37%|█  | 109/293 [00:00<00:00, 1135.48it/s, Materializing param=transformer.h.9.input_layernorm.bias]Loading weights:  37%|█  | 109/293 [00:00<00:00, 1135.48it/s, Materializing param=transformer.h.9.input_layernorm.bias]Loading weights:  38%|▍| 110/293 [00:00<00:00, 1145.90it/s, Materializing param=transformer.h.9.input_layernorm.weight]Loading weights:  38%|▍| 110/293 [00:00<00:00, 1145.90it/s, Materializing param=transformer.h.9.input_layernorm.weight]Loading weights:  38%|▍| 111/293 [00:00<00:00, 1156.32it/s, Materializing param=transformer.h.9.mlp.dense_4h_to_h.bias]Loading weights:  38%|▍| 111/293 [00:00<00:00, 1156.32it/s, Materializing param=transformer.h.9.mlp.dense_4h_to_h.bias]Loading weights:  38%|▍| 112/293 [00:00<00:00, 1166.74it/s, Materializing param=transformer.h.9.mlp.dense_4h_to_h.weighLoading weights:  38%|▍| 112/293 [00:00<00:00, 1166.74it/s, Materializing param=transformer.h.9.mlp.dense_4h_to_h.weighLoading weights:  39%|▍| 113/293 [00:00<00:00, 1177.15it/s, Materializing param=transformer.h.9.mlp.dense_h_to_4h.bias]Loading weights:  39%|▍| 113/293 [00:00<00:00, 1177.15it/s, Materializing param=transformer.h.9.mlp.dense_h_to_4h.bias]Loading weights:  39%|▍| 114/293 [00:00<00:00, 1187.57it/s, Materializing param=transformer.h.9.mlp.dense_h_to_4h.weighLoading weights:  39%|▍| 114/293 [00:00<00:00, 1187.57it/s, Materializing param=transformer.h.9.mlp.dense_h_to_4h.weighLoading weights:  39%|▍| 115/293 [00:00<00:00, 1197.99it/s, Materializing param=transformer.h.9.post_attention_layernorLoading weights:  39%|▍| 115/293 [00:00<00:00, 1197.99it/s, Materializing param=transformer.h.9.post_attention_layernorLoading weights:  40%|▍| 116/293 [00:00<00:00, 1208.41it/s, Materializing param=transformer.h.9.post_attention_layernorLoading weights:  40%|▍| 116/293 [00:00<00:00, 1208.41it/s, Materializing param=transformer.h.9.post_attention_layernorLoading weights:  40%|▍| 117/293 [00:00<00:00, 1218.82it/s, Materializing param=transformer.h.9.self_attention.dense.biLoading weights:  40%|▍| 117/293 [00:00<00:00, 1156.73it/s, Materializing param=transformer.h.9.self_attention.dense.biLoading weights:  40%|▍| 118/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.9.self_attention.dense.biLoading weights:  40%|▍| 118/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.9.self_attention.dense.weLoading weights:  40%|▍| 118/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.9.self_attention.dense.weLoading weights:  41%|▍| 119/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.9.self_attention.query_keLoading weights:  41%|▍| 119/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.9.self_attention.query_keLoading weights:  41%|▍| 120/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.9.self_attention.query_keLoading weights:  41%|▍| 120/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.9.self_attention.query_keLoading weights:  41%|▊ | 121/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.10.input_layernorm.bias]Loading weights:  41%|▊ | 121/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.10.input_layernorm.bias]Loading weights:  42%|▍| 122/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.10.input_layernorm.weightLoading weights:  42%|▍| 122/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.10.input_layernorm.weightLoading weights:  42%|▍| 123/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.10.mlp.dense_4h_to_h.biasLoading weights:  42%|▍| 123/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.10.mlp.dense_4h_to_h.biasLoading weights:  42%|▍| 124/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.10.mlp.dense_4h_to_h.weigLoading weights:  42%|▍| 124/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.10.mlp.dense_4h_to_h.weigLoading weights:  43%|▍| 125/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.10.mlp.dense_h_to_4h.biasLoading weights:  43%|▍| 125/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.10.mlp.dense_h_to_4h.biasLoading weights:  43%|▍| 126/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.10.mlp.dense_h_to_4h.weigLoading weights:  43%|▍| 126/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.10.mlp.dense_h_to_4h.weigLoading weights:  43%|▍| 127/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.10.post_attention_layernoLoading weights:  43%|▍| 127/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.10.post_attention_layernoLoading weights:  44%|▍| 128/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.10.post_attention_layernoLoading weights:  44%|▍| 128/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.10.post_attention_layernoLoading weights:  44%|▍| 129/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.10.self_attention.dense.bLoading weights:  44%|▍| 129/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.10.self_attention.dense.bLoading weights:  44%|▍| 130/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.10.self_attention.dense.wLoading weights:  44%|▍| 130/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.10.self_attention.dense.wLoading weights:  45%|▍| 131/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.10.self_attention.query_kLoading weights:  45%|▍| 131/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.10.self_attention.query_kLoading weights:  45%|▍| 132/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.10.self_attention.query_kLoading weights:  45%|▍| 132/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.10.self_attention.query_kLoading weights:  45%|▉ | 133/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.11.input_layernorm.bias]Loading weights:  45%|▉ | 133/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.11.input_layernorm.bias]Loading weights:  46%|▍| 134/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.11.input_layernorm.weightLoading weights:  46%|▍| 134/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.11.input_layernorm.weightLoading weights:  46%|▍| 135/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.11.mlp.dense_4h_to_h.biasLoading weights:  46%|▍| 135/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.11.mlp.dense_4h_to_h.biasLoading weights:  46%|▍| 136/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.11.mlp.dense_4h_to_h.weigLoading weights:  46%|▍| 136/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.11.mlp.dense_4h_to_h.weigLoading weights:  47%|▍| 137/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.11.mlp.dense_h_to_4h.biasLoading weights:  47%|▍| 137/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.11.mlp.dense_h_to_4h.biasLoading weights:  47%|▍| 138/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.11.mlp.dense_h_to_4h.weigLoading weights:  47%|▍| 138/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.11.mlp.dense_h_to_4h.weigLoading weights:  47%|▍| 139/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.11.post_attention_layernoLoading weights:  47%|▍| 139/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.11.post_attention_layernoLoading weights:  48%|▍| 140/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.11.post_attention_layernoLoading weights:  48%|▍| 140/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.11.post_attention_layernoLoading weights:  48%|▍| 141/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.11.self_attention.dense.bLoading weights:  48%|▍| 141/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.11.self_attention.dense.bLoading weights:  48%|▍| 142/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.11.self_attention.dense.wLoading weights:  48%|▍| 142/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.11.self_attention.dense.wLoading weights:  49%|▍| 143/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.11.self_attention.query_kLoading weights:  49%|▍| 143/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.11.self_attention.query_kLoading weights:  49%|▍| 144/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.11.self_attention.query_kLoading weights:  49%|▍| 144/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.11.self_attention.query_kLoading weights:  49%|▉ | 145/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.12.input_layernorm.bias]Loading weights:  49%|▉ | 145/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.12.input_layernorm.bias]Loading weights:  50%|▍| 146/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.12.input_layernorm.weightLoading weights:  50%|▍| 146/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.12.input_layernorm.weightLoading weights:  50%|▌| 147/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.12.mlp.dense_4h_to_h.biasLoading weights:  50%|▌| 147/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.12.mlp.dense_4h_to_h.biasLoading weights:  51%|▌| 148/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.12.mlp.dense_4h_to_h.weigLoading weights:  51%|▌| 148/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.12.mlp.dense_4h_to_h.weigLoading weights:  51%|▌| 149/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.12.mlp.dense_h_to_4h.biasLoading weights:  51%|▌| 149/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.12.mlp.dense_h_to_4h.biasLoading weights:  51%|▌| 150/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.12.mlp.dense_h_to_4h.weigLoading weights:  51%|▌| 150/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.12.mlp.dense_h_to_4h.weigLoading weights:  52%|▌| 151/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.12.post_attention_layernoLoading weights:  52%|▌| 151/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.12.post_attention_layernoLoading weights:  52%|▌| 152/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.12.post_attention_layernoLoading weights:  52%|▌| 152/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.12.post_attention_layernoLoading weights:  52%|▌| 153/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.12.self_attention.dense.bLoading weights:  52%|▌| 153/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.12.self_attention.dense.bLoading weights:  53%|▌| 154/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.12.self_attention.dense.wLoading weights:  53%|▌| 154/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.12.self_attention.dense.wLoading weights:  53%|▌| 155/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.12.self_attention.query_kLoading weights:  53%|▌| 155/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.12.self_attention.query_kLoading weights:  53%|▌| 156/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.12.self_attention.query_kLoading weights:  53%|▌| 156/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.12.self_attention.query_kLoading weights:  54%|█ | 157/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.13.input_layernorm.bias]Loading weights:  54%|█ | 157/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.13.input_layernorm.bias]Loading weights:  54%|▌| 158/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.13.input_layernorm.weightLoading weights:  54%|▌| 158/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.13.input_layernorm.weightLoading weights:  54%|▌| 159/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.13.mlp.dense_4h_to_h.biasLoading weights:  54%|▌| 159/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.13.mlp.dense_4h_to_h.biasLoading weights:  55%|▌| 160/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.13.mlp.dense_4h_to_h.weigLoading weights:  55%|▌| 160/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.13.mlp.dense_4h_to_h.weigLoading weights:  55%|▌| 161/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.13.mlp.dense_h_to_4h.biasLoading weights:  55%|▌| 161/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.13.mlp.dense_h_to_4h.biasLoading weights:  55%|▌| 162/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.13.mlp.dense_h_to_4h.weigLoading weights:  55%|▌| 162/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.13.mlp.dense_h_to_4h.weigLoading weights:  56%|▌| 163/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.13.post_attention_layernoLoading weights:  56%|▌| 163/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.13.post_attention_layernoLoading weights:  56%|▌| 164/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.13.post_attention_layernoLoading weights:  56%|▌| 164/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.13.post_attention_layernoLoading weights:  56%|▌| 165/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.13.self_attention.dense.bLoading weights:  56%|▌| 165/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.13.self_attention.dense.bLoading weights:  57%|▌| 166/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.13.self_attention.dense.wLoading weights:  57%|▌| 166/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.13.self_attention.dense.wLoading weights:  57%|▌| 167/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.13.self_attention.query_kLoading weights:  57%|▌| 167/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.13.self_attention.query_kLoading weights:  57%|▌| 168/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.13.self_attention.query_kLoading weights:  57%|▌| 168/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.13.self_attention.query_kLoading weights:  58%|█▏| 169/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.14.input_layernorm.bias]Loading weights:  58%|█▏| 169/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.14.input_layernorm.bias]Loading weights:  58%|▌| 170/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.14.input_layernorm.weightLoading weights:  58%|▌| 170/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.14.input_layernorm.weightLoading weights:  58%|▌| 171/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.14.mlp.dense_4h_to_h.biasLoading weights:  58%|▌| 171/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.14.mlp.dense_4h_to_h.biasLoading weights:  59%|▌| 172/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.14.mlp.dense_4h_to_h.weigLoading weights:  59%|▌| 172/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.14.mlp.dense_4h_to_h.weigLoading weights:  59%|▌| 173/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.14.mlp.dense_h_to_4h.biasLoading weights:  59%|▌| 173/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.14.mlp.dense_h_to_4h.biasLoading weights:  59%|▌| 174/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.14.mlp.dense_h_to_4h.weigLoading weights:  59%|▌| 174/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.14.mlp.dense_h_to_4h.weigLoading weights:  60%|▌| 175/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.14.post_attention_layernoLoading weights:  60%|▌| 175/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.14.post_attention_layernoLoading weights:  60%|▌| 176/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.14.post_attention_layernoLoading weights:  60%|▌| 176/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.14.post_attention_layernoLoading weights:  60%|▌| 177/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.14.self_attention.dense.bLoading weights:  60%|▌| 177/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.14.self_attention.dense.bLoading weights:  61%|▌| 178/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.14.self_attention.dense.wLoading weights:  61%|▌| 178/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.14.self_attention.dense.wLoading weights:  61%|▌| 179/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.14.self_attention.query_kLoading weights:  61%|▌| 179/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.14.self_attention.query_kLoading weights:  61%|▌| 180/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.14.self_attention.query_kLoading weights:  61%|▌| 180/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.14.self_attention.query_kLoading weights:  62%|█▏| 181/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.15.input_layernorm.bias]Loading weights:  62%|█▏| 181/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.15.input_layernorm.bias]Loading weights:  62%|▌| 182/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.15.input_layernorm.weightLoading weights:  62%|▌| 182/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.15.input_layernorm.weightLoading weights:  62%|▌| 183/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.15.mlp.dense_4h_to_h.biasLoading weights:  62%|▌| 183/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.15.mlp.dense_4h_to_h.biasLoading weights:  63%|▋| 184/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.15.mlp.dense_4h_to_h.weigLoading weights:  63%|▋| 184/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.15.mlp.dense_4h_to_h.weigLoading weights:  63%|▋| 185/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.15.mlp.dense_h_to_4h.biasLoading weights:  63%|▋| 185/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.15.mlp.dense_h_to_4h.biasLoading weights:  63%|▋| 186/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.15.mlp.dense_h_to_4h.weigLoading weights:  63%|▋| 186/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.15.mlp.dense_h_to_4h.weigLoading weights:  64%|▋| 187/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.15.post_attention_layernoLoading weights:  64%|▋| 187/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.15.post_attention_layernoLoading weights:  64%|▋| 188/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.15.post_attention_layernoLoading weights:  64%|▋| 188/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.15.post_attention_layernoLoading weights:  65%|▋| 189/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.15.self_attention.dense.bLoading weights:  65%|▋| 189/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.15.self_attention.dense.bLoading weights:  65%|▋| 190/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.15.self_attention.dense.wLoading weights:  65%|▋| 190/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.15.self_attention.dense.wLoading weights:  65%|▋| 191/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.15.self_attention.query_kLoading weights:  65%|▋| 191/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.15.self_attention.query_kLoading weights:  66%|▋| 192/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.15.self_attention.query_kLoading weights:  66%|▋| 192/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.15.self_attention.query_kLoading weights:  66%|█▎| 193/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.16.input_layernorm.bias]Loading weights:  66%|█▎| 193/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.16.input_layernorm.bias]Loading weights:  66%|▋| 194/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.16.input_layernorm.weightLoading weights:  66%|▋| 194/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.16.input_layernorm.weightLoading weights:  67%|▋| 195/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.16.mlp.dense_4h_to_h.biasLoading weights:  67%|▋| 195/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.16.mlp.dense_4h_to_h.biasLoading weights:  67%|▋| 196/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.16.mlp.dense_4h_to_h.weigLoading weights:  67%|▋| 196/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.16.mlp.dense_4h_to_h.weigLoading weights:  67%|▋| 197/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.16.mlp.dense_h_to_4h.biasLoading weights:  67%|▋| 197/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.16.mlp.dense_h_to_4h.biasLoading weights:  68%|▋| 198/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.16.mlp.dense_h_to_4h.weigLoading weights:  68%|▋| 198/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.16.mlp.dense_h_to_4h.weigLoading weights:  68%|▋| 199/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.16.post_attention_layernoLoading weights:  68%|▋| 199/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.16.post_attention_layernoLoading weights:  68%|▋| 200/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.16.post_attention_layernoLoading weights:  68%|▋| 200/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.16.post_attention_layernoLoading weights:  69%|▋| 201/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.16.self_attention.dense.bLoading weights:  69%|▋| 201/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.16.self_attention.dense.bLoading weights:  69%|▋| 202/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.16.self_attention.dense.wLoading weights:  69%|▋| 202/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.16.self_attention.dense.wLoading weights:  69%|▋| 203/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.16.self_attention.query_kLoading weights:  69%|▋| 203/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.16.self_attention.query_kLoading weights:  70%|▋| 204/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.16.self_attention.query_kLoading weights:  70%|▋| 204/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.16.self_attention.query_kLoading weights:  70%|█▍| 205/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.17.input_layernorm.bias]Loading weights:  70%|█▍| 205/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.17.input_layernorm.bias]Loading weights:  70%|▋| 206/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.17.input_layernorm.weightLoading weights:  70%|▋| 206/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.17.input_layernorm.weightLoading weights:  71%|▋| 207/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.17.mlp.dense_4h_to_h.biasLoading weights:  71%|▋| 207/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.17.mlp.dense_4h_to_h.biasLoading weights:  71%|▋| 208/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.17.mlp.dense_4h_to_h.weigLoading weights:  71%|▋| 208/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.17.mlp.dense_4h_to_h.weigLoading weights:  71%|▋| 209/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.17.mlp.dense_h_to_4h.biasLoading weights:  71%|▋| 209/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.17.mlp.dense_h_to_4h.biasLoading weights:  72%|▋| 210/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.17.mlp.dense_h_to_4h.weigLoading weights:  72%|▋| 210/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.17.mlp.dense_h_to_4h.weigLoading weights:  72%|▋| 211/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.17.post_attention_layernoLoading weights:  72%|▋| 211/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.17.post_attention_layernoLoading weights:  72%|▋| 212/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.17.post_attention_layernoLoading weights:  72%|▋| 212/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.17.post_attention_layernoLoading weights:  73%|▋| 213/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.17.self_attention.dense.bLoading weights:  73%|▋| 213/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.17.self_attention.dense.bLoading weights:  73%|▋| 214/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.17.self_attention.dense.wLoading weights:  73%|▋| 214/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.17.self_attention.dense.wLoading weights:  73%|▋| 215/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.17.self_attention.query_kLoading weights:  73%|▋| 215/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.17.self_attention.query_kLoading weights:  74%|▋| 216/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.17.self_attention.query_kLoading weights:  74%|▋| 216/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.17.self_attention.query_kLoading weights:  74%|█▍| 217/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.18.input_layernorm.bias]Loading weights:  74%|█▍| 217/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.18.input_layernorm.bias]Loading weights:  74%|▋| 218/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.18.input_layernorm.weightLoading weights:  74%|▋| 218/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.18.input_layernorm.weightLoading weights:  75%|▋| 219/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.18.mlp.dense_4h_to_h.biasLoading weights:  75%|▋| 219/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.18.mlp.dense_4h_to_h.biasLoading weights:  75%|▊| 220/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.18.mlp.dense_4h_to_h.weigLoading weights:  75%|▊| 220/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.18.mlp.dense_4h_to_h.weigLoading weights:  75%|▊| 221/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.18.mlp.dense_h_to_4h.biasLoading weights:  75%|▊| 221/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.18.mlp.dense_h_to_4h.biasLoading weights:  76%|▊| 222/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.18.mlp.dense_h_to_4h.weigLoading weights:  76%|▊| 222/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.18.mlp.dense_h_to_4h.weigLoading weights:  76%|▊| 223/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.18.post_attention_layernoLoading weights:  76%|▊| 223/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.18.post_attention_layernoLoading weights:  76%|▊| 224/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.18.post_attention_layernoLoading weights:  76%|▊| 224/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.18.post_attention_layernoLoading weights:  77%|▊| 225/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.18.self_attention.dense.bLoading weights:  77%|▊| 225/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.18.self_attention.dense.bLoading weights:  77%|▊| 226/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.18.self_attention.dense.wLoading weights:  77%|▊| 226/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.18.self_attention.dense.wLoading weights:  77%|▊| 227/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.18.self_attention.query_kLoading weights:  77%|▊| 227/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.18.self_attention.query_kLoading weights:  78%|▊| 228/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.18.self_attention.query_kLoading weights:  78%|▊| 228/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.18.self_attention.query_kLoading weights:  78%|█▌| 229/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.19.input_layernorm.bias]Loading weights:  78%|█▌| 229/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.19.input_layernorm.bias]Loading weights:  78%|▊| 230/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.19.input_layernorm.weightLoading weights:  78%|▊| 230/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.19.input_layernorm.weightLoading weights:  79%|▊| 231/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.19.mlp.dense_4h_to_h.biasLoading weights:  79%|▊| 231/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.19.mlp.dense_4h_to_h.biasLoading weights:  79%|▊| 232/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.19.mlp.dense_4h_to_h.weigLoading weights:  79%|▊| 232/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.19.mlp.dense_4h_to_h.weigLoading weights:  80%|▊| 233/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.19.mlp.dense_h_to_4h.biasLoading weights:  80%|▊| 233/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.19.mlp.dense_h_to_4h.biasLoading weights:  80%|▊| 234/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.19.mlp.dense_h_to_4h.weigLoading weights:  80%|▊| 234/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.19.mlp.dense_h_to_4h.weigLoading weights:  80%|▊| 235/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.19.post_attention_layernoLoading weights:  80%|▊| 235/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.19.post_attention_layernoLoading weights:  81%|▊| 236/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.19.post_attention_layernoLoading weights:  81%|▊| 236/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.19.post_attention_layernoLoading weights:  81%|▊| 237/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.19.self_attention.dense.bLoading weights:  81%|▊| 237/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.19.self_attention.dense.bLoading weights:  81%|▊| 238/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.19.self_attention.dense.wLoading weights:  81%|▊| 238/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.19.self_attention.dense.wLoading weights:  82%|▊| 239/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.19.self_attention.query_kLoading weights:  82%|▊| 239/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.19.self_attention.query_kLoading weights:  82%|▊| 240/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.19.self_attention.query_kLoading weights:  82%|▊| 240/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.19.self_attention.query_kLoading weights:  82%|█▋| 241/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.20.input_layernorm.bias]Loading weights:  82%|█▋| 241/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.20.input_layernorm.bias]Loading weights:  83%|▊| 242/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.20.input_layernorm.weightLoading weights:  83%|▊| 242/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.20.input_layernorm.weightLoading weights:  83%|▊| 243/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.20.mlp.dense_4h_to_h.biasLoading weights:  83%|▊| 243/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.20.mlp.dense_4h_to_h.biasLoading weights:  83%|▊| 244/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.20.mlp.dense_4h_to_h.weigLoading weights:  83%|▊| 244/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.20.mlp.dense_4h_to_h.weigLoading weights:  84%|▊| 245/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.20.mlp.dense_h_to_4h.biasLoading weights:  84%|▊| 245/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.20.mlp.dense_h_to_4h.biasLoading weights:  84%|▊| 246/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.20.mlp.dense_h_to_4h.weigLoading weights:  84%|▊| 246/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.20.mlp.dense_h_to_4h.weigLoading weights:  84%|▊| 247/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.20.post_attention_layernoLoading weights:  84%|▊| 247/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.20.post_attention_layernoLoading weights:  85%|▊| 248/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.20.post_attention_layernoLoading weights:  85%|▊| 248/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.20.post_attention_layernoLoading weights:  85%|▊| 249/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.20.self_attention.dense.bLoading weights:  85%|▊| 249/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.20.self_attention.dense.bLoading weights:  85%|▊| 250/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.20.self_attention.dense.wLoading weights:  85%|▊| 250/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.20.self_attention.dense.wLoading weights:  86%|▊| 251/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.20.self_attention.query_kLoading weights:  86%|▊| 251/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.20.self_attention.query_kLoading weights:  86%|▊| 252/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.20.self_attention.query_kLoading weights:  86%|▊| 252/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.20.self_attention.query_kLoading weights:  86%|█▋| 253/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.21.input_layernorm.bias]Loading weights:  86%|█▋| 253/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.21.input_layernorm.bias]Loading weights:  87%|▊| 254/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.21.input_layernorm.weightLoading weights:  87%|▊| 254/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.21.input_layernorm.weightLoading weights:  87%|▊| 255/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.21.mlp.dense_4h_to_h.biasLoading weights:  87%|▊| 255/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.21.mlp.dense_4h_to_h.biasLoading weights:  87%|▊| 256/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.21.mlp.dense_4h_to_h.weigLoading weights:  87%|▊| 256/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.21.mlp.dense_4h_to_h.weigLoading weights:  88%|▉| 257/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.21.mlp.dense_h_to_4h.biasLoading weights:  88%|▉| 257/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.21.mlp.dense_h_to_4h.biasLoading weights:  88%|▉| 258/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.21.mlp.dense_h_to_4h.weigLoading weights:  88%|▉| 258/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.21.mlp.dense_h_to_4h.weigLoading weights:  88%|▉| 259/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.21.post_attention_layernoLoading weights:  88%|▉| 259/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.21.post_attention_layernoLoading weights:  89%|▉| 260/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.21.post_attention_layernoLoading weights:  89%|▉| 260/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.21.post_attention_layernoLoading weights:  89%|▉| 261/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.21.self_attention.dense.bLoading weights:  89%|▉| 261/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.21.self_attention.dense.bLoading weights:  89%|▉| 262/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.21.self_attention.dense.wLoading weights:  89%|▉| 262/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.21.self_attention.dense.wLoading weights:  90%|▉| 263/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.21.self_attention.query_kLoading weights:  90%|▉| 263/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.21.self_attention.query_kLoading weights:  90%|▉| 264/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.21.self_attention.query_kLoading weights:  90%|▉| 264/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.21.self_attention.query_kLoading weights:  90%|█▊| 265/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.22.input_layernorm.bias]Loading weights:  90%|█▊| 265/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.22.input_layernorm.bias]Loading weights:  91%|▉| 266/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.22.input_layernorm.weightLoading weights:  91%|▉| 266/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.22.input_layernorm.weightLoading weights:  91%|▉| 267/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.22.mlp.dense_4h_to_h.biasLoading weights:  91%|▉| 267/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.22.mlp.dense_4h_to_h.biasLoading weights:  91%|▉| 268/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.22.mlp.dense_4h_to_h.weigLoading weights:  91%|▉| 268/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.22.mlp.dense_4h_to_h.weigLoading weights:  92%|▉| 269/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.22.mlp.dense_h_to_4h.biasLoading weights:  92%|▉| 269/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.22.mlp.dense_h_to_4h.biasLoading weights:  92%|▉| 270/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.22.mlp.dense_h_to_4h.weigLoading weights:  92%|▉| 270/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.22.mlp.dense_h_to_4h.weigLoading weights:  92%|▉| 271/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.22.post_attention_layernoLoading weights:  92%|▉| 271/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.22.post_attention_layernoLoading weights:  93%|▉| 272/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.22.post_attention_layernoLoading weights:  93%|▉| 272/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.22.post_attention_layernoLoading weights:  93%|▉| 273/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.22.self_attention.dense.bLoading weights:  93%|▉| 273/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.22.self_attention.dense.bLoading weights:  94%|▉| 274/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.22.self_attention.dense.wLoading weights:  94%|▉| 274/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.22.self_attention.dense.wLoading weights:  94%|▉| 275/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.22.self_attention.query_kLoading weights:  94%|▉| 275/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.22.self_attention.query_kLoading weights:  94%|▉| 276/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.22.self_attention.query_kLoading weights:  94%|▉| 276/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.22.self_attention.query_kLoading weights:  95%|█▉| 277/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.23.input_layernorm.bias]Loading weights:  95%|█▉| 277/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.23.input_layernorm.bias]Loading weights:  95%|▉| 278/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.23.input_layernorm.weightLoading weights:  95%|▉| 278/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.23.input_layernorm.weightLoading weights:  95%|▉| 279/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.23.mlp.dense_4h_to_h.biasLoading weights:  95%|▉| 279/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.23.mlp.dense_4h_to_h.biasLoading weights:  96%|▉| 280/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.23.mlp.dense_4h_to_h.weigLoading weights:  96%|▉| 280/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.23.mlp.dense_4h_to_h.weigLoading weights:  96%|▉| 281/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.23.mlp.dense_h_to_4h.biasLoading weights:  96%|▉| 281/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.23.mlp.dense_h_to_4h.biasLoading weights:  96%|▉| 282/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.23.mlp.dense_h_to_4h.weigLoading weights:  96%|▉| 282/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.23.mlp.dense_h_to_4h.weigLoading weights:  97%|▉| 283/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.23.post_attention_layernoLoading weights:  97%|▉| 283/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.23.post_attention_layernoLoading weights:  97%|▉| 284/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.23.post_attention_layernoLoading weights:  97%|▉| 284/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.23.post_attention_layernoLoading weights:  97%|▉| 285/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.23.self_attention.dense.bLoading weights:  97%|▉| 285/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.23.self_attention.dense.bLoading weights:  98%|▉| 286/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.23.self_attention.dense.wLoading weights:  98%|▉| 286/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.23.self_attention.dense.wLoading weights:  98%|▉| 287/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.23.self_attention.query_kLoading weights:  98%|▉| 287/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.23.self_attention.query_kLoading weights:  98%|▉| 288/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.23.self_attention.query_kLoading weights:  98%|▉| 288/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.h.23.self_attention.query_kLoading weights:  99%|█████████████████▊| 289/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.ln_f.bias]Loading weights:  99%|█████████████████▊| 289/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.ln_f.bias]Loading weights:  99%|███████████████▊| 290/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.ln_f.weight]Loading weights:  99%|███████████████▊| 290/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.ln_f.weight]Loading weights:  99%|████▉| 291/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.word_embeddings.weight]Loading weights:  99%|████▉| 291/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.word_embeddings.weight]Loading weights: 100%|▉| 292/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.word_embeddings_layernorm.bLoading weights: 100%|▉| 292/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.word_embeddings_layernorm.bLoading weights: 100%|█| 293/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.word_embeddings_layernorm.wLoading weights: 100%|█| 293/293 [00:00<00:00, 1166.62it/s, Materializing param=transformer.word_embeddings_layernorm.wLoading weights: 100%|█| 293/293 [00:00<00:00, 1754.44it/s, Materializing param=transformer.word_embeddings_layernorm.w

All models loaded. Device: cuda

==================================================
Dataset 30 (en)
==================================================
Computing sentence embeddings...
Computing perplexity scores (model: gpt2)...
`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.
  Perplexity: 50/275 users processed
  Perplexity: 100/275 users processed
  Perplexity: 150/275 users processed
  Perplexity: 200/275 users processed
  Perplexity: 250/275 users processed
  NLP features shape: (275, 13)

==================================================
Dataset 31 (fr)
==================================================
Computing sentence embeddings...
Computing perplexity scores (model: bigscience/bloom-560m)...
  Perplexity: 50/171 users processed
  Perplexity: 100/171 users processed
  Perplexity: 150/171 users processed
  NLP features shape: (171, 13)

==================================================
Dataset 32 (en)
==================================================
Computing sentence embeddings...
Computing perplexity scores (model: gpt2)...
  Perplexity: 50/271 users processed
  Perplexity: 100/271 users processed
  Perplexity: 150/271 users processed
  Perplexity: 200/271 users processed
  Perplexity: 250/271 users processed
  NLP features shape: (271, 13)

==================================================
Dataset 33 (fr)
==================================================
Computing sentence embeddings...
Computing perplexity scores (model: bigscience/bloom-560m)...
  Perplexity: 50/172 users processed
  Perplexity: 100/172 users processed
  Perplexity: 150/172 users processed
  NLP features shape: (172, 13)

NLP feature extraction complete!

Extracting topic coherence features for dataset 30...
  Shape: (275, 9)

Extracting topic coherence features for dataset 31...
  Shape: (171, 9)

Extracting topic coherence features for dataset 32...
  Shape: (271, 9)

Extracting topic coherence features for dataset 33...
  Shape: (172, 9)

Topic coherence feature extraction complete!
Loading multilingual sentiment model...
Loading weights:   0%|                                                                         | 0/201 [00:00<?, ?it/s]Loading weights:   0%|▏                             | 1/201 [00:00<?, ?it/s, Materializing param=classifier.dense.bias]Loading weights:   0%|▏                             | 1/201 [00:00<?, ?it/s, Materializing param=classifier.dense.bias]Loading weights:   1%|▎                           | 2/201 [00:00<?, ?it/s, Materializing param=classifier.dense.weight]Loading weights:   1%|▎                           | 2/201 [00:00<?, ?it/s, Materializing param=classifier.dense.weight]Loading weights:   1%|▍                          | 3/201 [00:00<?, ?it/s, Materializing param=classifier.out_proj.bias]Loading weights:   1%|▍                          | 3/201 [00:00<?, ?it/s, Materializing param=classifier.out_proj.bias]Loading weights:   2%|▍                        | 4/201 [00:00<?, ?it/s, Materializing param=classifier.out_proj.weight]Loading weights:   2%|▍                        | 4/201 [00:00<?, ?it/s, Materializing param=classifier.out_proj.weight]Loading weights:   2%|▍                 | 5/201 [00:00<?, ?it/s, Materializing param=roberta.embeddings.LayerNorm.bias]Loading weights:   2%|▍                 | 5/201 [00:00<?, ?it/s, Materializing param=roberta.embeddings.LayerNorm.bias]Loading weights:   3%|▍               | 6/201 [00:00<?, ?it/s, Materializing param=roberta.embeddings.LayerNorm.weight]Loading weights:   3%|▍               | 6/201 [00:00<?, ?it/s, Materializing param=roberta.embeddings.LayerNorm.weight]Loading weights:   3%|▏     | 7/201 [00:00<?, ?it/s, Materializing param=roberta.embeddings.position_embeddings.weight]Loading weights:   3%| | 7/201 [00:00<00:00, 1330.92it/s, Materializing param=roberta.embeddings.position_embeddings.weLoading weights:   4%| | 8/201 [00:00<00:00, 1521.05it/s, Materializing param=roberta.embeddings.token_type_embeddings.Loading weights:   4%| | 8/201 [00:00<00:00, 1521.05it/s, Materializing param=roberta.embeddings.token_type_embeddings.Loading weights:   4%| | 9/201 [00:00<00:00, 1711.18it/s, Materializing param=roberta.embeddings.word_embeddings.weightLoading weights:   4%| | 9/201 [00:00<00:00, 1711.18it/s, Materializing param=roberta.embeddings.word_embeddings.weightLoading weights:   5%| | 10/201 [00:00<00:00, 1901.32it/s, Materializing param=roberta.encoder.layer.0.attention.outputLoading weights:   5%| | 10/201 [00:00<00:00, 1901.32it/s, Materializing param=roberta.encoder.layer.0.attention.outputLoading weights:   5%| | 11/201 [00:00<00:00, 2091.45it/s, Materializing param=roberta.encoder.layer.0.attention.outputLoading weights:   5%| | 11/201 [00:00<00:00, 2091.45it/s, Materializing param=roberta.encoder.layer.0.attention.outputLoading weights:   6%| | 12/201 [00:00<00:00, 2281.58it/s, Materializing param=roberta.encoder.layer.0.attention.outputLoading weights:   6%| | 12/201 [00:00<00:00, 2281.58it/s, Materializing param=roberta.encoder.layer.0.attention.outputLoading weights:   6%| | 13/201 [00:00<00:00, 2471.71it/s, Materializing param=roberta.encoder.layer.0.attention.outputLoading weights:   6%| | 13/201 [00:00<00:00, 2471.71it/s, Materializing param=roberta.encoder.layer.0.attention.outputLoading weights:   7%| | 14/201 [00:00<00:00, 2661.84it/s, Materializing param=roberta.encoder.layer.0.attention.self.kLoading weights:   7%| | 14/201 [00:00<00:00, 2661.84it/s, Materializing param=roberta.encoder.layer.0.attention.self.kLoading weights:   7%| | 15/201 [00:00<00:00, 2851.97it/s, Materializing param=roberta.encoder.layer.0.attention.self.kLoading weights:   7%| | 15/201 [00:00<00:00, 2851.97it/s, Materializing param=roberta.encoder.layer.0.attention.self.kLoading weights:   8%| | 16/201 [00:00<00:00, 3042.11it/s, Materializing param=roberta.encoder.layer.0.attention.self.qLoading weights:   8%| | 16/201 [00:00<00:00, 3042.11it/s, Materializing param=roberta.encoder.layer.0.attention.self.qLoading weights:   8%| | 17/201 [00:00<00:00, 3232.24it/s, Materializing param=roberta.encoder.layer.0.attention.self.qLoading weights:   8%| | 17/201 [00:00<00:00, 3232.24it/s, Materializing param=roberta.encoder.layer.0.attention.self.qLoading weights:   9%| | 18/201 [00:00<00:00, 3422.37it/s, Materializing param=roberta.encoder.layer.0.attention.self.vLoading weights:   9%| | 18/201 [00:00<00:00, 3422.37it/s, Materializing param=roberta.encoder.layer.0.attention.self.vLoading weights:   9%| | 19/201 [00:00<00:00, 3612.50it/s, Materializing param=roberta.encoder.layer.0.attention.self.vLoading weights:   9%| | 19/201 [00:00<00:00, 3612.50it/s, Materializing param=roberta.encoder.layer.0.attention.self.vLoading weights:  10%| | 20/201 [00:00<00:00, 3802.63it/s, Materializing param=roberta.encoder.layer.0.intermediate.denLoading weights:  10%| | 20/201 [00:00<00:00, 3802.63it/s, Materializing param=roberta.encoder.layer.0.intermediate.denLoading weights:  10%| | 21/201 [00:00<00:00, 3992.76it/s, Materializing param=roberta.encoder.layer.0.intermediate.denLoading weights:  10%| | 21/201 [00:00<00:00, 2028.52it/s, Materializing param=roberta.encoder.layer.0.intermediate.denLoading weights:  11%| | 22/201 [00:00<00:00, 2125.12it/s, Materializing param=roberta.encoder.layer.0.output.LayerNormLoading weights:  11%| | 22/201 [00:00<00:00, 2125.12it/s, Materializing param=roberta.encoder.layer.0.output.LayerNormLoading weights:  11%| | 23/201 [00:00<00:00, 2221.71it/s, Materializing param=roberta.encoder.layer.0.output.LayerNormLoading weights:  11%| | 23/201 [00:00<00:00, 2221.71it/s, Materializing param=roberta.encoder.layer.0.output.LayerNormLoading weights:  12%| | 24/201 [00:00<00:00, 2318.31it/s, Materializing param=roberta.encoder.layer.0.output.dense.biaLoading weights:  12%| | 24/201 [00:00<00:00, 2318.31it/s, Materializing param=roberta.encoder.layer.0.output.dense.biaLoading weights:  12%| | 25/201 [00:00<00:00, 2414.91it/s, Materializing param=roberta.encoder.layer.0.output.dense.weiLoading weights:  12%| | 25/201 [00:00<00:00, 2414.91it/s, Materializing param=roberta.encoder.layer.0.output.dense.weiLoading weights:  13%|▏| 26/201 [00:00<00:00, 2511.50it/s, Materializing param=roberta.encoder.layer.1.attention.outputLoading weights:  13%|▏| 26/201 [00:00<00:00, 2511.50it/s, Materializing param=roberta.encoder.layer.1.attention.outputLoading weights:  13%|▏| 27/201 [00:00<00:00, 2608.10it/s, Materializing param=roberta.encoder.layer.1.attention.outputLoading weights:  13%|▏| 27/201 [00:00<00:00, 2608.10it/s, Materializing param=roberta.encoder.layer.1.attention.outputLoading weights:  14%|▏| 28/201 [00:00<00:00, 2704.69it/s, Materializing param=roberta.encoder.layer.1.attention.outputLoading weights:  14%|▏| 28/201 [00:00<00:00, 2704.69it/s, Materializing param=roberta.encoder.layer.1.attention.outputLoading weights:  14%|▏| 29/201 [00:00<00:00, 2801.29it/s, Materializing param=roberta.encoder.layer.1.attention.outputLoading weights:  14%|▏| 29/201 [00:00<00:00, 2801.29it/s, Materializing param=roberta.encoder.layer.1.attention.outputLoading weights:  15%|▏| 30/201 [00:00<00:00, 2897.89it/s, Materializing param=roberta.encoder.layer.1.attention.self.kLoading weights:  15%|▏| 30/201 [00:00<00:00, 2897.89it/s, Materializing param=roberta.encoder.layer.1.attention.self.kLoading weights:  15%|▏| 31/201 [00:00<00:00, 2994.48it/s, Materializing param=roberta.encoder.layer.1.attention.self.kLoading weights:  15%|▏| 31/201 [00:00<00:00, 2994.48it/s, Materializing param=roberta.encoder.layer.1.attention.self.kLoading weights:  16%|▏| 32/201 [00:00<00:00, 3091.08it/s, Materializing param=roberta.encoder.layer.1.attention.self.qLoading weights:  16%|▏| 32/201 [00:00<00:00, 3091.08it/s, Materializing param=roberta.encoder.layer.1.attention.self.qLoading weights:  16%|▏| 33/201 [00:00<00:00, 3187.67it/s, Materializing param=roberta.encoder.layer.1.attention.self.qLoading weights:  16%|▏| 33/201 [00:00<00:00, 3187.67it/s, Materializing param=roberta.encoder.layer.1.attention.self.qLoading weights:  17%|▏| 34/201 [00:00<00:00, 3284.27it/s, Materializing param=roberta.encoder.layer.1.attention.self.vLoading weights:  17%|▏| 34/201 [00:00<00:00, 2203.61it/s, Materializing param=roberta.encoder.layer.1.attention.self.vLoading weights:  17%|▏| 35/201 [00:00<00:00, 2268.42it/s, Materializing param=roberta.encoder.layer.1.attention.self.vLoading weights:  17%|▏| 35/201 [00:00<00:00, 2268.42it/s, Materializing param=roberta.encoder.layer.1.attention.self.vLoading weights:  18%|▏| 36/201 [00:00<00:00, 2333.23it/s, Materializing param=roberta.encoder.layer.1.intermediate.denLoading weights:  18%|▏| 36/201 [00:00<00:00, 2333.23it/s, Materializing param=roberta.encoder.layer.1.intermediate.denLoading weights:  18%|▏| 37/201 [00:00<00:00, 2398.04it/s, Materializing param=roberta.encoder.layer.1.intermediate.denLoading weights:  18%|▏| 37/201 [00:00<00:00, 2398.04it/s, Materializing param=roberta.encoder.layer.1.intermediate.denLoading weights:  19%|▏| 38/201 [00:00<00:00, 2462.85it/s, Materializing param=roberta.encoder.layer.1.output.LayerNormLoading weights:  19%|▏| 38/201 [00:00<00:00, 2462.85it/s, Materializing param=roberta.encoder.layer.1.output.LayerNormLoading weights:  19%|▏| 39/201 [00:00<00:00, 2527.67it/s, Materializing param=roberta.encoder.layer.1.output.LayerNormLoading weights:  19%|▏| 39/201 [00:00<00:00, 2527.67it/s, Materializing param=roberta.encoder.layer.1.output.LayerNormLoading weights:  20%|▏| 40/201 [00:00<00:00, 2592.48it/s, Materializing param=roberta.encoder.layer.1.output.dense.biaLoading weights:  20%|▏| 40/201 [00:00<00:00, 2592.48it/s, Materializing param=roberta.encoder.layer.1.output.dense.biaLoading weights:  20%|▏| 41/201 [00:00<00:00, 2657.29it/s, Materializing param=roberta.encoder.layer.1.output.dense.weiLoading weights:  20%|▏| 41/201 [00:00<00:00, 2657.29it/s, Materializing param=roberta.encoder.layer.1.output.dense.weiLoading weights:  21%|▏| 42/201 [00:00<00:00, 2722.10it/s, Materializing param=roberta.encoder.layer.2.attention.outputLoading weights:  21%|▏| 42/201 [00:00<00:00, 2722.10it/s, Materializing param=roberta.encoder.layer.2.attention.outputLoading weights:  21%|▏| 43/201 [00:00<00:00, 2786.91it/s, Materializing param=roberta.encoder.layer.2.attention.outputLoading weights:  21%|▏| 43/201 [00:00<00:00, 2786.91it/s, Materializing param=roberta.encoder.layer.2.attention.outputLoading weights:  22%|▏| 44/201 [00:00<00:00, 2851.72it/s, Materializing param=roberta.encoder.layer.2.attention.outputLoading weights:  22%|▏| 44/201 [00:00<00:00, 2851.72it/s, Materializing param=roberta.encoder.layer.2.attention.outputLoading weights:  22%|▏| 45/201 [00:00<00:00, 2916.54it/s, Materializing param=roberta.encoder.layer.2.attention.outputLoading weights:  22%|▏| 45/201 [00:00<00:00, 2916.54it/s, Materializing param=roberta.encoder.layer.2.attention.outputLoading weights:  23%|▏| 46/201 [00:00<00:00, 2981.35it/s, Materializing param=roberta.encoder.layer.2.attention.self.kLoading weights:  23%|▏| 46/201 [00:00<00:00, 2981.35it/s, Materializing param=roberta.encoder.layer.2.attention.self.kLoading weights:  23%|▏| 47/201 [00:00<00:00, 2299.96it/s, Materializing param=roberta.encoder.layer.2.attention.self.kLoading weights:  23%|▏| 47/201 [00:00<00:00, 2299.96it/s, Materializing param=roberta.encoder.layer.2.attention.self.kLoading weights:  24%|▏| 48/201 [00:00<00:00, 2348.90it/s, Materializing param=roberta.encoder.layer.2.attention.self.qLoading weights:  24%|▏| 48/201 [00:00<00:00, 2348.90it/s, Materializing param=roberta.encoder.layer.2.attention.self.qLoading weights:  24%|▏| 49/201 [00:00<00:00, 2397.84it/s, Materializing param=roberta.encoder.layer.2.attention.self.qLoading weights:  24%|▏| 49/201 [00:00<00:00, 2397.84it/s, Materializing param=roberta.encoder.layer.2.attention.self.qLoading weights:  25%|▏| 50/201 [00:00<00:00, 2446.77it/s, Materializing param=roberta.encoder.layer.2.attention.self.vLoading weights:  25%|▏| 50/201 [00:00<00:00, 2446.77it/s, Materializing param=roberta.encoder.layer.2.attention.self.vLoading weights:  25%|▎| 51/201 [00:00<00:00, 2495.71it/s, Materializing param=roberta.encoder.layer.2.attention.self.vLoading weights:  25%|▎| 51/201 [00:00<00:00, 2495.71it/s, Materializing param=roberta.encoder.layer.2.attention.self.vLoading weights:  26%|▎| 52/201 [00:00<00:00, 2544.64it/s, Materializing param=roberta.encoder.layer.2.intermediate.denLoading weights:  26%|▎| 52/201 [00:00<00:00, 2544.64it/s, Materializing param=roberta.encoder.layer.2.intermediate.denLoading weights:  26%|▎| 53/201 [00:00<00:00, 2593.58it/s, Materializing param=roberta.encoder.layer.2.intermediate.denLoading weights:  26%|▎| 53/201 [00:00<00:00, 2593.58it/s, Materializing param=roberta.encoder.layer.2.intermediate.denLoading weights:  27%|▎| 54/201 [00:00<00:00, 2642.51it/s, Materializing param=roberta.encoder.layer.2.output.LayerNormLoading weights:  27%|▎| 54/201 [00:00<00:00, 2642.51it/s, Materializing param=roberta.encoder.layer.2.output.LayerNormLoading weights:  27%|▎| 55/201 [00:00<00:00, 2691.45it/s, Materializing param=roberta.encoder.layer.2.output.LayerNormLoading weights:  27%|▎| 55/201 [00:00<00:00, 2691.45it/s, Materializing param=roberta.encoder.layer.2.output.LayerNormLoading weights:  28%|▎| 56/201 [00:00<00:00, 2740.38it/s, Materializing param=roberta.encoder.layer.2.output.dense.biaLoading weights:  28%|▎| 56/201 [00:00<00:00, 2740.38it/s, Materializing param=roberta.encoder.layer.2.output.dense.biaLoading weights:  28%|▎| 57/201 [00:00<00:00, 2789.32it/s, Materializing param=roberta.encoder.layer.2.output.dense.weiLoading weights:  28%|▎| 57/201 [00:00<00:00, 2789.32it/s, Materializing param=roberta.encoder.layer.2.output.dense.weiLoading weights:  29%|▎| 58/201 [00:00<00:00, 2838.25it/s, Materializing param=roberta.encoder.layer.3.attention.outputLoading weights:  29%|▎| 58/201 [00:00<00:00, 2838.25it/s, Materializing param=roberta.encoder.layer.3.attention.outputLoading weights:  29%|▎| 59/201 [00:00<00:00, 2315.50it/s, Materializing param=roberta.encoder.layer.3.attention.outputLoading weights:  29%|▎| 59/201 [00:00<00:00, 2315.50it/s, Materializing param=roberta.encoder.layer.3.attention.outputLoading weights:  30%|▎| 60/201 [00:00<00:00, 2354.74it/s, Materializing param=roberta.encoder.layer.3.attention.outputLoading weights:  30%|▎| 60/201 [00:00<00:00, 2354.74it/s, Materializing param=roberta.encoder.layer.3.attention.outputLoading weights:  30%|▎| 61/201 [00:00<00:00, 2393.99it/s, Materializing param=roberta.encoder.layer.3.attention.outputLoading weights:  30%|▎| 61/201 [00:00<00:00, 2393.99it/s, Materializing param=roberta.encoder.layer.3.attention.outputLoading weights:  31%|▎| 62/201 [00:00<00:00, 2433.23it/s, Materializing param=roberta.encoder.layer.3.attention.self.kLoading weights:  31%|▎| 62/201 [00:00<00:00, 2433.23it/s, Materializing param=roberta.encoder.layer.3.attention.self.kLoading weights:  31%|▎| 63/201 [00:00<00:00, 2472.48it/s, Materializing param=roberta.encoder.layer.3.attention.self.kLoading weights:  31%|▎| 63/201 [00:00<00:00, 2472.48it/s, Materializing param=roberta.encoder.layer.3.attention.self.kLoading weights:  32%|▎| 64/201 [00:00<00:00, 2511.72it/s, Materializing param=roberta.encoder.layer.3.attention.self.qLoading weights:  32%|▎| 64/201 [00:00<00:00, 2511.72it/s, Materializing param=roberta.encoder.layer.3.attention.self.qLoading weights:  32%|▎| 65/201 [00:00<00:00, 2550.97it/s, Materializing param=roberta.encoder.layer.3.attention.self.qLoading weights:  32%|▎| 65/201 [00:00<00:00, 2550.97it/s, Materializing param=roberta.encoder.layer.3.attention.self.qLoading weights:  33%|▎| 66/201 [00:00<00:00, 2590.22it/s, Materializing param=roberta.encoder.layer.3.attention.self.vLoading weights:  33%|▎| 66/201 [00:00<00:00, 2590.22it/s, Materializing param=roberta.encoder.layer.3.attention.self.vLoading weights:  33%|▎| 67/201 [00:00<00:00, 2629.46it/s, Materializing param=roberta.encoder.layer.3.attention.self.vLoading weights:  33%|▎| 67/201 [00:00<00:00, 2629.46it/s, Materializing param=roberta.encoder.layer.3.attention.self.vLoading weights:  34%|▎| 68/201 [00:00<00:00, 2668.71it/s, Materializing param=roberta.encoder.layer.3.intermediate.denLoading weights:  34%|▎| 68/201 [00:00<00:00, 2668.71it/s, Materializing param=roberta.encoder.layer.3.intermediate.denLoading weights:  34%|▎| 69/201 [00:00<00:00, 2707.95it/s, Materializing param=roberta.encoder.layer.3.intermediate.denLoading weights:  34%|▎| 69/201 [00:00<00:00, 2707.95it/s, Materializing param=roberta.encoder.layer.3.intermediate.denLoading weights:  35%|▎| 70/201 [00:00<00:00, 2747.20it/s, Materializing param=roberta.encoder.layer.3.output.LayerNormLoading weights:  35%|▎| 70/201 [00:00<00:00, 2747.20it/s, Materializing param=roberta.encoder.layer.3.output.LayerNormLoading weights:  35%|▎| 71/201 [00:00<00:00, 2786.44it/s, Materializing param=roberta.encoder.layer.3.output.LayerNormLoading weights:  35%|▎| 71/201 [00:00<00:00, 2786.44it/s, Materializing param=roberta.encoder.layer.3.output.LayerNormLoading weights:  36%|▎| 72/201 [00:00<00:00, 2360.90it/s, Materializing param=roberta.encoder.layer.3.output.dense.biaLoading weights:  36%|▎| 72/201 [00:00<00:00, 2360.90it/s, Materializing param=roberta.encoder.layer.3.output.dense.biaLoading weights:  36%|▎| 73/201 [00:00<00:00, 2393.69it/s, Materializing param=roberta.encoder.layer.3.output.dense.weiLoading weights:  36%|▎| 73/201 [00:00<00:00, 2393.69it/s, Materializing param=roberta.encoder.layer.3.output.dense.weiLoading weights:  37%|▎| 74/201 [00:00<00:00, 2426.48it/s, Materializing param=roberta.encoder.layer.4.attention.outputLoading weights:  37%|▎| 74/201 [00:00<00:00, 2426.48it/s, Materializing param=roberta.encoder.layer.4.attention.outputLoading weights:  37%|▎| 75/201 [00:00<00:00, 2459.27it/s, Materializing param=roberta.encoder.layer.4.attention.outputLoading weights:  37%|▎| 75/201 [00:00<00:00, 2459.27it/s, Materializing param=roberta.encoder.layer.4.attention.outputLoading weights:  38%|▍| 76/201 [00:00<00:00, 2492.06it/s, Materializing param=roberta.encoder.layer.4.attention.outputLoading weights:  38%|▍| 76/201 [00:00<00:00, 2492.06it/s, Materializing param=roberta.encoder.layer.4.attention.outputLoading weights:  38%|▍| 77/201 [00:00<00:00, 2524.85it/s, Materializing param=roberta.encoder.layer.4.attention.outputLoading weights:  38%|▍| 77/201 [00:00<00:00, 2524.85it/s, Materializing param=roberta.encoder.layer.4.attention.outputLoading weights:  39%|▍| 78/201 [00:00<00:00, 2557.64it/s, Materializing param=roberta.encoder.layer.4.attention.self.kLoading weights:  39%|▍| 78/201 [00:00<00:00, 2557.64it/s, Materializing param=roberta.encoder.layer.4.attention.self.kLoading weights:  39%|▍| 79/201 [00:00<00:00, 2590.43it/s, Materializing param=roberta.encoder.layer.4.attention.self.kLoading weights:  39%|▍| 79/201 [00:00<00:00, 2590.43it/s, Materializing param=roberta.encoder.layer.4.attention.self.kLoading weights:  40%|▍| 80/201 [00:00<00:00, 2623.22it/s, Materializing param=roberta.encoder.layer.4.attention.self.qLoading weights:  40%|▍| 80/201 [00:00<00:00, 2623.22it/s, Materializing param=roberta.encoder.layer.4.attention.self.qLoading weights:  40%|▍| 81/201 [00:00<00:00, 2656.01it/s, Materializing param=roberta.encoder.layer.4.attention.self.qLoading weights:  40%|▍| 81/201 [00:00<00:00, 2656.01it/s, Materializing param=roberta.encoder.layer.4.attention.self.qLoading weights:  41%|▍| 82/201 [00:00<00:00, 2688.80it/s, Materializing param=roberta.encoder.layer.4.attention.self.vLoading weights:  41%|▍| 82/201 [00:00<00:00, 2688.80it/s, Materializing param=roberta.encoder.layer.4.attention.self.vLoading weights:  41%|▍| 83/201 [00:00<00:00, 2721.59it/s, Materializing param=roberta.encoder.layer.4.attention.self.vLoading weights:  41%|▍| 83/201 [00:00<00:00, 2721.59it/s, Materializing param=roberta.encoder.layer.4.attention.self.vLoading weights:  42%|▍| 84/201 [00:00<00:00, 2754.38it/s, Materializing param=roberta.encoder.layer.4.intermediate.denLoading weights:  42%|▍| 84/201 [00:00<00:00, 2754.38it/s, Materializing param=roberta.encoder.layer.4.intermediate.denLoading weights:  42%|▍| 85/201 [00:00<00:00, 2392.07it/s, Materializing param=roberta.encoder.layer.4.intermediate.denLoading weights:  42%|▍| 85/201 [00:00<00:00, 2392.07it/s, Materializing param=roberta.encoder.layer.4.intermediate.denLoading weights:  43%|▍| 86/201 [00:00<00:00, 2420.21it/s, Materializing param=roberta.encoder.layer.4.output.LayerNormLoading weights:  43%|▍| 86/201 [00:00<00:00, 2420.21it/s, Materializing param=roberta.encoder.layer.4.output.LayerNormLoading weights:  43%|▍| 87/201 [00:00<00:00, 2448.35it/s, Materializing param=roberta.encoder.layer.4.output.LayerNormLoading weights:  43%|▍| 87/201 [00:00<00:00, 2448.35it/s, Materializing param=roberta.encoder.layer.4.output.LayerNormLoading weights:  44%|▍| 88/201 [00:00<00:00, 2476.49it/s, Materializing param=roberta.encoder.layer.4.output.dense.biaLoading weights:  44%|▍| 88/201 [00:00<00:00, 2476.49it/s, Materializing param=roberta.encoder.layer.4.output.dense.biaLoading weights:  44%|▍| 89/201 [00:00<00:00, 2504.63it/s, Materializing param=roberta.encoder.layer.4.output.dense.weiLoading weights:  44%|▍| 89/201 [00:00<00:00, 2504.63it/s, Materializing param=roberta.encoder.layer.4.output.dense.weiLoading weights:  45%|▍| 90/201 [00:00<00:00, 2532.78it/s, Materializing param=roberta.encoder.layer.5.attention.outputLoading weights:  45%|▍| 90/201 [00:00<00:00, 2532.78it/s, Materializing param=roberta.encoder.layer.5.attention.outputLoading weights:  45%|▍| 91/201 [00:00<00:00, 2560.92it/s, Materializing param=roberta.encoder.layer.5.attention.outputLoading weights:  45%|▍| 91/201 [00:00<00:00, 2560.92it/s, Materializing param=roberta.encoder.layer.5.attention.outputLoading weights:  46%|▍| 92/201 [00:00<00:00, 2589.06it/s, Materializing param=roberta.encoder.layer.5.attention.outputLoading weights:  46%|▍| 92/201 [00:00<00:00, 2589.06it/s, Materializing param=roberta.encoder.layer.5.attention.outputLoading weights:  46%|▍| 93/201 [00:00<00:00, 2617.20it/s, Materializing param=roberta.encoder.layer.5.attention.outputLoading weights:  46%|▍| 93/201 [00:00<00:00, 2617.20it/s, Materializing param=roberta.encoder.layer.5.attention.outputLoading weights:  47%|▍| 94/201 [00:00<00:00, 2645.34it/s, Materializing param=roberta.encoder.layer.5.attention.self.kLoading weights:  47%|▍| 94/201 [00:00<00:00, 2645.34it/s, Materializing param=roberta.encoder.layer.5.attention.self.kLoading weights:  47%|▍| 95/201 [00:00<00:00, 2673.49it/s, Materializing param=roberta.encoder.layer.5.attention.self.kLoading weights:  47%|▍| 95/201 [00:00<00:00, 2673.49it/s, Materializing param=roberta.encoder.layer.5.attention.self.kLoading weights:  48%|▍| 96/201 [00:00<00:00, 2701.63it/s, Materializing param=roberta.encoder.layer.5.attention.self.qLoading weights:  48%|▍| 96/201 [00:00<00:00, 2367.96it/s, Materializing param=roberta.encoder.layer.5.attention.self.qLoading weights:  48%|▍| 97/201 [00:00<00:00, 2392.63it/s, Materializing param=roberta.encoder.layer.5.attention.self.qLoading weights:  48%|▍| 97/201 [00:00<00:00, 2392.63it/s, Materializing param=roberta.encoder.layer.5.attention.self.qLoading weights:  49%|▍| 98/201 [00:00<00:00, 2417.30it/s, Materializing param=roberta.encoder.layer.5.attention.self.vLoading weights:  49%|▍| 98/201 [00:00<00:00, 2417.30it/s, Materializing param=roberta.encoder.layer.5.attention.self.vLoading weights:  49%|▍| 99/201 [00:00<00:00, 2441.96it/s, Materializing param=roberta.encoder.layer.5.attention.self.vLoading weights:  49%|▍| 99/201 [00:00<00:00, 2441.96it/s, Materializing param=roberta.encoder.layer.5.attention.self.vLoading weights:  50%|▍| 100/201 [00:00<00:00, 2466.63it/s, Materializing param=roberta.encoder.layer.5.intermediate.deLoading weights:  50%|▍| 100/201 [00:00<00:00, 2466.63it/s, Materializing param=roberta.encoder.layer.5.intermediate.deLoading weights:  50%|▌| 101/201 [00:00<00:00, 2491.29it/s, Materializing param=roberta.encoder.layer.5.intermediate.deLoading weights:  50%|▌| 101/201 [00:00<00:00, 2491.29it/s, Materializing param=roberta.encoder.layer.5.intermediate.deLoading weights:  51%|▌| 102/201 [00:00<00:00, 2515.96it/s, Materializing param=roberta.encoder.layer.5.output.LayerNorLoading weights:  51%|▌| 102/201 [00:00<00:00, 2515.96it/s, Materializing param=roberta.encoder.layer.5.output.LayerNorLoading weights:  51%|▌| 103/201 [00:00<00:00, 2540.63it/s, Materializing param=roberta.encoder.layer.5.output.LayerNorLoading weights:  51%|▌| 103/201 [00:00<00:00, 2540.63it/s, Materializing param=roberta.encoder.layer.5.output.LayerNorLoading weights:  52%|▌| 104/201 [00:00<00:00, 2565.29it/s, Materializing param=roberta.encoder.layer.5.output.dense.biLoading weights:  52%|▌| 104/201 [00:00<00:00, 2565.29it/s, Materializing param=roberta.encoder.layer.5.output.dense.biLoading weights:  52%|▌| 105/201 [00:00<00:00, 2589.96it/s, Materializing param=roberta.encoder.layer.5.output.dense.weLoading weights:  52%|▌| 105/201 [00:00<00:00, 2589.96it/s, Materializing param=roberta.encoder.layer.5.output.dense.weLoading weights:  53%|▌| 106/201 [00:00<00:00, 2614.63it/s, Materializing param=roberta.encoder.layer.6.attention.outpuLoading weights:  53%|▌| 106/201 [00:00<00:00, 2614.63it/s, Materializing param=roberta.encoder.layer.6.attention.outpuLoading weights:  53%|▌| 107/201 [00:00<00:00, 2639.29it/s, Materializing param=roberta.encoder.layer.6.attention.outpuLoading weights:  53%|▌| 107/201 [00:00<00:00, 2639.29it/s, Materializing param=roberta.encoder.layer.6.attention.outpuLoading weights:  54%|▌| 108/201 [00:00<00:00, 2663.96it/s, Materializing param=roberta.encoder.layer.6.attention.outpuLoading weights:  54%|▌| 108/201 [00:00<00:00, 2663.96it/s, Materializing param=roberta.encoder.layer.6.attention.outpuLoading weights:  54%|▌| 109/201 [00:00<00:00, 2387.27it/s, Materializing param=roberta.encoder.layer.6.attention.outpuLoading weights:  54%|▌| 109/201 [00:00<00:00, 2387.27it/s, Materializing param=roberta.encoder.layer.6.attention.outpuLoading weights:  55%|▌| 110/201 [00:00<00:00, 2409.17it/s, Materializing param=roberta.encoder.layer.6.attention.self.Loading weights:  55%|▌| 110/201 [00:00<00:00, 2409.17it/s, Materializing param=roberta.encoder.layer.6.attention.self.Loading weights:  55%|▌| 111/201 [00:00<00:00, 2431.07it/s, Materializing param=roberta.encoder.layer.6.attention.self.Loading weights:  55%|▌| 111/201 [00:00<00:00, 2431.07it/s, Materializing param=roberta.encoder.layer.6.attention.self.Loading weights:  56%|▌| 112/201 [00:00<00:00, 2452.98it/s, Materializing param=roberta.encoder.layer.6.attention.self.Loading weights:  56%|▌| 112/201 [00:00<00:00, 2452.98it/s, Materializing param=roberta.encoder.layer.6.attention.self.Loading weights:  56%|▌| 113/201 [00:00<00:00, 2474.88it/s, Materializing param=roberta.encoder.layer.6.attention.self.Loading weights:  56%|▌| 113/201 [00:00<00:00, 2474.88it/s, Materializing param=roberta.encoder.layer.6.attention.self.Loading weights:  57%|▌| 114/201 [00:00<00:00, 2496.78it/s, Materializing param=roberta.encoder.layer.6.attention.self.Loading weights:  57%|▌| 114/201 [00:00<00:00, 2496.78it/s, Materializing param=roberta.encoder.layer.6.attention.self.Loading weights:  57%|▌| 115/201 [00:00<00:00, 2518.68it/s, Materializing param=roberta.encoder.layer.6.attention.self.Loading weights:  57%|▌| 115/201 [00:00<00:00, 2518.68it/s, Materializing param=roberta.encoder.layer.6.attention.self.Loading weights:  58%|▌| 116/201 [00:00<00:00, 2540.58it/s, Materializing param=roberta.encoder.layer.6.intermediate.deLoading weights:  58%|▌| 116/201 [00:00<00:00, 2540.58it/s, Materializing param=roberta.encoder.layer.6.intermediate.deLoading weights:  58%|▌| 117/201 [00:00<00:00, 2562.48it/s, Materializing param=roberta.encoder.layer.6.intermediate.deLoading weights:  58%|▌| 117/201 [00:00<00:00, 2562.48it/s, Materializing param=roberta.encoder.layer.6.intermediate.deLoading weights:  59%|▌| 118/201 [00:00<00:00, 2584.39it/s, Materializing param=roberta.encoder.layer.6.output.LayerNorLoading weights:  59%|▌| 118/201 [00:00<00:00, 2584.39it/s, Materializing param=roberta.encoder.layer.6.output.LayerNorLoading weights:  59%|▌| 119/201 [00:00<00:00, 2606.29it/s, Materializing param=roberta.encoder.layer.6.output.LayerNorLoading weights:  59%|▌| 119/201 [00:00<00:00, 2606.29it/s, Materializing param=roberta.encoder.layer.6.output.LayerNorLoading weights:  60%|▌| 120/201 [00:00<00:00, 2628.19it/s, Materializing param=roberta.encoder.layer.6.output.dense.biLoading weights:  60%|▌| 120/201 [00:00<00:00, 2628.19it/s, Materializing param=roberta.encoder.layer.6.output.dense.biLoading weights:  60%|▌| 121/201 [00:00<00:00, 2650.09it/s, Materializing param=roberta.encoder.layer.6.output.dense.weLoading weights:  60%|▌| 121/201 [00:00<00:00, 2650.09it/s, Materializing param=roberta.encoder.layer.6.output.dense.weLoading weights:  61%|▌| 122/201 [00:00<00:00, 2671.99it/s, Materializing param=roberta.encoder.layer.7.attention.outpuLoading weights:  61%|▌| 122/201 [00:00<00:00, 2404.50it/s, Materializing param=roberta.encoder.layer.7.attention.outpuLoading weights:  61%|▌| 123/201 [00:00<00:00, 2424.21it/s, Materializing param=roberta.encoder.layer.7.attention.outpuLoading weights:  61%|▌| 123/201 [00:00<00:00, 2424.21it/s, Materializing param=roberta.encoder.layer.7.attention.outpuLoading weights:  62%|▌| 124/201 [00:00<00:00, 2443.92it/s, Materializing param=roberta.encoder.layer.7.attention.outpuLoading weights:  62%|▌| 124/201 [00:00<00:00, 2443.92it/s, Materializing param=roberta.encoder.layer.7.attention.outpuLoading weights:  62%|▌| 125/201 [00:00<00:00, 2463.63it/s, Materializing param=roberta.encoder.layer.7.attention.outpuLoading weights:  62%|▌| 125/201 [00:00<00:00, 2463.63it/s, Materializing param=roberta.encoder.layer.7.attention.outpuLoading weights:  63%|▋| 126/201 [00:00<00:00, 2483.34it/s, Materializing param=roberta.encoder.layer.7.attention.self.Loading weights:  63%|▋| 126/201 [00:00<00:00, 2483.34it/s, Materializing param=roberta.encoder.layer.7.attention.self.Loading weights:  63%|▋| 127/201 [00:00<00:00, 2503.05it/s, Materializing param=roberta.encoder.layer.7.attention.self.Loading weights:  63%|▋| 127/201 [00:00<00:00, 2503.05it/s, Materializing param=roberta.encoder.layer.7.attention.self.Loading weights:  64%|▋| 128/201 [00:00<00:00, 2522.76it/s, Materializing param=roberta.encoder.layer.7.attention.self.Loading weights:  64%|▋| 128/201 [00:00<00:00, 2522.76it/s, Materializing param=roberta.encoder.layer.7.attention.self.Loading weights:  64%|▋| 129/201 [00:00<00:00, 2542.47it/s, Materializing param=roberta.encoder.layer.7.attention.self.Loading weights:  64%|▋| 129/201 [00:00<00:00, 2542.47it/s, Materializing param=roberta.encoder.layer.7.attention.self.Loading weights:  65%|▋| 130/201 [00:00<00:00, 2562.18it/s, Materializing param=roberta.encoder.layer.7.attention.self.Loading weights:  65%|▋| 130/201 [00:00<00:00, 2562.18it/s, Materializing param=roberta.encoder.layer.7.attention.self.Loading weights:  65%|▋| 131/201 [00:00<00:00, 2581.89it/s, Materializing param=roberta.encoder.layer.7.attention.self.Loading weights:  65%|▋| 131/201 [00:00<00:00, 2581.89it/s, Materializing param=roberta.encoder.layer.7.attention.self.Loading weights:  66%|▋| 132/201 [00:00<00:00, 2601.60it/s, Materializing param=roberta.encoder.layer.7.intermediate.deLoading weights:  66%|▋| 132/201 [00:00<00:00, 2601.60it/s, Materializing param=roberta.encoder.layer.7.intermediate.deLoading weights:  66%|▋| 133/201 [00:00<00:00, 2621.30it/s, Materializing param=roberta.encoder.layer.7.intermediate.deLoading weights:  66%|▋| 133/201 [00:00<00:00, 2621.30it/s, Materializing param=roberta.encoder.layer.7.intermediate.deLoading weights:  67%|▋| 134/201 [00:00<00:00, 2641.01it/s, Materializing param=roberta.encoder.layer.7.output.LayerNorLoading weights:  67%|▋| 134/201 [00:00<00:00, 2641.01it/s, Materializing param=roberta.encoder.layer.7.output.LayerNorLoading weights:  67%|▋| 135/201 [00:00<00:00, 2421.74it/s, Materializing param=roberta.encoder.layer.7.output.LayerNorLoading weights:  67%|▋| 135/201 [00:00<00:00, 2421.74it/s, Materializing param=roberta.encoder.layer.7.output.LayerNorLoading weights:  68%|▋| 136/201 [00:00<00:00, 2439.68it/s, Materializing param=roberta.encoder.layer.7.output.dense.biLoading weights:  68%|▋| 136/201 [00:00<00:00, 2439.68it/s, Materializing param=roberta.encoder.layer.7.output.dense.biLoading weights:  68%|▋| 137/201 [00:00<00:00, 2457.61it/s, Materializing param=roberta.encoder.layer.7.output.dense.weLoading weights:  68%|▋| 137/201 [00:00<00:00, 2457.61it/s, Materializing param=roberta.encoder.layer.7.output.dense.weLoading weights:  69%|▋| 138/201 [00:00<00:00, 2475.55it/s, Materializing param=roberta.encoder.layer.8.attention.outpuLoading weights:  69%|▋| 138/201 [00:00<00:00, 2475.55it/s, Materializing param=roberta.encoder.layer.8.attention.outpuLoading weights:  69%|▋| 139/201 [00:00<00:00, 2493.49it/s, Materializing param=roberta.encoder.layer.8.attention.outpuLoading weights:  69%|▋| 139/201 [00:00<00:00, 2493.49it/s, Materializing param=roberta.encoder.layer.8.attention.outpuLoading weights:  70%|▋| 140/201 [00:00<00:00, 2511.43it/s, Materializing param=roberta.encoder.layer.8.attention.outpuLoading weights:  70%|▋| 140/201 [00:00<00:00, 2511.43it/s, Materializing param=roberta.encoder.layer.8.attention.outpuLoading weights:  70%|▋| 141/201 [00:00<00:00, 2529.37it/s, Materializing param=roberta.encoder.layer.8.attention.outpuLoading weights:  70%|▋| 141/201 [00:00<00:00, 2529.37it/s, Materializing param=roberta.encoder.layer.8.attention.outpuLoading weights:  71%|▋| 142/201 [00:00<00:00, 2547.31it/s, Materializing param=roberta.encoder.layer.8.attention.self.Loading weights:  71%|▋| 142/201 [00:00<00:00, 2547.31it/s, Materializing param=roberta.encoder.layer.8.attention.self.Loading weights:  71%|▋| 143/201 [00:00<00:00, 2565.25it/s, Materializing param=roberta.encoder.layer.8.attention.self.Loading weights:  71%|▋| 143/201 [00:00<00:00, 2565.25it/s, Materializing param=roberta.encoder.layer.8.attention.self.Loading weights:  72%|▋| 144/201 [00:00<00:00, 2583.19it/s, Materializing param=roberta.encoder.layer.8.attention.self.Loading weights:  72%|▋| 144/201 [00:00<00:00, 2583.19it/s, Materializing param=roberta.encoder.layer.8.attention.self.Loading weights:  72%|▋| 145/201 [00:00<00:00, 2601.12it/s, Materializing param=roberta.encoder.layer.8.attention.self.Loading weights:  72%|▋| 145/201 [00:00<00:00, 2601.12it/s, Materializing param=roberta.encoder.layer.8.attention.self.Loading weights:  73%|▋| 146/201 [00:00<00:00, 2619.06it/s, Materializing param=roberta.encoder.layer.8.attention.self.Loading weights:  73%|▋| 146/201 [00:00<00:00, 2619.06it/s, Materializing param=roberta.encoder.layer.8.attention.self.Loading weights:  73%|▋| 147/201 [00:00<00:00, 2414.21it/s, Materializing param=roberta.encoder.layer.8.attention.self.Loading weights:  73%|▋| 147/201 [00:00<00:00, 2414.21it/s, Materializing param=roberta.encoder.layer.8.attention.self.Loading weights:  74%|▋| 148/201 [00:00<00:00, 2430.63it/s, Materializing param=roberta.encoder.layer.8.intermediate.deLoading weights:  74%|▋| 148/201 [00:00<00:00, 2430.63it/s, Materializing param=roberta.encoder.layer.8.intermediate.deLoading weights:  74%|▋| 149/201 [00:00<00:00, 2447.06it/s, Materializing param=roberta.encoder.layer.8.intermediate.deLoading weights:  74%|▋| 149/201 [00:00<00:00, 2447.06it/s, Materializing param=roberta.encoder.layer.8.intermediate.deLoading weights:  75%|▋| 150/201 [00:00<00:00, 2463.48it/s, Materializing param=roberta.encoder.layer.8.output.LayerNorLoading weights:  75%|▋| 150/201 [00:00<00:00, 2463.48it/s, Materializing param=roberta.encoder.layer.8.output.LayerNorLoading weights:  75%|▊| 151/201 [00:00<00:00, 2479.90it/s, Materializing param=roberta.encoder.layer.8.output.LayerNorLoading weights:  75%|▊| 151/201 [00:00<00:00, 2479.90it/s, Materializing param=roberta.encoder.layer.8.output.LayerNorLoading weights:  76%|▊| 152/201 [00:00<00:00, 2496.33it/s, Materializing param=roberta.encoder.layer.8.output.dense.biLoading weights:  76%|▊| 152/201 [00:00<00:00, 2496.33it/s, Materializing param=roberta.encoder.layer.8.output.dense.biLoading weights:  76%|▊| 153/201 [00:00<00:00, 2512.75it/s, Materializing param=roberta.encoder.layer.8.output.dense.weLoading weights:  76%|▊| 153/201 [00:00<00:00, 2512.75it/s, Materializing param=roberta.encoder.layer.8.output.dense.weLoading weights:  77%|▊| 154/201 [00:00<00:00, 2529.17it/s, Materializing param=roberta.encoder.layer.9.attention.outpuLoading weights:  77%|▊| 154/201 [00:00<00:00, 2529.17it/s, Materializing param=roberta.encoder.layer.9.attention.outpuLoading weights:  77%|▊| 155/201 [00:00<00:00, 2545.60it/s, Materializing param=roberta.encoder.layer.9.attention.outpuLoading weights:  77%|▊| 155/201 [00:00<00:00, 2545.60it/s, Materializing param=roberta.encoder.layer.9.attention.outpuLoading weights:  78%|▊| 156/201 [00:00<00:00, 2352.63it/s, Materializing param=roberta.encoder.layer.9.attention.outpuLoading weights:  78%|▊| 156/201 [00:00<00:00, 2352.63it/s, Materializing param=roberta.encoder.layer.9.attention.outpuLoading weights:  78%|▊| 157/201 [00:00<00:00, 2367.71it/s, Materializing param=roberta.encoder.layer.9.attention.outpuLoading weights:  78%|▊| 157/201 [00:00<00:00, 2367.71it/s, Materializing param=roberta.encoder.layer.9.attention.outpuLoading weights:  79%|▊| 158/201 [00:00<00:00, 2382.79it/s, Materializing param=roberta.encoder.layer.9.attention.self.Loading weights:  79%|▊| 158/201 [00:00<00:00, 2382.79it/s, Materializing param=roberta.encoder.layer.9.attention.self.Loading weights:  79%|▊| 159/201 [00:00<00:00, 2397.87it/s, Materializing param=roberta.encoder.layer.9.attention.self.Loading weights:  79%|▊| 159/201 [00:00<00:00, 2397.87it/s, Materializing param=roberta.encoder.layer.9.attention.self.Loading weights:  80%|▊| 160/201 [00:00<00:00, 2412.96it/s, Materializing param=roberta.encoder.layer.9.attention.self.Loading weights:  80%|▊| 160/201 [00:00<00:00, 2342.07it/s, Materializing param=roberta.encoder.layer.9.attention.self.Loading weights:  80%|▊| 161/201 [00:00<00:00, 2356.70it/s, Materializing param=roberta.encoder.layer.9.attention.self.Loading weights:  80%|▊| 161/201 [00:00<00:00, 2356.70it/s, Materializing param=roberta.encoder.layer.9.attention.self.Loading weights:  81%|▊| 162/201 [00:00<00:00, 2371.34it/s, Materializing param=roberta.encoder.layer.9.attention.self.Loading weights:  81%|▊| 162/201 [00:00<00:00, 2371.34it/s, Materializing param=roberta.encoder.layer.9.attention.self.Loading weights:  81%|▊| 163/201 [00:00<00:00, 2385.98it/s, Materializing param=roberta.encoder.layer.9.attention.self.Loading weights:  81%|▊| 163/201 [00:00<00:00, 2385.98it/s, Materializing param=roberta.encoder.layer.9.attention.self.Loading weights:  82%|▊| 164/201 [00:00<00:00, 2400.62it/s, Materializing param=roberta.encoder.layer.9.intermediate.deLoading weights:  82%|▊| 164/201 [00:00<00:00, 2400.62it/s, Materializing param=roberta.encoder.layer.9.intermediate.deLoading weights:  82%|▊| 165/201 [00:00<00:00, 2346.36it/s, Materializing param=roberta.encoder.layer.9.intermediate.deLoading weights:  82%|▊| 165/201 [00:00<00:00, 2346.36it/s, Materializing param=roberta.encoder.layer.9.intermediate.deLoading weights:  83%|▊| 166/201 [00:00<00:00, 2360.58it/s, Materializing param=roberta.encoder.layer.9.output.LayerNorLoading weights:  83%|▊| 166/201 [00:00<00:00, 2360.58it/s, Materializing param=roberta.encoder.layer.9.output.LayerNorLoading weights:  83%|▊| 167/201 [00:00<00:00, 2374.80it/s, Materializing param=roberta.encoder.layer.9.output.LayerNorLoading weights:  83%|▊| 167/201 [00:00<00:00, 2341.33it/s, Materializing param=roberta.encoder.layer.9.output.LayerNorLoading weights:  84%|▊| 168/201 [00:00<00:00, 2355.35it/s, Materializing param=roberta.encoder.layer.9.output.dense.biLoading weights:  84%|▊| 168/201 [00:00<00:00, 2355.35it/s, Materializing param=roberta.encoder.layer.9.output.dense.biLoading weights:  84%|▊| 169/201 [00:00<00:00, 2369.37it/s, Materializing param=roberta.encoder.layer.9.output.dense.weLoading weights:  84%|▊| 169/201 [00:00<00:00, 2369.37it/s, Materializing param=roberta.encoder.layer.9.output.dense.weLoading weights:  85%|▊| 170/201 [00:00<00:00, 2383.39it/s, Materializing param=roberta.encoder.layer.10.attention.outpLoading weights:  85%|▊| 170/201 [00:00<00:00, 2383.39it/s, Materializing param=roberta.encoder.layer.10.attention.outpLoading weights:  85%|▊| 171/201 [00:00<00:00, 2397.41it/s, Materializing param=roberta.encoder.layer.10.attention.outpLoading weights:  85%|▊| 171/201 [00:00<00:00, 2397.41it/s, Materializing param=roberta.encoder.layer.10.attention.outpLoading weights:  86%|▊| 172/201 [00:00<00:00, 2345.47it/s, Materializing param=roberta.encoder.layer.10.attention.outpLoading weights:  86%|▊| 172/201 [00:00<00:00, 2345.47it/s, Materializing param=roberta.encoder.layer.10.attention.outpLoading weights:  86%|▊| 173/201 [00:00<00:00, 2359.11it/s, Materializing param=roberta.encoder.layer.10.attention.outpLoading weights:  86%|▊| 173/201 [00:00<00:00, 2359.11it/s, Materializing param=roberta.encoder.layer.10.attention.outpLoading weights:  87%|▊| 174/201 [00:00<00:00, 2372.74it/s, Materializing param=roberta.encoder.layer.10.attention.selfLoading weights:  87%|▊| 174/201 [00:00<00:00, 2372.74it/s, Materializing param=roberta.encoder.layer.10.attention.selfLoading weights:  87%|▊| 175/201 [00:00<00:00, 2386.38it/s, Materializing param=roberta.encoder.layer.10.attention.selfLoading weights:  87%|▊| 175/201 [00:00<00:00, 2322.85it/s, Materializing param=roberta.encoder.layer.10.attention.selfLoading weights:  88%|▉| 176/201 [00:00<00:00, 2336.13it/s, Materializing param=roberta.encoder.layer.10.attention.selfLoading weights:  88%|▉| 176/201 [00:00<00:00, 2336.13it/s, Materializing param=roberta.encoder.layer.10.attention.selfLoading weights:  88%|▉| 177/201 [00:00<00:00, 2349.40it/s, Materializing param=roberta.encoder.layer.10.attention.selfLoading weights:  88%|▉| 177/201 [00:00<00:00, 2349.40it/s, Materializing param=roberta.encoder.layer.10.attention.selfLoading weights:  89%|▉| 178/201 [00:00<00:00, 2331.60it/s, Materializing param=roberta.encoder.layer.10.attention.selfLoading weights:  89%|▉| 178/201 [00:00<00:00, 2331.60it/s, Materializing param=roberta.encoder.layer.10.attention.selfLoading weights:  89%|▉| 179/201 [00:00<00:00, 2344.69it/s, Materializing param=roberta.encoder.layer.10.attention.selfLoading weights:  89%|▉| 179/201 [00:00<00:00, 2344.69it/s, Materializing param=roberta.encoder.layer.10.attention.selfLoading weights:  90%|▉| 180/201 [00:00<00:00, 2357.79it/s, Materializing param=roberta.encoder.layer.10.intermediate.dLoading weights:  90%|▉| 180/201 [00:00<00:00, 2357.79it/s, Materializing param=roberta.encoder.layer.10.intermediate.dLoading weights:  90%|▉| 181/201 [00:00<00:00, 2370.89it/s, Materializing param=roberta.encoder.layer.10.intermediate.dLoading weights:  90%|▉| 181/201 [00:00<00:00, 2370.89it/s, Materializing param=roberta.encoder.layer.10.intermediate.dLoading weights:  91%|▉| 182/201 [00:00<00:00, 2322.93it/s, Materializing param=roberta.encoder.layer.10.output.LayerNoLoading weights:  91%|▉| 182/201 [00:00<00:00, 2322.93it/s, Materializing param=roberta.encoder.layer.10.output.LayerNoLoading weights:  91%|▉| 183/201 [00:00<00:00, 2335.69it/s, Materializing param=roberta.encoder.layer.10.output.LayerNoLoading weights:  91%|▉| 183/201 [00:00<00:00, 2335.69it/s, Materializing param=roberta.encoder.layer.10.output.LayerNoLoading weights:  92%|▉| 184/201 [00:00<00:00, 2348.46it/s, Materializing param=roberta.encoder.layer.10.output.dense.bLoading weights:  92%|▉| 184/201 [00:00<00:00, 2348.46it/s, Materializing param=roberta.encoder.layer.10.output.dense.bLoading weights:  92%|▉| 185/201 [00:00<00:00, 2361.22it/s, Materializing param=roberta.encoder.layer.10.output.dense.wLoading weights:  92%|▉| 185/201 [00:00<00:00, 2361.22it/s, Materializing param=roberta.encoder.layer.10.output.dense.wLoading weights:  93%|▉| 186/201 [00:00<00:00, 2373.98it/s, Materializing param=roberta.encoder.layer.11.attention.outpLoading weights:  93%|▉| 186/201 [00:00<00:00, 2373.98it/s, Materializing param=roberta.encoder.layer.11.attention.outpLoading weights:  93%|▉| 187/201 [00:00<00:00, 2327.18it/s, Materializing param=roberta.encoder.layer.11.attention.outpLoading weights:  93%|▉| 187/201 [00:00<00:00, 2327.18it/s, Materializing param=roberta.encoder.layer.11.attention.outpLoading weights:  94%|▉| 188/201 [00:00<00:00, 2339.62it/s, Materializing param=roberta.encoder.layer.11.attention.outpLoading weights:  94%|▉| 188/201 [00:00<00:00, 2310.68it/s, Materializing param=roberta.encoder.layer.11.attention.outpLoading weights:  94%|▉| 189/201 [00:00<00:00, 2322.97it/s, Materializing param=roberta.encoder.layer.11.attention.outpLoading weights:  94%|▉| 189/201 [00:00<00:00, 2322.97it/s, Materializing param=roberta.encoder.layer.11.attention.outpLoading weights:  95%|▉| 190/201 [00:00<00:00, 2335.26it/s, Materializing param=roberta.encoder.layer.11.attention.selfLoading weights:  95%|▉| 190/201 [00:00<00:00, 2335.26it/s, Materializing param=roberta.encoder.layer.11.attention.selfLoading weights:  95%|▉| 191/201 [00:00<00:00, 2347.55it/s, Materializing param=roberta.encoder.layer.11.attention.selfLoading weights:  95%|▉| 191/201 [00:00<00:00, 2347.55it/s, Materializing param=roberta.encoder.layer.11.attention.selfLoading weights:  96%|▉| 192/201 [00:00<00:00, 2359.84it/s, Materializing param=roberta.encoder.layer.11.attention.selfLoading weights:  96%|▉| 192/201 [00:00<00:00, 2359.84it/s, Materializing param=roberta.encoder.layer.11.attention.selfLoading weights:  96%|▉| 193/201 [00:00<00:00, 2372.14it/s, Materializing param=roberta.encoder.layer.11.attention.selfLoading weights:  96%|▉| 193/201 [00:00<00:00, 2372.14it/s, Materializing param=roberta.encoder.layer.11.attention.selfLoading weights:  97%|▉| 194/201 [00:00<00:00, 2384.43it/s, Materializing param=roberta.encoder.layer.11.attention.selfLoading weights:  97%|▉| 194/201 [00:00<00:00, 2384.43it/s, Materializing param=roberta.encoder.layer.11.attention.selfLoading weights:  97%|▉| 195/201 [00:00<00:00, 2396.72it/s, Materializing param=roberta.encoder.layer.11.attention.selfLoading weights:  97%|▉| 195/201 [00:00<00:00, 2396.72it/s, Materializing param=roberta.encoder.layer.11.attention.selfLoading weights:  98%|▉| 196/201 [00:00<00:00, 2409.01it/s, Materializing param=roberta.encoder.layer.11.intermediate.dLoading weights:  98%|▉| 196/201 [00:00<00:00, 2409.01it/s, Materializing param=roberta.encoder.layer.11.intermediate.dLoading weights:  98%|▉| 197/201 [00:00<00:00, 2421.30it/s, Materializing param=roberta.encoder.layer.11.intermediate.dLoading weights:  98%|▉| 197/201 [00:00<00:00, 2421.30it/s, Materializing param=roberta.encoder.layer.11.intermediate.dLoading weights:  99%|▉| 198/201 [00:00<00:00, 2433.59it/s, Materializing param=roberta.encoder.layer.11.output.LayerNoLoading weights:  99%|▉| 198/201 [00:00<00:00, 2433.59it/s, Materializing param=roberta.encoder.layer.11.output.LayerNoLoading weights:  99%|▉| 199/201 [00:00<00:00, 2445.88it/s, Materializing param=roberta.encoder.layer.11.output.LayerNoLoading weights:  99%|▉| 199/201 [00:00<00:00, 2445.88it/s, Materializing param=roberta.encoder.layer.11.output.LayerNoLoading weights: 100%|▉| 200/201 [00:00<00:00, 2458.17it/s, Materializing param=roberta.encoder.layer.11.output.dense.bLoading weights: 100%|▉| 200/201 [00:00<00:00, 2458.17it/s, Materializing param=roberta.encoder.layer.11.output.dense.bLoading weights: 100%|█| 201/201 [00:00<00:00, 2320.10it/s, Materializing param=roberta.encoder.layer.11.output.dense.wLoading weights: 100%|█| 201/201 [00:00<00:00, 2320.10it/s, Materializing param=roberta.encoder.layer.11.output.dense.wLoading weights: 100%|█| 201/201 [00:00<00:00, 2320.10it/s, Materializing param=roberta.encoder.layer.11.output.dense.w
[1mXLMRobertaForSequenceClassification LOAD REPORT[0m from: cardiffnlp/twitter-xlm-roberta-base-sentiment-multilingual
Key                             | Status     |  | 
--------------------------------+------------+--+-
roberta.embeddings.position_ids | [38;5;208mUNEXPECTED[0m |  | 

[3mNotes:
- [38;5;208mUNEXPECTED[0m[3m	:can be ignored when loading from different task/architecture; not ok if you expect identical arch.[0m
Sentiment model loaded: cardiffnlp/twitter-xlm-roberta-base-sentiment-multilingual

Extracting sentiment features for dataset 30 (en)...
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  Sentiment: 50/275 users processed
  Sentiment: 100/275 users processed
  Sentiment: 150/275 users processed
  Sentiment: 200/275 users processed
  Sentiment: 250/275 users processed
  Shape: (275, 10)

Extracting sentiment features for dataset 31 (fr)...
  Sentiment: 50/171 users processed
  Sentiment: 100/171 users processed
  Sentiment: 150/171 users processed
  Shape: (171, 10)

Extracting sentiment features for dataset 32 (en)...
  Sentiment: 50/271 users processed
  Sentiment: 100/271 users processed
  Sentiment: 150/271 users processed
  Sentiment: 200/271 users processed
  Sentiment: 250/271 users processed
  Shape: (271, 10)

Extracting sentiment features for dataset 33 (fr)...
  Sentiment: 50/172 users processed
  Sentiment: 100/172 users processed
  Sentiment: 150/172 users processed
  Shape: (172, 10)

Sentiment feature extraction complete!

Combining features for dataset 30...
  Final feature shape: (275, 149)

Combining features for dataset 31...
  Final feature shape: (171, 149)

Combining features for dataset 32...
  Final feature shape: (271, 149)

Combining features for dataset 33...
  Final feature shape: (172, 149)

Total features: 147
Features: ['tweet_count', 'z_score', 'username_length', 'username_digit_ratio', 'username_underscore_count', 'username_upper_ratio', 'username_has_numbers', 'name_length', 'name_emoji_count', 'name_word_count', 'has_description', 'description_length', 'description_emoji_count', 'description_word_count', 'description_hashtag_count', 'description_url_count', 'description_pipe_count', 'has_location', 'location_length', 'time_span_hours', 'posting_frequency', 'avg_interval', 'std_interval', 'min_interval', 'max_interval', 'median_interval', 'cv_interval', 'interval_skewness', 'interval_kurtosis', 'hour_entropy', 'night_post_ratio', 'morning_post_ratio', 'evening_post_ratio', 'burst_count_60s', 'burst_count_300s', 'unique_hours', 'unique_days', 'weekend_ratio', 'posts_per_day_std', 'max_posts_in_hour', 'regularity_score', 'avg_length_chars', 'avg_length_words', 'std_length_chars', 'vocabulary_richness', 'hapax_ratio', 'avg_hashtags', 'avg_urls', 'avg_mentions', 'emoji_rate', 'avg_exclamation', 'avg_question', 'avg_uppercase_ratio', 'avg_punctuation_ratio', 'duplicate_ratio', 'near_duplicate_ratio', 'avg_sentence_count', 'avg_word_length', 'link_tweet_ratio', 'retweet_ratio', 'time_dna_self_sim_hour', 'time_dna_self_sim_minute', 'time_dna_unique_3gram_ratio', 'iat_exponential_ks_stat', 'iat_exponential_ks_pvalue', 'iat_gini_coefficient', 'iat_benford_deviation', 'session_count', 'avg_session_length', 'max_session_length', 'avg_inter_session_gap', 'session_regularity', 'posting_acceleration', 'longest_active_streak_hours', 'minute_entropy', 'day_of_week_entropy', 'second_entropy', 'second_mode_frequency', 'round_second_ratio', 'interval_autocorr_lag1', 'interval_fft_peak_strength', 'ngram2_repetition', 'ngram3_repetition', 'pairwise_jaccard_mean', 'pairwise_jaccard_std', 'pairwise_jaccard_max', 'zipf_deviation', 'compression_ratio', 'text_char_entropy', 'punctuation_pattern_std', 'sentence_length_cv', 'avg_word_length_std', 'unique_first_words_ratio', 'url_pattern_regularity', 'mention_diversity', 'hashtag_diversity', 'mention_total_count', 'mention_unique_count', 'mention_unique_ratio', 'mention_entropy', 'mention_concentration_top3', 'mention_in_dataset_ratio', 'mention_self_ratio', 'is_mentioned_count', 'is_mentioned_ratio', 'mention_reciprocity', 'emb_avg_sim', 'emb_std_sim', 'emb_min_sim', 'emb_max_sim', 'emb_median_sim', 'ppl_mean', 'ppl_std', 'ppl_min', 'ppl_max', 'ppl_median', 'ppl_skew', 'ppl_low_ratio', 'sequential_coherence_mean', 'sequential_coherence_std', 'sequential_coherence_min', 'topic_diversity_score', 'topic_embedding_spread', 'topic_cluster_count', 'topic_dominant_cluster_ratio', 'topic_switch_rate', 'sentiment_mean', 'sentiment_std', 'sentiment_positive_ratio', 'sentiment_negative_ratio', 'sentiment_neutral_ratio', 'sentiment_extreme_ratio', 'sentiment_monotony', 'sentiment_confidence_mean', 'sentiment_confidence_std', 'cross_avg_sim', 'cross_max_sim', 'cross_min_sim', 'cross_std_sim', 'emb_cluster_id', 'emb_cluster_prob', 'emb_cluster_size', 'emb_is_noise', 'temp_cluster_id', 'temp_cluster_prob', 'temp_cluster_size', 'temp_is_noise']

[GPU] Releasing NLP models from GPU to free VRAM for tree model training...
  Perplexity models released.
  Sentiment pipeline released.
  Sentence Transformer released.
  GPU memory after cleanup: 4.9 GB free / 6.0 GB total
[GPU] Cleanup complete. Ready for tree model training.

Training functions defined.
[Local] Hyperparameters will be saved to: C:\Users\XuRui\Downloads\Bot-or-Not-main\Bot-or-Not-main\saved_hyperparams
[Run]   Hyperparameters snapshot: C:\Users\XuRui\Downloads\Bot-or-Not-main\Bot-or-Not-main\runs\max_v3_20260214_074700\hyperparams
Optuna hyperparameter optimization function defined.
Hyperparameter save/load utilities defined.

############################################################
Training on Dataset 30 -> Testing on Dataset 32 (English)
############################################################
  Running Optuna hyperparameter optimization (200 trials)...
  0%|                                                                                          | 0/200 [00:00<?, ?it/s]Best trial: 0. Best value: 84:   0%|                                                           | 0/200 [05:31<?, ?it/s]Best trial: 0. Best value: 84:   0%|▏                                              | 1/200 [05:31<18:20:26, 331.79s/it]Best trial: 0. Best value: 84:   0%|▏                                              | 1/200 [07:02<18:20:26, 331.79s/it]Best trial: 0. Best value: 84:   1%|▍                                              | 2/200 [07:02<10:27:24, 190.12s/it]Best trial: 0. Best value: 84:   1%|▍                                              | 2/200 [08:07<10:27:24, 190.12s/it]Best trial: 0. Best value: 84:   2%|▋                                               | 3/200 [08:07<7:16:29, 132.94s/it]Best trial: 0. Best value: 84:   2%|▋                                               | 3/200 [10:30<7:16:29, 132.94s/it]Best trial: 0. Best value: 84:   2%|▉                                               | 4/200 [10:30<7:27:03, 136.86s/it]Best trial: 0. Best value: 84:   2%|▉                                               | 4/200 [11:15<7:27:03, 136.86s/it]Best trial: 0. Best value: 84:   2%|█▏                                              | 5/200 [11:15<5:36:40, 103.59s/it]Best trial: 0. Best value: 84:   2%|█▏                                              | 5/200 [12:48<5:36:40, 103.59s/it]Best trial: 0. Best value: 84:   3%|█▍                                              | 6/200 [12:48<5:24:14, 100.28s/it]Best trial: 0. Best value: 84:   3%|█▍                                              | 6/200 [20:55<5:24:14, 100.28s/it]Best trial: 0. Best value: 84:   4%|█▋                                             | 7/200 [20:55<12:08:29, 226.48s/it]Best trial: 7. Best value: 84.3333:   4%|█▍                                        | 7/200 [21:51<12:08:29, 226.48s/it]Best trial: 7. Best value: 84.3333:   4%|█▋                                         | 8/200 [21:51<9:11:18, 172.28s/it]Best trial: 7. Best value: 84.3333:   4%|█▋                                         | 8/200 [21:57<9:11:18, 172.28s/it]Best trial: 7. Best value: 84.3333:   4%|█▉                                         | 9/200 [21:57<6:22:37, 120.20s/it]Best trial: 7. Best value: 84.3333:   4%|█▉                                         | 9/200 [23:28<6:22:37, 120.20s/it]Best trial: 7. Best value: 84.3333:   5%|██                                        | 10/200 [23:28<5:51:55, 111.13s/it]Best trial: 10. Best value: 85.3333:   5%|██                                       | 10/200 [23:39<5:51:55, 111.13s/it]Best trial: 10. Best value: 85.3333:   6%|██▎                                       | 11/200 [23:39<4:14:08, 80.68s/it]Best trial: 10. Best value: 85.3333:   6%|██▎                                       | 11/200 [23:45<4:14:08, 80.68s/it]Best trial: 10. Best value: 85.3333:   6%|██▌                                       | 12/200 [23:45<3:01:03, 57.79s/it]Best trial: 10. Best value: 85.3333:   6%|██▌                                       | 12/200 [23:53<3:01:03, 57.79s/it]Best trial: 10. Best value: 85.3333:   6%|██▋                                       | 13/200 [23:53<2:13:54, 42.97s/it]Best trial: 10. Best value: 85.3333:   6%|██▋                                       | 13/200 [24:17<2:13:54, 42.97s/it]Best trial: 10. Best value: 85.3333:   7%|██▉                                       | 14/200 [24:17<1:54:47, 37.03s/it]Best trial: 10. Best value: 85.3333:   7%|██▉                                       | 14/200 [35:04<1:54:47, 37.03s/it]Best trial: 10. Best value: 85.3333:   8%|███                                     | 15/200 [35:04<11:21:24, 221.00s/it]Best trial: 10. Best value: 85.3333:   8%|███                                     | 15/200 [35:19<11:21:24, 221.00s/it]Best trial: 10. Best value: 85.3333:   8%|███▎                                     | 16/200 [35:19<8:07:22, 158.93s/it]Best trial: 10. Best value: 85.3333:   8%|███▎                                     | 16/200 [35:25<8:07:22, 158.93s/it]Best trial: 10. Best value: 85.3333:   8%|███▍                                     | 17/200 [35:25<5:44:29, 112.95s/it]Best trial: 10. Best value: 85.3333:   8%|███▍                                     | 17/200 [35:36<5:44:29, 112.95s/it]Best trial: 10. Best value: 85.3333:   9%|███▊                                      | 18/200 [35:36<4:09:42, 82.32s/it]Best trial: 10. Best value: 85.3333:   9%|███▊                                      | 18/200 [39:49<4:09:42, 82.32s/it]Best trial: 10. Best value: 85.3333:  10%|███▉                                     | 19/200 [39:49<6:43:13, 133.66s/it]Best trial: 10. Best value: 85.3333:  10%|███▉                                     | 19/200 [40:01<6:43:13, 133.66s/it]Best trial: 10. Best value: 85.3333:  10%|████▏                                     | 20/200 [40:01<4:51:28, 97.16s/it]Best trial: 10. Best value: 85.3333:  10%|████▏                                     | 20/200 [40:11<4:51:28, 97.16s/it]Best trial: 10. Best value: 85.3333:  10%|████▍                                     | 21/200 [40:11<3:31:34, 70.92s/it]Best trial: 10. Best value: 85.3333:  10%|████▍                                     | 21/200 [40:24<3:31:34, 70.92s/it]Best trial: 10. Best value: 85.3333:  11%|████▌                                     | 22/200 [40:24<2:38:24, 53.40s/it]Best trial: 10. Best value: 85.3333:  11%|████▌                                     | 22/200 [40:48<2:38:24, 53.40s/it]Best trial: 10. Best value: 85.3333:  12%|████▊                                     | 23/200 [40:48<2:11:32, 44.59s/it]Best trial: 10. Best value: 85.3333:  12%|████▊                                     | 23/200 [40:54<2:11:32, 44.59s/it]Best trial: 10. Best value: 85.3333:  12%|█████                                     | 24/200 [40:54<1:37:29, 33.24s/it]Best trial: 10. Best value: 85.3333:  12%|█████                                     | 24/200 [44:34<1:37:29, 33.24s/it]Best trial: 10. Best value: 85.3333:  12%|█████▎                                    | 25/200 [44:34<4:20:07, 89.19s/it]Best trial: 10. Best value: 85.3333:  12%|█████▎                                    | 25/200 [44:46<4:20:07, 89.19s/it]Best trial: 10. Best value: 85.3333:  13%|█████▍                                    | 26/200 [44:46<3:11:50, 66.15s/it]Best trial: 10. Best value: 85.3333:  13%|█████▍                                    | 26/200 [47:16<3:11:50, 66.15s/it]Best trial: 10. Best value: 85.3333:  14%|█████▋                                    | 27/200 [47:16<4:23:01, 91.22s/it]Best trial: 10. Best value: 85.3333:  14%|█████▋                                    | 27/200 [48:19<4:23:01, 91.22s/it]Best trial: 10. Best value: 85.3333:  14%|█████▉                                    | 28/200 [48:19<3:57:01, 82.69s/it]Best trial: 10. Best value: 85.3333:  14%|█████▉                                    | 28/200 [48:40<3:57:01, 82.69s/it]Best trial: 10. Best value: 85.3333:  14%|██████                                    | 29/200 [48:40<3:03:06, 64.25s/it]Best trial: 10. Best value: 85.3333:  14%|██████                                    | 29/200 [50:28<3:03:06, 64.25s/it]Best trial: 10. Best value: 85.3333:  15%|██████▎                                   | 30/200 [50:28<3:39:18, 77.40s/it]Best trial: 10. Best value: 85.3333:  15%|██████▎                                   | 30/200 [50:38<3:39:18, 77.40s/it]Best trial: 10. Best value: 85.3333:  16%|██████▌                                   | 31/200 [50:38<2:40:35, 57.02s/it]Best trial: 10. Best value: 85.3333:  16%|██████▌                                   | 31/200 [51:40<2:40:35, 57.02s/it]Best trial: 10. Best value: 85.3333:  16%|██████▋                                   | 32/200 [51:40<2:44:22, 58.70s/it]Best trial: 10. Best value: 85.3333:  16%|██████▋                                   | 32/200 [52:57<2:44:22, 58.70s/it]Best trial: 10. Best value: 85.3333:  16%|██████▉                                   | 33/200 [52:57<2:58:12, 64.03s/it]Best trial: 10. Best value: 85.3333:  16%|██████▉                                   | 33/200 [53:15<2:58:12, 64.03s/it]Best trial: 10. Best value: 85.3333:  17%|███████▏                                  | 34/200 [53:15<2:18:42, 50.14s/it]Best trial: 10. Best value: 85.3333:  17%|███████▏                                  | 34/200 [53:25<2:18:42, 50.14s/it]Best trial: 10. Best value: 85.3333:  18%|███████▎                                  | 35/200 [53:25<1:44:48, 38.11s/it]Best trial: 10. Best value: 85.3333:  18%|███████▎                                  | 35/200 [55:53<1:44:48, 38.11s/it]Best trial: 10. Best value: 85.3333:  18%|███████▌                                  | 36/200 [55:53<3:14:59, 71.34s/it]Best trial: 10. Best value: 85.3333:  18%|███████▌                                  | 36/200 [57:34<3:14:59, 71.34s/it]Best trial: 10. Best value: 85.3333:  18%|███████▊                                  | 37/200 [57:34<3:37:53, 80.21s/it]Best trial: 10. Best value: 85.3333:  18%|███████▍                                | 37/200 [1:01:09<3:37:53, 80.21s/it]Best trial: 10. Best value: 85.3333:  19%|███████▍                               | 38/200 [1:01:09<5:25:06, 120.41s/it]Best trial: 10. Best value: 85.3333:  19%|███████▍                               | 38/200 [1:01:35<5:25:06, 120.41s/it]Best trial: 10. Best value: 85.3333:  20%|███████▊                                | 39/200 [1:01:35<4:07:25, 92.21s/it]Best trial: 10. Best value: 85.3333:  20%|███████▊                                | 39/200 [1:02:49<4:07:25, 92.21s/it]Best trial: 10. Best value: 85.3333:  20%|████████                                | 40/200 [1:02:49<3:51:26, 86.79s/it]Best trial: 10. Best value: 85.3333:  20%|████████                                | 40/200 [1:02:54<3:51:26, 86.79s/it]Best trial: 10. Best value: 85.3333:  20%|████████▏                               | 41/200 [1:02:54<2:45:01, 62.27s/it]Best trial: 10. Best value: 85.3333:  20%|████████▏                               | 41/200 [1:03:57<2:45:01, 62.27s/it]Best trial: 10. Best value: 85.3333:  21%|████████▍                               | 42/200 [1:03:57<2:44:35, 62.50s/it]Best trial: 10. Best value: 85.3333:  21%|████████▍                               | 42/200 [1:04:59<2:44:35, 62.50s/it]Best trial: 10. Best value: 85.3333:  22%|████████▌                               | 43/200 [1:04:59<2:43:08, 62.35s/it]Best trial: 10. Best value: 85.3333:  22%|████████▌                               | 43/200 [1:05:47<2:43:08, 62.35s/it]Best trial: 10. Best value: 85.3333:  22%|████████▊                               | 44/200 [1:05:47<2:30:50, 58.01s/it]Best trial: 10. Best value: 85.3333:  22%|████████▊                               | 44/200 [1:06:03<2:30:50, 58.01s/it]Best trial: 10. Best value: 85.3333:  22%|█████████                               | 45/200 [1:06:03<1:57:07, 45.34s/it]Best trial: 10. Best value: 85.3333:  22%|█████████                               | 45/200 [1:07:34<1:57:07, 45.34s/it]Best trial: 10. Best value: 85.3333:  23%|█████████▏                              | 46/200 [1:07:34<2:31:18, 58.95s/it]Best trial: 10. Best value: 85.3333:  23%|█████████▏                              | 46/200 [1:07:41<2:31:18, 58.95s/it]Best trial: 10. Best value: 85.3333:  24%|█████████▍                              | 47/200 [1:07:41<1:51:16, 43.64s/it]Best trial: 10. Best value: 85.3333:  24%|█████████▍                              | 47/200 [1:11:06<1:51:16, 43.64s/it]Best trial: 10. Best value: 85.3333:  24%|█████████▌                              | 48/200 [1:11:06<3:53:02, 91.99s/it]Best trial: 10. Best value: 85.3333:  24%|█████████▌                              | 48/200 [1:14:24<3:53:02, 91.99s/it]Best trial: 10. Best value: 85.3333:  24%|█████████▌                             | 49/200 [1:14:24<5:11:31, 123.78s/it]Best trial: 10. Best value: 85.3333:  24%|█████████▌                             | 49/200 [1:22:02<5:11:31, 123.78s/it]Best trial: 10. Best value: 85.3333:  25%|█████████▊                             | 50/200 [1:22:02<9:20:13, 224.09s/it]Best trial: 10. Best value: 85.3333:  25%|█████████▊                             | 50/200 [1:22:18<9:20:13, 224.09s/it]Best trial: 10. Best value: 85.3333:  26%|█████████▉                             | 51/200 [1:22:18<6:40:49, 161.41s/it]Best trial: 10. Best value: 85.3333:  26%|█████████▉                             | 51/200 [1:23:58<6:40:49, 161.41s/it]Best trial: 10. Best value: 85.3333:  26%|██████████▏                            | 52/200 [1:23:58<5:52:40, 142.98s/it]Best trial: 10. Best value: 85.3333:  26%|██████████▏                            | 52/200 [1:25:06<5:52:40, 142.98s/it]Best trial: 10. Best value: 85.3333:  26%|██████████▎                            | 53/200 [1:25:06<4:55:28, 120.60s/it]Best trial: 10. Best value: 85.3333:  26%|██████████▎                            | 53/200 [1:26:37<4:55:28, 120.60s/it]Best trial: 10. Best value: 85.3333:  27%|██████████▌                            | 54/200 [1:26:37<4:31:54, 111.75s/it]Best trial: 10. Best value: 85.3333:  27%|██████████▌                            | 54/200 [1:26:52<4:31:54, 111.75s/it]Best trial: 10. Best value: 85.3333:  28%|███████████                             | 55/200 [1:26:52<3:19:40, 82.63s/it]Best trial: 10. Best value: 85.3333:  28%|███████████                             | 55/200 [1:26:59<3:19:40, 82.63s/it]Best trial: 10. Best value: 85.3333:  28%|███████████▏                            | 56/200 [1:26:59<2:23:54, 59.96s/it]Best trial: 10. Best value: 85.3333:  28%|███████████▏                            | 56/200 [1:29:54<2:23:54, 59.96s/it]Best trial: 10. Best value: 85.3333:  28%|███████████▍                            | 57/200 [1:29:54<3:45:04, 94.44s/it]Best trial: 10. Best value: 85.3333:  28%|███████████▍                            | 57/200 [1:30:00<3:45:04, 94.44s/it]Best trial: 10. Best value: 85.3333:  29%|███████████▌                            | 58/200 [1:30:00<2:40:48, 67.95s/it]Best trial: 10. Best value: 85.3333:  29%|███████████▌                            | 58/200 [1:30:08<2:40:48, 67.95s/it]Best trial: 10. Best value: 85.3333:  30%|███████████▊                            | 59/200 [1:30:08<1:57:35, 50.04s/it]Best trial: 10. Best value: 85.3333:  30%|███████████▊                            | 59/200 [1:30:39<1:57:35, 50.04s/it]Best trial: 10. Best value: 85.3333:  30%|████████████                            | 60/200 [1:30:39<1:43:09, 44.21s/it]Best trial: 10. Best value: 85.3333:  30%|████████████                            | 60/200 [1:34:12<1:43:09, 44.21s/it]Best trial: 10. Best value: 85.3333:  30%|████████████▏                           | 61/200 [1:34:12<3:39:45, 94.86s/it]Best trial: 10. Best value: 85.3333:  30%|████████████▏                           | 61/200 [1:35:28<3:39:45, 94.86s/it]Best trial: 10. Best value: 85.3333:  31%|████████████▍                           | 62/200 [1:35:28<3:25:31, 89.36s/it]Best trial: 10. Best value: 85.3333:  31%|████████████▍                           | 62/200 [1:36:54<3:25:31, 89.36s/it]Best trial: 10. Best value: 85.3333:  32%|████████████▌                           | 63/200 [1:36:54<3:21:48, 88.39s/it]Best trial: 10. Best value: 85.3333:  32%|████████████▌                           | 63/200 [1:38:39<3:21:48, 88.39s/it]Best trial: 10. Best value: 85.3333:  32%|████████████▊                           | 64/200 [1:38:39<3:31:35, 93.35s/it]Best trial: 10. Best value: 85.3333:  32%|████████████▊                           | 64/200 [1:39:47<3:31:35, 93.35s/it]Best trial: 10. Best value: 85.3333:  32%|█████████████                           | 65/200 [1:39:47<3:12:36, 85.61s/it]                                                                                                                       [33m[W 2026-02-14 09:40:58,811][0m Trial 65 failed with parameters: {'n_estimators': 516, 'max_depth': 5, 'learning_rate': 0.009267593967096543, 'subsample': 0.8933851531163975, 'colsample_bytree': 0.7850107952788158, 'min_child_weight': 9, 'reg_alpha': 0.0002923432936524545, 'reg_lambda': 2.6585279114588735e-05, 'gamma': 3.7514200720372895e-06} because of the following error: KeyboardInterrupt('').[0m
Traceback (most recent call last):
  File "C:\Users\XuRui\anaconda3\envs\xurui-clean\lib\site-packages\optuna\study\_optimize.py", line 206, in _run_trial
    value_or_values = func(trial)
  File "C:\Users\XuRui\Downloads\Bot-or-Not-main\Bot-or-Not-main\max.py", line 2067, in objective
    # Train all base models with the suggested hyperparameters
  File "C:\Users\XuRui\Downloads\Bot-or-Not-main\Bot-or-Not-main\max.py", line 1908, in train_models
    )
  File "C:\Users\XuRui\anaconda3\envs\xurui-clean\lib\site-packages\catboost\core.py", line 5245, in fit
    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,
  File "C:\Users\XuRui\anaconda3\envs\xurui-clean\lib\site-packages\catboost\core.py", line 2410, in _fit
    self._train(
  File "C:\Users\XuRui\anaconda3\envs\xurui-clean\lib\site-packages\catboost\core.py", line 1790, in _train
    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)
  File "_catboost.pyx", line 5023, in _catboost._CatBoost._train
  File "_catboost.pyx", line 5072, in _catboost._CatBoost._train
KeyboardInterrupt
Best trial: 10. Best value: 85.3333:  32%|█████████████                           | 65/200 [1:40:42<3:12:36, 85.61s/it]                                                                                                                       [33m[W 2026-02-14 09:40:58,813][0m Trial 65 failed with value None.[0m
Best trial: 10. Best value: 85.3333:  32%|█████████████                           | 65/200 [1:40:42<3:12:36, 85.61s/it]Best trial: 10. Best value: 85.3333:  32%|█████████████                           | 65/200 [1:40:42<3:29:08, 92.95s/it]
Traceback (most recent call last):
  File "C:\Users\XuRui\Downloads\Bot-or-Not-main\Bot-or-Not-main\max.py", line 2283, in <module>
    if best_params is None:
  File "C:\Users\XuRui\Downloads\Bot-or-Not-main\Bot-or-Not-main\max.py", line 2087, in optuna_optimize_hyperparams
    )
  File "C:\Users\XuRui\anaconda3\envs\xurui-clean\lib\site-packages\optuna\study\study.py", line 490, in optimize
    _optimize(
  File "C:\Users\XuRui\anaconda3\envs\xurui-clean\lib\site-packages\optuna\study\_optimize.py", line 68, in _optimize
    _optimize_sequential(
  File "C:\Users\XuRui\anaconda3\envs\xurui-clean\lib\site-packages\optuna\study\_optimize.py", line 165, in _optimize_sequential
    frozen_trial_id = _run_trial(study, func, catch)
  File "C:\Users\XuRui\anaconda3\envs\xurui-clean\lib\site-packages\optuna\study\_optimize.py", line 263, in _run_trial
    raise func_err
  File "C:\Users\XuRui\anaconda3\envs\xurui-clean\lib\site-packages\optuna\study\_optimize.py", line 206, in _run_trial
    value_or_values = func(trial)
  File "C:\Users\XuRui\Downloads\Bot-or-Not-main\Bot-or-Not-main\max.py", line 2067, in objective
    # Train all base models with the suggested hyperparameters
  File "C:\Users\XuRui\Downloads\Bot-or-Not-main\Bot-or-Not-main\max.py", line 1908, in train_models
    )
  File "C:\Users\XuRui\anaconda3\envs\xurui-clean\lib\site-packages\catboost\core.py", line 5245, in fit
    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,
  File "C:\Users\XuRui\anaconda3\envs\xurui-clean\lib\site-packages\catboost\core.py", line 2410, in _fit
    self._train(
  File "C:\Users\XuRui\anaconda3\envs\xurui-clean\lib\site-packages\catboost\core.py", line 1790, in _train
    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)
  File "_catboost.pyx", line 5023, in _catboost._CatBoost._train
  File "_catboost.pyx", line 5072, in _catboost._CatBoost._train
KeyboardInterrupt
